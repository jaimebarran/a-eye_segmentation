{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D patch-based segmentation with U-Net\n",
    "\n",
    "Code started from [Francesco's tutorials](https://github.com/FrancescoLR/tutorials)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.1rc3\n",
      "Numpy version: 1.22.4\n",
      "Pytorch version: 1.12.1+cu116\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 7a5de8b7b9db101a431e70ae2aa8ea7ebb8dfffe\n",
      "MONAI __file__: /home/jaimebarranco/miniconda3/envs/3dmultilabel/lib/python3.9/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.9\n",
      "Nibabel version: 4.0.1\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.2.0\n",
      "Tensorboard version: 2.9.1\n",
      "gdown version: 4.5.1\n",
      "TorchVision version: 0.13.1+cu116\n",
      "tqdm version: 4.64.0\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.1\n",
      "pandas version: 1.4.3\n",
      "einops version: 0.4.1\n",
      "transformers version: 4.20.1\n",
      "mlflow version: 1.27.0\n",
      "pynrrd version: 0.4.3\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from monai.config import print_config\n",
    "from monai.data import ArrayDataset, decollate_batch, DataLoader, CacheDataset, Dataset\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric, MeanIoU, compute_meaniou\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    Orientationd,\n",
    "    Spacingd,\n",
    "    ResizeWithPadOrCropd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    Lambdad,\n",
    "    ScaleIntensityd,\n",
    ")\n",
    "from monai.utils import first\n",
    "\n",
    "import ignite\n",
    "import torch, torchvision\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths and cuda check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is: /mnt/sda1/Repos/a-eye/a-eye_preprocessing/ANTs/\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "main_dir = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/3D_multilabel/'\n",
    "data_dir = '/mnt/sda1/Repos/a-eye/a-eye_preprocessing/ANTs/'\n",
    "\n",
    "[print(f\"Data directory is: {data_dir}\") if os.path.isdir(data_dir) else print(\"Check your data directory\")]\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set images and segmentation paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset is composed by 26 (74.29%) subjects and validation by 9 (25.71%).\n"
     ]
    }
   ],
   "source": [
    "train_images_1 = []\n",
    "train_labels_1 = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "# List of subjects taken for the template construction\n",
    "best_subjects_cc = ['sub-02','sub-03','sub-08','sub-09','sub-20','sub-29','sub-30','sub-33','sub-34'] # 9\n",
    "\n",
    "# List of remaining subjects\n",
    "all_subjects = list()\n",
    "for i in range(35):\n",
    "    all_subjects.append('sub-'+str(i+1).zfill(2))\n",
    "rest_subjects = [elem for elem in all_subjects if elem not in best_subjects_cc]\n",
    "\n",
    "# Train (rest subjects)\n",
    "for i in range(len(rest_subjects)):\n",
    "    input_t1 = data_dir + 'a123/' + rest_subjects[i] + '/input/' + rest_subjects[i] + '_T1.nii.gz'\n",
    "    input_labels = data_dir + 'a123/' + rest_subjects[i] + '/input/' + rest_subjects[i] + '_labels.nii.gz'\n",
    "    train_images_1.append(input_t1)\n",
    "    train_labels_1.append(input_labels)\n",
    "# Train dictionary\n",
    "data_train_dicts_1 = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images_1, train_labels_1)\n",
    "]   \n",
    "\n",
    "# Test (best subjects)\n",
    "for i in range(len(best_subjects_cc)):\n",
    "    input_t1 = data_dir + 'a123/' + best_subjects_cc[i] + '/input/' + best_subjects_cc[i] + '_T1.nii.gz'\n",
    "    input_labels = data_dir + 'a123/' + best_subjects_cc[i] + '/input/' + best_subjects_cc[i] + '_labels.nii.gz'\n",
    "    test_images.append(input_t1)\n",
    "    test_labels.append(input_labels)\n",
    "# Test dictionary\n",
    "data_test_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(test_images, test_labels)\n",
    "]\n",
    "\n",
    "num_train_samples = len(data_train_dicts_1)\n",
    "num_test_samples = len(data_test_dicts)\n",
    "num_total_samples = num_train_samples + num_test_samples\n",
    "print(f\"Train dataset is composed by {len(data_train_dicts_1)} ({num_train_samples/num_total_samples*100:.2f}%) subjects and validation by {len(data_test_dicts)} ({num_test_samples/num_total_samples*100:.2f}%).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set transforms and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to crop the eye from the medical image\n",
    "def masked(data_dict):\n",
    "    eye_mask = (data_dict[\"label\"] != 0)\n",
    "    eye_mask[eye_mask == True] = 1\n",
    "    eye_mask[eye_mask == False] = 0\n",
    "    data_dict[\"image\"] = data_dict[\"image\"] * eye_mask\n",
    "\n",
    "    return data_dict\n",
    "    \n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]), #Load image file or files from provided path based on reader.\n",
    "        Lambdad(keys=[\"image\"], func=lambda image: torch.nan_to_num(image, nan=0)),\n",
    "        ScaleIntensityd(keys=[\"image\"], ), #Scale the intensity of input image to the given value range (minv, maxv). If minv and maxv and factor not provided, Normalize the data\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]), #Automatically adjust or add the channel dimension of input data to ensure channel_first shape.\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"), #Change the input imageâ€™s orientation into the specified based on axcodes.\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
    "            1, 1, 1), mode=(\"bilinear\", \"nearest\")),\n",
    "        ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=(160, 160, 160)),\n",
    "        masked,\n",
    "        # RandCropByPosNegLabeld( #Crop random fixed sized regions with the center being a foreground or background voxel based on the Pos Neg Ratio. I recommend to use it since improves dice and IoU score\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     label_key=\"label\",\n",
    "        #     spatial_size=(96, 96, 96),\n",
    "        #     pos=1,\n",
    "        #     neg=1,\n",
    "        #     num_samples=4,\n",
    "        #     image_key=\"image\",\n",
    "        #     image_threshold=0,\n",
    "        # ),\n",
    "    ]    \n",
    ")\n",
    "\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        Lambdad(keys=[\"image\"], func=lambda image: torch.nan_to_num(image, nan=0)),\n",
    "        ScaleIntensityd(keys=[\"image\"],),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAI\"),\n",
    "        # Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
    "        #     1, 1, 1), mode=(\"bilinear\", \"nearest\")),\n",
    "        # ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=(176, 256, 176)),\n",
    "        masked,\n",
    "        # RandCropByPosNegLabeld( #Crop random fixed sized regions with the center being a foreground or background voxel based on the Pos Neg Ratio. \n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     label_key=\"label\",\n",
    "        #     spatial_size=(96, 96, 96),\n",
    "        #     pos=1,\n",
    "        #     neg=1,\n",
    "        #     num_samples=4,\n",
    "        #     image_key=\"image\",\n",
    "        #     image_threshold=0,\n",
    "        # ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use CacheDataset to accelerate training and validation process, it's 10x faster than the regular Dataset.  \n",
    "To achieve best performance, set `cache_rate=1.0` to cache all the data, if memory is not enough, set lower value.  \n",
    "Users can also set `cache_num` instead of `cache_rate`, will use the minimum value of the 2 settings.  \n",
    "And set `num_workers` to enable multi-threads during caching.  \n",
    "If want to try the regular Dataset, just change to use the commented code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00, 10.15it/s]\n",
      "Loading dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 13.71it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds = CacheDataset(\n",
    "    data=data_train_dicts_1, transform=train_transforms,\n",
    "    cache_rate=1.0, num_workers=8)\n",
    "# train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "# to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=8)\n",
    "\n",
    "test_ds = CacheDataset(\n",
    "    data=data_test_dicts, transform=test_transforms, cache_rate=1.0, num_workers=8)\n",
    "# val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict: (1, 1, 176, 256, 176)\n",
      "(1, 176, 256, 176)\n"
     ]
    }
   ],
   "source": [
    "# '''\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# Saving test_loader images\n",
    "i = 0\n",
    "for _, dict in enumerate(test_loader):\n",
    "    print(f\"dict: {dict['image'].shape}\")\n",
    "    im_tensors = dict['image']\n",
    "    # lab_tensors = dict['label'][0][0]\n",
    "    print(im_tensors[0].detach().cpu().numpy().shape)\n",
    "    im_trans = sitk.GetImageFromArray(np.transpose(im_tensors[0].detach().cpu().numpy(), (3,2,1,0)))\n",
    "    # lab_trans = sitk.GetImageFromArray(torch.argmax(lab_tensors, dim=1).detach().cpu()[0,:,:,:].numpy())\n",
    "    sitk.WriteImage(im_trans, main_dir+'im_trans_masked'+str(i)+'.nii.gz')\n",
    "    i += 1\n",
    "    if i == 1:\n",
    "        break\n",
    "# '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check transforms in DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (176, 256, 176), label shape: (176, 256, 176)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAADdCAYAAABjcdyjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVRElEQVR4nO3df7DldX3f8edLFjZRWGED2dkCEdDVKk66wR0wE7W06w9gkiLp1GI7CUHTxSZMtW2agk4jk8508kPixEmKxXEHTBPAxqLU4g/ccUI7DRt3leAiIguBsuu6K666aOxmgXf/ON+Nhzv3snfPOZ/za5+PmTP3ez7f7/ec92e+977ndb/ne85JVSFJkqTRe96kC5AkSZpXBi1JkqRGDFqSJEmNGLQkSZIaMWhJkiQ1YtCSJElqxKClgSS5P8mFk65DkkYhyaNJXr+M7SrJSwZ8joH31exaMekCNJuq6txJ1yBJ0rTzjJYkSVIjBi0N5PBp9iTXJflvSf5rkieTfDnJS5Ncm2RfkseTvLFvvyuTPNBt+0iSqxY87q8n2ZPk60l+uf9Ue5KVSd6X5P8m2Zvkg0l+dNxzlzS/kpyf5M+TfKfrRX+Q5IQFm13S9a8nkvxukuf17f+2rsd9O8lnkrxozFPQlDFoaRR+Dvgj4BTgS8Bn6P1unQ78JvBf+rbdB/wssAq4Enh/kvMAklwE/Bvg9cBLgAsXPM9vAS8F1nfrTwd+o8F8JB27ngb+NXAq8NPARuBXFmxzGbABOA+4FHgbQJJLgXcDPw+cBvwv4JaxVK2pFb/rUINI8ijwy8BrgJ+pqjd04z9Hr7G8sKqeTnIScAA4paq+s8jjfBz4fFX9fpLNwN6qurZb9xLgIWAd8DDwPeAnq+rhbv1PA39SVWe3nKuk+Xe4p1XV5xaMvwv4+1V1WXe/gIur6tPd/V8B/nFVbUzyKeBPq+rD3brn0etbL6+qx7p911XVznHNS5PnGS2Nwt6+5R8AT1TV0333AU4ESHJxknuS7E/yHeASev85Avwd4PG+x+pfPg14PrC9O6X/HeDT3bgkjUR36cMnk3wjyQHgP/HDHnVYf296jF7vAngR8Pt9PWo/EHpn33WMMmhpbJKsBD4GvA9YU1UnA3fSa0QAe4Az+nY5s2/5CXqh7dyqOrm7vbCqTmxfuaRjyA3AV+mdeVpF76XALNimvzf9BPD1bvlx4Kq+HnVyVf1oVf2f5lVrahm0NE4nACuBbwJPJbkYeGPf+o8CVyZ5eZLnA//h8Iqqegb4EL1run4cIMnpSd40tuolHQsOX+7wvSR/F/iXi2zz75KckuRM4J3Abd34B4Frk5wLkOSFSf7JOIrW9DJoaWyq6kngX9ELVN8G/hlwR9/6TwEfAD4P7ATu6VYd7H7++8Pj3Sn9zwEvG0vxko4Vv0avNz1J75+72xbZ5hPAduBe4H8CHwaoqtuB3wZu7XrUDuDi9iVrmnkxvKZWkpfTa1Qrq+qpSdcjSdLR8oyWpkqSy7rPyzqF3n+G/8OQJUmaVQYtTZur6H3W1sP0Ps9msesjJEmaCc2CVpKLkjyYZGeSa1o9j+ZLVV3UvZtwdVVdVlV7Jl2Tjj32L0mj0uQarSTHAV8D3gDsAr4AvLWqvjLyJ5OkEbJ/SRqlFY0e93xgZ1U9ApDkVnpfU7Boo+o+LVfSseWJqprGD5w9qv4FcEJW1o/wgjGVJ2nS/h/f52/q4MLPV1tUq6B1Os/+5NxdwAX9GyTZBGxq9PySpt9jky5gCUfsX/DsHvYjPJ8LsnE81UmauK21ZdnbTuxi+Kq6sao2VNWGSdUgSYPq72HHs3LS5UiaUq2C1m6e/RUFZ3RjkjTt7F+SRqZV0PoCsC7J2UlOAC6n7xPAJWmK2b8kjUyTa7Sq6qkkVwOfAY4DNlfV/S2eS5JGyf4laZRaXQxPVd0J3Nnq8SWpFfuXpFHxk+ElSZIaMWhJkiQ1YtCSJElqxKAlSZLUiEFLkiSpEYOWJElSIwYtSZKkRgxakiRJjRi0JEmSGjFoSZIkNWLQkiRJasSgJUmS1IhBS5IkqRGDliRJUiMGLUmSpEYGDlpJzkzy+SRfSXJ/knd249cl2Z3k3u52yejKlaTRsIdJGocVQ+z7FPBvq+qLSU4Ctie5q1v3/qp63/DlSVIz9jBJzQ0ctKpqD7CnW34yyQPA6aMqTJJasodJGoeRXKOV5Czgp4Ct3dDVSe5LsjnJKaN4DklqxR4mqZWhg1aSE4GPAe+qqgPADcCLgfX0/lu8fon9NiXZlmTbsDVI0qBG0cMOcXBc5UqaMamqwXdOjgc+CXymqn5vkfVnAZ+sqlce4XEGL0LSrNpeVRsmWcCoetiqrK4LsrFNkZKmztbawoHan+VsO8y7DgN8GHigv0ElWdu32WXAjkGfQ5JasYdJGodh3nX4M8AvAF9Ocm839m7grUnWAwU8Clw1xHNIUiv2MEnNDfOuw/8NLHba7M7By5Gk8bCHSRoHPxlekiSpEYOWJElSIwYtSZKkRgxakiRJjRi0JEmSGjFoSZIkNWLQkiRJasSgJUmS1IhBS5IkqRGDliRJUiMGLUmSpEYMWpIkSY0YtCRJkhoxaEmSJDVi0JIkSWrEoCVJktTIimEfIMmjwJPA08BTVbUhyWrgNuAs4FHgLVX17WGfS5JGyf4lqbVRndH6B1W1vqo2dPevAbZU1TpgS3dfkqaR/UtSM61eOrwUuLlbvhl4c6PnkaRRs39JGplRBK0CPptke5JN3diaqtrTLX8DWLNwpySbkmxLsm0ENUjSIAbqX/DsHnaIg+OoVdIMGvoaLeA1VbU7yY8DdyX5av/KqqoktXCnqroRuBFgsfWSNAYD9a9u3d/2sFVZbQ+TtKihz2hV1e7u5z7gduB8YG+StQDdz33DPo8kjZr9S1JrQwWtJC9IctLhZeCNwA7gDuCKbrMrgE8M8zySNGr2L0njMOxLh2uA25Mcfqw/qapPJ/kC8NEkbwceA94y5PNI0qjZvyQ1N1TQqqpHgL+3yPi3gI3DPLYktWT/kjQOfjK8JElSIwYtSZKkRgxakiRJjRi0JEmSGjFoSZIkNWLQkiRJasSgJUmS1IhBS5IkqRGDliRJUiMGLUmSpEYMWpIkSY0YtCRJkhoxaEmSJDVi0JIkSWrEoCVJktSIQUuSJKmRFYPumORlwG19Q+cAvwGcDPwL4Jvd+Lur6s5Bn0eSWrCHSRqHVNXwD5IcB+wGLgCuBL5XVe87iv2HL0LSrNleVRsmXQQM38NWZXVdkI2typM0ZbbWFg7U/ixn21G9dLgReLiqHhvR40nSONnDJDUxqqB1OXBL3/2rk9yXZHOSUxbbIcmmJNuSbBtRDZI0qKF62CEOjqdKSTNn6JcOk5wAfB04t6r2JlkDPAEU8B+BtVX1tiM8hi8dSseeqXjpcBQ9zJcOpWPLuF86vBj4YlXtBaiqvVX1dFU9A3wIOH8EzyFJrdjDJDUziqD1VvpOuSdZ27fuMmDHCJ5Dklqxh0lqZuCPdwBI8gLgDcBVfcO/k2Q9vdPujy5YJ0lTwx4mqbWhglZVfR/4sQVjvzBURZI0JvYwSa35yfCSJEmNGLQkSZIaMWhJkiQ1YtCSJElqxKAlSZLUiEFLkiSpEYOWJElSIwYtSZKkRgxakiRJjRi0JEmSGjFoSZIkNWLQkiRJasSgJUmS1IhBS5IkqRGDliRJUiMGLUmSpEaWFbSSbE6yL8mOvrHVSe5K8lD385RuPEk+kGRnkvuSnNeqeEk6EvuXpEla7hmtm4CLFoxdA2ypqnXAlu4+wMXAuu62Cbhh+DIlaWA3Yf+SNCHLClpVdTewf8HwpcDN3fLNwJv7xj9SPfcAJydZO4JaJemo2b8kTdIw12itqao93fI3gDXd8unA433b7erGniXJpiTbkmwbogZJGsRQ/Que3cMOcbBdpZJm2kguhq+qAuoo97mxqjZU1YZR1CBJgxikf3X7/W0PO56VDSqTNA+GCVp7D59S737u68Z3A2f2bXdGNyZJ08L+JWkshgladwBXdMtXAJ/oG//F7t07rwa+23eKXpKmgf1L0lisWM5GSW4BLgROTbILeC/wW8BHk7wdeAx4S7f5ncAlwE7gr4ErR1yzJC2b/UvSJKV3ecKEi0gmX4Skcds+L9dorsrquiAbJ12GpDHZWls4UPuznG39ZHhJkqRGDFqSJEmNGLQkSZIaMWhJkiQ1YtCSJElqxKAlSZLUiEFLkiSpEYOWJElSIwYtSZKkRgxakiRJjRi0JEmSGjFoSZIkNWLQkiRJasSgJUmS1IhBS5IkqRGDliRJUiNHDFpJNifZl2RH39jvJvlqkvuS3J7k5G78rCQ/SHJvd/tgw9ol6YjsYZImaTlntG4CLlowdhfwyqr6SeBrwLV96x6uqvXd7R2jKVOSBnYT9jBJE3LEoFVVdwP7F4x9tqqe6u7eA5zRoDZJGpo9TNIkjeIarbcBn+q7f3aSLyX5sySvXWqnJJuSbEuybQQ1SNKghu5hhzjYvkpJM2nFMDsneQ/wFPDH3dAe4Ceq6ltJXgV8PMm5VXVg4b5VdSNwY/c4NUwdkjSIUfWwVVltD5O0qIHPaCX5JeBngX9eVQVQVQer6lvd8nbgYeClI6hTkkbKHiZpHAYKWkkuAn4d+EdV9dd946clOa5bPgdYBzwyikIlaVTsYZLG5YgvHSa5BbgQODXJLuC99N6hsxK4KwnAPd27c14H/GaSQ8AzwDuqav+iDyxJY2APkzRJ6c6YT7YIr9GSjkXbq2rDpIsYhVVZXRdk46TLkDQmW2sLB2p/lrOtnwwvSZLUiEFLkiSpEYOWJElSIwYtSZKkRgxakiRJjRi0JEmSGjFoSZIkNWLQkiRJasSgJUmS1IhBS5IkqRGDliRJUiMGLUmSpEYMWpIkSY0YtCRJkhoxaEmSJDVyxKCVZHOSfUl29I1dl2R3knu72yV9665NsjPJg0ne1KpwSVoOe5ikSVrOGa2bgIsWGX9/Va3vbncCJHkFcDlwbrfPf05y3KiKlaQB3IQ9TNKEHDFoVdXdwP5lPt6lwK1VdbCq/grYCZw/RH2SNBR7mKRJGuYarauT3Nedlj+lGzsdeLxvm13dmCRNG3uYpOYGDVo3AC8G1gN7gOuP9gGSbEqyLcm2AWuQpEGNtIcd4uCIy5M0LwYKWlW1t6qerqpngA/xw1Pru4Ez+zY9oxtb7DFurKoNVbVhkBokaVCj7mHHs7JtwZJm1kBBK8navruXAYffzXMHcHmSlUnOBtYBfzFciZI0WvYwSeOy4kgbJLkFuBA4Ncku4L3AhUnWAwU8ClwFUFX3J/ko8BXgKeBXq+rpJpVL0jLYwyRNUqpq0jWQZPJFSBq37fNy6cCqrK4LsnHSZUgak621hQO1P8vZ1k+GlyRJasSgJUmS1IhBS5IkqRGDliRJUiMGLUmSpEYMWpIkSY0YtCRJkhoxaEmSJDVi0JIkSWrEoCVJktSIQUuSJKkRg5YkSVIjBi1JkqRGDFqSJEmNGLQkSZIaMWhJkiQ1csSglWRzkn1JdvSN3Zbk3u72aJJ7u/Gzkvygb90HG9YuSUdkD5M0SSuWsc1NwB8AHzk8UFX/9PBykuuB7/Zt/3BVrR9RfZI0rJuwh0makCMGraq6O8lZi61LEuAtwD8ccV2SNBL2MEmTNOw1Wq8F9lbVQ31jZyf5UpI/S/LapXZMsinJtiTbhqxBkgY1kh52iIPtK5U0k1JVR96o99/gJ6vqlQvGbwB2VtX13f2VwIlV9a0krwI+DpxbVQeO8PjfBL4PPDHIJKbIqcz+HGA+5jEPc4D5nseLquq0cTz5GHrYk8CDLWofs3n4fZuHOcB8zGMe5gBD9q/lXKO1qCQrgJ8HXnV4rKoOQu9fu6ranuRh4KXAc561qqrTkmyrqg2D1jMN5mEOMB/zmIc5gPNoaZQ9DHhw2uY3iGk8TkdrHuYA8zGPeZgDDD+PYV46fD3w1ara1VfMaUmO65bPAdYBjwzxHJLUij1MUnPL+XiHW4A/B16WZFeSt3erLgduWbD564D7urdK/ynwjqraP8J6Jemo2MMkTdJy3nX41iXGf2mRsY8BHxuwlhsH3G+azMMcYD7mMQ9zAOcxtDH1MI/T9JiHOcB8zGMe5gBDzmNZF8NLkiTp6PkVPJIkSY0YtCRJkhqZeNBKclGSB5PsTHLNpOs5Gt13pH25+060bd3Y6iR3JXmo+3nKpOtcaInvflu07vR8oDs+9yU5b3KV/9ASc7guye6+76m7pG/dtd0cHkzypslU/WxJzkzy+SRfSXJ/knd247N2LJaax0wdj0HNag+zf03OPPQvmI8eNpb+VVUTuwHHAQ8D5wAnAH8JvGKSNR1l/Y8Cpy4Y+x3gmm75GuC3J13nInW/DjgP2HGkuoFLgE8BAV4NbJ10/c8xh+uAX1tk21d0v1srgbO737njpmAOa4HzuuWTgK91tc7asVhqHjN1PAac+8z2MPvX1M1h5v5e5qGHjaN/TfqM1vn0PpX5kar6G+BW4NIJ1zSsS4Gbu+WbgTdPrpTFVdXdwMK3rC9V96XAR6rnHuDkJGvHUuhzWGIOS7kUuLWqDlbVXwE76f3uTVRV7amqL3bLTwIPAKcze8diqXksZSqPx4DmrYfZv8ZgHvoXzEcPG0f/mnTQOh14vO/+Lp57gtOmgM8m2Z5kUze2pqr2dMvfANZMprSjtlTds3aMru5OSW/ue9lj6ueQ3lfE/BSwlRk+FgvmATN6PI7CLM/F/jV9ZvbvZR56WKv+NemgNeteU1XnARcDv5rkdf0rq3eeceY+P2NW6wZuAF4MrAf2ANdPtJplSnIivc9uelct+E69WToWi8xjJo/HMcT+NV1m9u9lHnpYy/416aC1Gziz7/4Z3dhMqKrd3c99wO30Th/uPXwqtPu5b3IVHpWl6p6ZY1RVe6vq6ap6BvgQPzydO7VzSHI8vT/uP66q/94Nz9yxWGwes3g8BjCzc7F/TZdZ/XuZhx7Wun9NOmh9AViX5OwkJ9D7Sow7JlzTsiR5QZKTDi8DbwR20Kv/im6zK4BPTKbCo7ZU3XcAv9i9W+TVwHf7TglPlQWv9V9G73hAbw6XJ1mZ5Gx631/3F+Oub6EkAT4MPFBVv9e3aqaOxVLzmLXjMaCZ7GH2r+kzi38v89DDxtK/hr1if9gbvXchfI3elfvvmXQ9R1H3OfTeefCXwP2Hawd+DNgCPAR8Dlg96VoXqf0WeqdCD9F7ffntS9VN790hf9gdny8DGyZd/3PM4Y+6Gu/r/hjW9m3/nm4ODwIXT7r+rqbX0Dulfh9wb3e7ZAaPxVLzmKnjMcT8Z66H2b+mcg4z9/cyDz1sHP3Lr+CRJElqZNIvHUqSJM0tg5YkSVIjBi1JkqRGDFqSJEmNGLQkSZIaMWhJkiQ1YtCSJElq5P8DS41zfz8hwZEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_iter = iter(test_loader)\n",
    "random_data = data_iter.next()\n",
    "image, label = (random_data[\"image\"][0][0], random_data[\"label\"][0][0]) # [0][0] is to show only the image shape\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "\n",
    "# plot the slice [:, :, 80]\n",
    "plt.figure(\"check\", (10,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(image[:, :, 80], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, 80])\n",
    "plt.show()\n",
    "#print(len(torch.unique(label)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNet, DiceLoss and Adam optimizer\n",
    "# import gc \n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    spatial_dims = 3,\n",
    "    in_channels = 1,\n",
    "    out_channels = 10,\n",
    "    channels = (16, 32, 64, 128, 256),\n",
    "    strides = (2, 2, 2, 2),\n",
    "    num_res_units = 2,\n",
    "    norm = Norm.BATCH,\n",
    "    dropout = 0.5\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DSC is 0.5930375456809998. \n",
      "Total IoU score is 0.4942435026168823.\n",
      "Dice per class: [0.6186713576316833, 0.6833220720291138, 0.718679666519165, 0.5941488742828369, 0.693603515625, 0.6383098363876343, 0.6851651668548584, 0.6821538805961609]. \n",
      "IoU per class: [0.4926207959651947, 0.5793008208274841, 0.6224082112312317, 0.46919167041778564, 0.5857326984405518, 0.5140339136123657, 0.5782992839813232, 0.5726327300071716]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "FILE = \"3dmultilabel_v1.pth\"\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    spatial_dims = 3,\n",
    "    in_channels = 1,\n",
    "    out_channels = 10,\n",
    "    channels = (16, 32, 64, 128, 256),\n",
    "    strides = (2, 2, 2, 2),\n",
    "    num_res_units = 2,\n",
    "    norm = Norm.BATCH,\n",
    "    dropout = 0.5\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(main_dir, FILE)))\n",
    "\n",
    "# IoU metric\n",
    "post_pred = Compose([AsDiscrete(argmax=True, to_onehot=10)])\n",
    "post_label = Compose([AsDiscrete(to_onehot=10)])\n",
    "iou_metric = MeanIoU(include_background=False, reduction=\"mean\")\n",
    "metric_iou_values = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, val_data in enumerate(test_loader):\n",
    "        test_inputs, test_labels = (\n",
    "            val_data[\"image\"].to(device),\n",
    "            val_data[\"label\"].to(device),\n",
    "        )\n",
    "        roi_size = (176, 256, 176)\n",
    "        sw_batch_size = 4\n",
    "\n",
    "        val_outputs = sliding_window_inference(\n",
    "            test_inputs, roi_size, sw_batch_size, model\n",
    "        )\n",
    "\n",
    "        test_outputs = [post_pred(j) for j in decollate_batch(val_outputs)]\n",
    "        test_labels = [post_label(j) for j in decollate_batch(test_labels)]\n",
    "        iou_metric(y_pred=test_outputs, y=test_labels)\n",
    "        dice_metric(y_pred=test_outputs, y=test_labels)\n",
    "\n",
    "        # plot the slice [:, :, 80]\n",
    "        fig = plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f\"image {i}\")\n",
    "        plt.imshow(val_data[\"image\"][0, 0, :, :, 70], cmap=\"gray\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f\"label {i}\")\n",
    "        plt.imshow(val_data[\"label\"][0, 0, :, :, 70])\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(f\"output {i}\")\n",
    "        plt.imshow(torch.argmax(\n",
    "            val_outputs, dim=1).detach().cpu()[0, :, :, 70])\n",
    "        # print(val_outputs.shape)\n",
    "        im_result = sitk.GetImageFromArray(np.transpose(torch.argmax(val_outputs, dim=1).detach().cpu().numpy(), (3,2,1,0)))\n",
    "        if i == 0:\n",
    "            sitk.WriteImage(im_result, main_dir+'result_'+str(i)+'.nii.gz')\n",
    "        fig.suptitle('Test Monai A-Eye')\n",
    "        # plt.show()\n",
    "    \n",
    "    # aggregate the final mean dice and IoU results\n",
    "    dice_array = dice_metric.get_buffer()\n",
    "    test_metric_dice = dice_metric.aggregate().item()\n",
    "    iou_array = iou_metric.get_buffer() #(9, 10) --> 25 subjects and 10 classes\n",
    "    test_metric_iou = iou_metric.aggregate().item()\n",
    "    print(f\"Total DSC is {test_metric_dice}. \\nTotal IoU score is {test_metric_iou}.\")\n",
    "    \n",
    "    # DSC per class\n",
    "    dice_array_n = dice_array[:,:-1].transpose(0, 1) # to get in each line the IoU of each class (and eliminate NaN values of backgrounf)--> (6, 25)\n",
    "    dice_array_mean = []\n",
    "    for i, val in enumerate(dice_array_n):\n",
    "        dice_array_mean.append(torch.mean(dice_array_n[:, i]).item())\n",
    "\n",
    "    # IoU per class\n",
    "    iou_array_n = iou_array[:,:-1].transpose(0, 1) # to get in each line the IoU of each class (and eliminate NaN values of backgrounf)--> (6, 25)\n",
    "    iou_array_mean = []\n",
    "    for i, val in enumerate(iou_array_n):\n",
    "        iou_array_mean.append(torch.mean(iou_array_n[:, i]).item())\n",
    "\n",
    "    print(f\"Dice per class: {dice_array_mean}. \\nIoU per class: {iou_array_mean}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('3dmultilabel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "236677abf66ddcf33094279068f0bab187d6786b2da11104f264e332fab0dfcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
