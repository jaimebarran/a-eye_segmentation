
=============
== PyTorch ==
=============

NVIDIA Release 22.04 (build 36527063)
PyTorch Version 1.12.0a0+bd13bc6

Container image Copyright (c) 2022, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

Copyright (c) 2014-2022 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

WARNING: CUDA Minor Version Compatibility mode ENABLED.
  Using driver version 455.23.04 which has support for CUDA 11.1.  This container
  was built with CUDA 11.6 and will be run in Minor Version Compatibility mode.
  CUDA Forward Compatibility is preferred over Minor Version Compatibility for use
  with this container but was unavailable:
  [[No CUDA-capable device is detected (CUDA_ERROR_NO_DEVICE) cuInit()=100]]
  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.

NOTE: Mellanox network driver detected, but NVIDIA peer memory driver not
      detected.  Multi-node communication performance may be reduced.



Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_fullres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  9
modalities:  {0: 'T1w'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'nonCT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [5, 5, 4], 'patch_size': array([128, 160, 112]), 'median_patient_size_in_voxels': array([176, 255, 175]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 0 from these plans
I am using sample dice + CE loss

I am using data from this folder:  /opt/nnunet_resources/nnUNet_preprocessed/Task313_Eye/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2023-01-12 15:01:09.115376: Using splits from existing split file: /opt/nnunet_resources/nnUNet_preprocessed/Task313_Eye/splits_final.pkl
2023-01-12 15:01:09.138564: The split file contains 5 splits.
2023-01-12 15:01:09.138835: Desired fold for training: 0
2023-01-12 15:01:09.139087: This split has 24 training and 7 validation cases.
unpacking dataset
done
2023-01-12 15:01:14.348267: loading checkpoint /opt/nnunet_resources/nnUNet_trained_models/nnUNet/3d_fullres/Task313_Eye/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_latest.model train= True
2023-01-12 15:01:14.691270: lr: 0.000675
using pin_memory on device 0
using pin_memory on device 0
2023-01-12 15:01:40.649612: Unable to plot network architecture:
2023-01-12 15:01:40.650718: _jit_pass_onnx_unpack_quantized_weights(): incompatible function arguments. The following argument types are supported:
    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: bool) -> Dict[str, IValue]

Invoked with: graph(%input.1 : Float(1, 1, 128, 160, 112, strides=[2293760, 2293760, 17920, 112, 1], requires_grad=0, device=cuda:0),
      %1 : Float(320, 640, 3, 3, 3, strides=[17280, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %2 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %3 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %4 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %5 : Float(320, 320, 3, 3, 3, strides=[8640, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %6 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %7 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %8 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %9 : Float(256, 512, 3, 3, 3, strides=[13824, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %10 : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %11 : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %12 : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %13 : Float(256, 256, 3, 3, 3, strides=[6912, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %14 : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %15 : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %16 : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %17 : Float(128, 256, 3, 3, 3, strides=[6912, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %18 : Float(128, strides=[1], requires_grad=1, device=cuda:0),
      %19 : Float(128, strides=[1], requires_grad=1, device=cuda:0),
      %20 : Float(128, strides=[1], requires_grad=1, device=cuda:0),
      %21 : Float(128, 128, 3, 3, 3, strides=[3456, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %22 : Float(128, strides=[1], requires_grad=1, device=cuda:0),
      %23 : Float(128, strides=[1], requires_grad=1, device=cuda:0),
      %24 : Float(128, strides=[1], requires_grad=1, device=cuda:0),
      %25 : Float(64, 128, 3, 3, 3, strides=[3456, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %26 : Float(64, strides=[1], requires_grad=1, device=cuda:0),
      %27 : Float(64, strides=[1], requires_grad=1, device=cuda:0),
      %28 : Float(64, strides=[1], requires_grad=1, device=cuda:0),
      %29 : Float(64, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %30 : Float(64, strides=[1], requires_grad=1, device=cuda:0),
      %31 : Float(64, strides=[1], requires_grad=1, device=cuda:0),
      %32 : Float(64, strides=[1], requires_grad=1, device=cuda:0),
      %33 : Float(32, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %34 : Float(32, strides=[1], requires_grad=1, device=cuda:0),
      %35 : Float(32, strides=[1], requires_grad=1, device=cuda:0),
      %36 : Float(32, strides=[1], requires_grad=1, device=cuda:0),
      %37 : Float(32, 32, 3, 3, 3, strides=[864, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %38 : Float(32, strides=[1], requires_grad=1, device=cuda:0),
      %39 : Float(32, strides=[1], requires_grad=1, device=cuda:0),
      %40 : Float(32, strides=[1], requires_grad=1, device=cuda:0),
      %41 : Float(32, 1, 3, 3, 3, strides=[27, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %42 : Float(32, strides=[1], requires_grad=1, device=cuda:0),
      %43 : Float(32, strides=[1], requires_grad=1, device=cuda:0),
      %44 : Float(32, strides=[1], requires_grad=1, device=cuda:0),
      %45 : Float(32, 32, 3, 3, 3, strides=[864, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %46 : Float(32, strides=[1], requires_grad=1, device=cuda:0),
      %47 : Float(32, strides=[1], requires_grad=1, device=cuda:0),
      %48 : Float(32, strides=[1], requires_grad=1, device=cuda:0),
      %49 : Float(64, 32, 3, 3, 3, strides=[864, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %50 : Float(64, strides=[1], requires_grad=1, device=cuda:0),
      %51 : Float(64, strides=[1], requires_grad=1, device=cuda:0),
      %52 : Float(64, strides=[1], requires_grad=1, device=cuda:0),
      %53 : Float(64, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %54 : Float(64, strides=[1], requires_grad=1, device=cuda:0),
      %55 : Float(64, strides=[1], requires_grad=1, device=cuda:0),
      %56 : Float(64, strides=[1], requires_grad=1, device=cuda:0),
      %57 : Float(128, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %58 : Float(128, strides=[1], requires_grad=1, device=cuda:0),
      %59 : Float(128, strides=[1], requires_grad=1, device=cuda:0),
      %60 : Float(128, strides=[1], requires_grad=1, device=cuda:0),
      %61 : Float(128, 128, 3, 3, 3, strides=[3456, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %62 : Float(128, strides=[1], requires_grad=1, device=cuda:0),
      %63 : Float(128, strides=[1], requires_grad=1, device=cuda:0),
      %64 : Float(128, strides=[1], requires_grad=1, device=cuda:0),
      %65 : Float(256, 128, 3, 3, 3, strides=[3456, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %66 : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %67 : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %68 : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %69 : Float(256, 256, 3, 3, 3, strides=[6912, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %70 : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %71 : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %72 : Float(256, strides=[1], requires_grad=1, device=cuda:0),
      %73 : Float(320, 256, 3, 3, 3, strides=[6912, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %74 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %75 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %76 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %77 : Float(320, 320, 3, 3, 3, strides=[8640, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %78 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %79 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %80 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %81 : Float(320, 320, 3, 3, 3, strides=[8640, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %82 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %83 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %84 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %85 : Float(320, 320, 3, 3, 3, strides=[8640, 27, 9, 3, 1], requires_grad=1, device=cuda:0),
      %86 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %87 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %88 : Float(320, strides=[1], requires_grad=1, device=cuda:0),
      %89 : Float(320, 320, 2, 2, 1, strides=[1280, 4, 2, 1, 1], requires_grad=1, device=cuda:0),
      %90 : Float(320, 256, 2, 2, 2, strides=[2048, 8, 4, 2, 1], requires_grad=1, device=cuda:0),
      %91 : Float(256, 128, 2, 2, 2, strides=[1024, 8, 4, 2, 1], requires_grad=1, device=cuda:0),
      %92 : Float(128, 64, 2, 2, 2, strides=[512, 8, 4, 2, 1], requires_grad=1, device=cuda:0),
      %93 : Float(64, 32, 2, 2, 2, strides=[256, 8, 4, 2, 1], requires_grad=1, device=cuda:0),
      %94 : Float(10, 320, 1, 1, 1, strides=[320, 1, 1, 1, 1], requires_grad=1, device=cuda:0),
      %95 : Float(10, 256, 1, 1, 1, strides=[256, 1, 1, 1, 1], requires_grad=1, device=cuda:0),
      %96 : Float(10, 128, 1, 1, 1, strides=[128, 1, 1, 1, 1], requires_grad=1, device=cuda:0),
      %97 : Float(10, 64, 1, 1, 1, strides=[64, 1, 1, 1, 1], requires_grad=1, device=cuda:0),
      %98 : Float(10, 32, 1, 1, 1, strides=[32, 1, 1, 1, 1], requires_grad=1, device=cuda:0)):
  %1719 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1720 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1721 : int[] = prim::Constant[value=[1, 1, 1]]()
  %309 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1722 : int[] = prim::Constant[value=[0, 0, 0]]()
  %314 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %315 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %316 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %317 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %318 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.3 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%input.1, %41, %42, %1719, %1720, %1721, %309, %1722, %314, %315, %316, %317, %318) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %341 : NoneType = prim::Constant()
  %342 : NoneType = prim::Constant()
  %343 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %344 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %345 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %346 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %348 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.5 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.3, %43, %44, %341, %342, %343, %344, %345, %346) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1847 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.5, %348) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1723 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1724 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1725 : int[] = prim::Constant[value=[1, 1, 1]]()
  %362 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1726 : int[] = prim::Constant[value=[0, 0, 0]]()
  %367 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %368 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %369 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %370 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %371 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.9 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1847, %45, %46, %1723, %1724, %1725, %362, %1726, %367, %368, %369, %370, %371) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %394 : NoneType = prim::Constant()
  %395 : NoneType = prim::Constant()
  %396 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %397 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %398 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %399 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %401 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.11 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.9, %47, %48, %394, %395, %396, %397, %398, %399) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1848 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.11, %401) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1727 : int[] = prim::Constant[value=[2, 2, 2]]()
  %1728 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1729 : int[] = prim::Constant[value=[1, 1, 1]]()
  %415 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1730 : int[] = prim::Constant[value=[0, 0, 0]]()
  %420 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %421 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %422 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %423 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %424 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.15 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1848, %49, %50, %1727, %1728, %1729, %415, %1730, %420, %421, %422, %423, %424) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %447 : NoneType = prim::Constant()
  %448 : NoneType = prim::Constant()
  %449 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %450 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %451 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %452 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %454 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.17 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.15, %51, %52, %447, %448, %449, %450, %451, %452) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1849 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.17, %454) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1731 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1732 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1733 : int[] = prim::Constant[value=[1, 1, 1]]()
  %468 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1734 : int[] = prim::Constant[value=[0, 0, 0]]()
  %473 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %474 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %475 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %476 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %477 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.21 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1849, %53, %54, %1731, %1732, %1733, %468, %1734, %473, %474, %475, %476, %477) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %500 : NoneType = prim::Constant()
  %501 : NoneType = prim::Constant()
  %502 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %503 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %504 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %505 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %507 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.23 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.21, %55, %56, %500, %501, %502, %503, %504, %505) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1850 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.23, %507) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1735 : int[] = prim::Constant[value=[2, 2, 2]]()
  %1736 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1737 : int[] = prim::Constant[value=[1, 1, 1]]()
  %521 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1738 : int[] = prim::Constant[value=[0, 0, 0]]()
  %526 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %527 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %528 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %529 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %530 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.27 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1850, %57, %58, %1735, %1736, %1737, %521, %1738, %526, %527, %528, %529, %530) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %553 : NoneType = prim::Constant()
  %554 : NoneType = prim::Constant()
  %555 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %556 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %557 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %558 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %560 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.29 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.27, %59, %60, %553, %554, %555, %556, %557, %558) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1851 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.29, %560) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1739 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1740 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1741 : int[] = prim::Constant[value=[1, 1, 1]]()
  %574 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1742 : int[] = prim::Constant[value=[0, 0, 0]]()
  %579 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %580 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %581 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %582 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %583 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.33 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1851, %61, %62, %1739, %1740, %1741, %574, %1742, %579, %580, %581, %582, %583) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %606 : NoneType = prim::Constant()
  %607 : NoneType = prim::Constant()
  %608 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %609 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %610 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %611 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %613 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.35 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.33, %63, %64, %606, %607, %608, %609, %610, %611) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1852 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.35, %613) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1743 : int[] = prim::Constant[value=[2, 2, 2]]()
  %1744 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1745 : int[] = prim::Constant[value=[1, 1, 1]]()
  %627 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1746 : int[] = prim::Constant[value=[0, 0, 0]]()
  %632 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %633 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %634 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %635 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %636 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.39 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1852, %65, %66, %1743, %1744, %1745, %627, %1746, %632, %633, %634, %635, %636) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %659 : NoneType = prim::Constant()
  %660 : NoneType = prim::Constant()
  %661 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %662 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %663 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %664 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %666 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.41 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.39, %67, %68, %659, %660, %661, %662, %663, %664) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1853 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.41, %666) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1747 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1748 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1749 : int[] = prim::Constant[value=[1, 1, 1]]()
  %680 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1750 : int[] = prim::Constant[value=[0, 0, 0]]()
  %685 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %686 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %687 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %688 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %689 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.45 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1853, %69, %70, %1747, %1748, %1749, %680, %1750, %685, %686, %687, %688, %689) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %712 : NoneType = prim::Constant()
  %713 : NoneType = prim::Constant()
  %714 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %715 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %716 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %717 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %719 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.47 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.45, %71, %72, %712, %713, %714, %715, %716, %717) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1854 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.47, %719) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1751 : int[] = prim::Constant[value=[2, 2, 2]]()
  %1752 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1753 : int[] = prim::Constant[value=[1, 1, 1]]()
  %733 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1754 : int[] = prim::Constant[value=[0, 0, 0]]()
  %738 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %739 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %740 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %741 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %742 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.51 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1854, %73, %74, %1751, %1752, %1753, %733, %1754, %738, %739, %740, %741, %742) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %765 : NoneType = prim::Constant()
  %766 : NoneType = prim::Constant()
  %767 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %768 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %769 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %770 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %772 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.53 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.51, %75, %76, %765, %766, %767, %768, %769, %770) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1855 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.53, %772) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1755 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1756 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1757 : int[] = prim::Constant[value=[1, 1, 1]]()
  %786 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1758 : int[] = prim::Constant[value=[0, 0, 0]]()
  %791 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %792 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %793 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %794 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %795 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.57 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1855, %77, %78, %1755, %1756, %1757, %786, %1758, %791, %792, %793, %794, %795) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %818 : NoneType = prim::Constant()
  %819 : NoneType = prim::Constant()
  %820 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %821 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %822 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %823 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %825 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.59 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.57, %79, %80, %818, %819, %820, %821, %822, %823) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1856 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.59, %825) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1759 : int[] = prim::Constant[value=[2, 2, 1]]()
  %1760 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1761 : int[] = prim::Constant[value=[1, 1, 1]]()
  %839 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1762 : int[] = prim::Constant[value=[0, 0, 0]]()
  %844 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %845 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %846 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %847 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %848 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.63 : Float(1, 320, 4, 5, 7, strides=[44800, 140, 35, 7, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1856, %81, %82, %1759, %1760, %1761, %839, %1762, %844, %845, %846, %847, %848) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %871 : NoneType = prim::Constant()
  %872 : NoneType = prim::Constant()
  %873 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %874 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %875 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %876 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %878 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.65 : Float(1, 320, 4, 5, 7, strides=[44800, 140, 35, 7, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.63, %83, %84, %871, %872, %873, %874, %875, %876) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1857 : Float(1, 320, 4, 5, 7, strides=[44800, 140, 35, 7, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.65, %878) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1763 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1764 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1765 : int[] = prim::Constant[value=[1, 1, 1]]()
  %892 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1766 : int[] = prim::Constant[value=[0, 0, 0]]()
  %897 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %898 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %899 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %900 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %901 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.69 : Float(1, 320, 4, 5, 7, strides=[44800, 140, 35, 7, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1857, %85, %86, %1763, %1764, %1765, %892, %1766, %897, %898, %899, %900, %901) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %924 : NoneType = prim::Constant()
  %925 : NoneType = prim::Constant()
  %926 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %927 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %928 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %929 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %931 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.71 : Float(1, 320, 4, 5, 7, strides=[44800, 140, 35, 7, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.69, %87, %88, %924, %925, %926, %927, %928, %929) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1858 : Float(1, 320, 4, 5, 7, strides=[44800, 140, 35, 7, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.71, %931) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %933 : NoneType = prim::Constant()
  %1767 : int[] = prim::Constant[value=[2, 2, 1]]()
  %1768 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1769 : int[] = prim::Constant[value=[1, 1, 1]]()
  %946 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1770 : int[] = prim::Constant[value=[0, 0, 0]]()
  %951 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %952 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %953 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %954 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %955 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %956 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1858, %89, %933, %1767, %1768, %1769, %946, %1770, %951, %952, %953, %954, %955) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %957 : Tensor[] = prim::ListConstruct(%956, %1856)
  %958 : int = prim::Constant[value=1]() # /nnunet/nnunet/network_architecture/generic_UNet.py:400:0
  %input.73 : Float(1, 640, 8, 10, 7, strides=[358400, 560, 70, 7, 1], requires_grad=1, device=cuda:0) = aten::cat(%957, %958) # /nnunet/nnunet/network_architecture/generic_UNet.py:400:0
  %1771 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1772 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1773 : int[] = prim::Constant[value=[1, 1, 1]]()
  %972 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1774 : int[] = prim::Constant[value=[0, 0, 0]]()
  %977 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %978 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %979 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %980 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %981 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.75 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%input.73, %1, %2, %1771, %1772, %1773, %972, %1774, %977, %978, %979, %980, %981) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1004 : NoneType = prim::Constant()
  %1005 : NoneType = prim::Constant()
  %1006 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1007 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1008 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1009 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1011 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.77 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.75, %3, %4, %1004, %1005, %1006, %1007, %1008, %1009) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1859 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.77, %1011) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1775 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1776 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1777 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1025 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1778 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1030 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1031 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1032 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1033 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1034 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.81 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1859, %5, %6, %1775, %1776, %1777, %1025, %1778, %1030, %1031, %1032, %1033, %1034) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1057 : NoneType = prim::Constant()
  %1058 : NoneType = prim::Constant()
  %1059 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1060 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1061 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1062 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1064 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.83 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.81, %7, %8, %1057, %1058, %1059, %1060, %1061, %1062) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1860 : Float(1, 320, 8, 10, 7, strides=[179200, 560, 70, 7, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.83, %1064) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1066 : NoneType = prim::Constant()
  %1779 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1780 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1781 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1079 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1782 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1084 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1085 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1086 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1087 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1088 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1089 : Float(1, 10, 8, 10, 7, strides=[5600, 560, 70, 7, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1860, %94, %1066, %1779, %1780, %1781, %1079, %1782, %1084, %1085, %1086, %1087, %1088) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1090 : NoneType = prim::Constant()
  %1783 : int[] = prim::Constant[value=[2, 2, 2]]()
  %1784 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1785 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1103 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1786 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1108 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1109 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1110 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1111 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1112 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1113 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1860, %90, %1090, %1783, %1784, %1785, %1103, %1786, %1108, %1109, %1110, %1111, %1112) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1114 : Tensor[] = prim::ListConstruct(%1113, %1854)
  %1115 : int = prim::Constant[value=1]() # /nnunet/nnunet/network_architecture/generic_UNet.py:400:0
  %input.87 : Float(1, 512, 16, 20, 14, strides=[2293760, 4480, 280, 14, 1], requires_grad=1, device=cuda:0) = aten::cat(%1114, %1115) # /nnunet/nnunet/network_architecture/generic_UNet.py:400:0
  %1787 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1788 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1789 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1129 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1790 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1134 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1135 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1136 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1137 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1138 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.89 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%input.87, %9, %10, %1787, %1788, %1789, %1129, %1790, %1134, %1135, %1136, %1137, %1138) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1161 : NoneType = prim::Constant()
  %1162 : NoneType = prim::Constant()
  %1163 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1164 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1165 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1166 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1168 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.91 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.89, %11, %12, %1161, %1162, %1163, %1164, %1165, %1166) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1861 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.91, %1168) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1791 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1792 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1793 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1182 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1794 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1187 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1188 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1189 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1190 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1191 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.95 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1861, %13, %14, %1791, %1792, %1793, %1182, %1794, %1187, %1188, %1189, %1190, %1191) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1214 : NoneType = prim::Constant()
  %1215 : NoneType = prim::Constant()
  %1216 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1217 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1218 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1219 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1221 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.97 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.95, %15, %16, %1214, %1215, %1216, %1217, %1218, %1219) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1862 : Float(1, 256, 16, 20, 14, strides=[1146880, 4480, 280, 14, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.97, %1221) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1223 : NoneType = prim::Constant()
  %1795 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1796 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1797 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1236 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1798 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1241 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1242 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1243 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1244 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1245 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1246 : Float(1, 10, 16, 20, 14, strides=[44800, 4480, 280, 14, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1862, %95, %1223, %1795, %1796, %1797, %1236, %1798, %1241, %1242, %1243, %1244, %1245) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1247 : NoneType = prim::Constant()
  %1799 : int[] = prim::Constant[value=[2, 2, 2]]()
  %1800 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1801 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1260 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1802 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1265 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1266 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1267 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1268 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1269 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1270 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1862, %91, %1247, %1799, %1800, %1801, %1260, %1802, %1265, %1266, %1267, %1268, %1269) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1271 : Tensor[] = prim::ListConstruct(%1270, %1852)
  %1272 : int = prim::Constant[value=1]() # /nnunet/nnunet/network_architecture/generic_UNet.py:400:0
  %input.101 : Float(1, 256, 32, 40, 28, strides=[9175040, 35840, 1120, 28, 1], requires_grad=1, device=cuda:0) = aten::cat(%1271, %1272) # /nnunet/nnunet/network_architecture/generic_UNet.py:400:0
  %1803 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1804 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1805 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1286 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1806 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1291 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1292 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1293 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1294 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1295 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.103 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%input.101, %17, %18, %1803, %1804, %1805, %1286, %1806, %1291, %1292, %1293, %1294, %1295) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1318 : NoneType = prim::Constant()
  %1319 : NoneType = prim::Constant()
  %1320 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1321 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1322 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1323 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1325 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.105 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.103, %19, %20, %1318, %1319, %1320, %1321, %1322, %1323) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1863 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.105, %1325) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1807 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1808 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1809 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1339 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1810 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1344 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1345 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1346 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1347 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1348 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.109 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1863, %21, %22, %1807, %1808, %1809, %1339, %1810, %1344, %1345, %1346, %1347, %1348) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1371 : NoneType = prim::Constant()
  %1372 : NoneType = prim::Constant()
  %1373 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1374 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1375 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1376 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1378 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.111 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.109, %23, %24, %1371, %1372, %1373, %1374, %1375, %1376) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1864 : Float(1, 128, 32, 40, 28, strides=[4587520, 35840, 1120, 28, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.111, %1378) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1380 : NoneType = prim::Constant()
  %1811 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1812 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1813 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1393 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1814 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1398 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1399 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1400 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1401 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1402 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1403 : Float(1, 10, 32, 40, 28, strides=[358400, 35840, 1120, 28, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1864, %96, %1380, %1811, %1812, %1813, %1393, %1814, %1398, %1399, %1400, %1401, %1402) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1404 : NoneType = prim::Constant()
  %1815 : int[] = prim::Constant[value=[2, 2, 2]]()
  %1816 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1817 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1417 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1818 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1422 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1423 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1424 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1425 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1426 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1427 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1864, %92, %1404, %1815, %1816, %1817, %1417, %1818, %1422, %1423, %1424, %1425, %1426) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1428 : Tensor[] = prim::ListConstruct(%1427, %1850)
  %1429 : int = prim::Constant[value=1]() # /nnunet/nnunet/network_architecture/generic_UNet.py:400:0
  %input.115 : Float(1, 128, 64, 80, 56, strides=[36700160, 286720, 4480, 56, 1], requires_grad=1, device=cuda:0) = aten::cat(%1428, %1429) # /nnunet/nnunet/network_architecture/generic_UNet.py:400:0
  %1819 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1820 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1821 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1443 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1822 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1448 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1449 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1450 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1451 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1452 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.117 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%input.115, %25, %26, %1819, %1820, %1821, %1443, %1822, %1448, %1449, %1450, %1451, %1452) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1475 : NoneType = prim::Constant()
  %1476 : NoneType = prim::Constant()
  %1477 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1478 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1479 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1480 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1482 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.119 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.117, %27, %28, %1475, %1476, %1477, %1478, %1479, %1480) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1865 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.119, %1482) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1823 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1824 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1825 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1496 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1826 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1501 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1502 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1503 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1504 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1505 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.123 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1865, %29, %30, %1823, %1824, %1825, %1496, %1826, %1501, %1502, %1503, %1504, %1505) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1528 : NoneType = prim::Constant()
  %1529 : NoneType = prim::Constant()
  %1530 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1531 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1532 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1533 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1535 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.125 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.123, %31, %32, %1528, %1529, %1530, %1531, %1532, %1533) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1866 : Float(1, 64, 64, 80, 56, strides=[18350080, 286720, 4480, 56, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.125, %1535) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1537 : NoneType = prim::Constant()
  %1827 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1828 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1829 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1550 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1830 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1555 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1556 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1557 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1558 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1559 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1560 : Float(1, 10, 64, 80, 56, strides=[2867200, 286720, 4480, 56, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1866, %97, %1537, %1827, %1828, %1829, %1550, %1830, %1555, %1556, %1557, %1558, %1559) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1561 : NoneType = prim::Constant()
  %1831 : int[] = prim::Constant[value=[2, 2, 2]]()
  %1832 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1833 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1574 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1834 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1579 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1580 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1581 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1582 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1583 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1584 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1866, %93, %1561, %1831, %1832, %1833, %1574, %1834, %1579, %1580, %1581, %1582, %1583) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1073:0
  %1585 : Tensor[] = prim::ListConstruct(%1584, %1848)
  %1586 : int = prim::Constant[value=1]() # /nnunet/nnunet/network_architecture/generic_UNet.py:400:0
  %input.129 : Float(1, 64, 128, 160, 112, strides=[146800640, 2293760, 17920, 112, 1], requires_grad=1, device=cuda:0) = aten::cat(%1585, %1586) # /nnunet/nnunet/network_architecture/generic_UNet.py:400:0
  %1835 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1836 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1837 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1600 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1838 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1605 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1606 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1607 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1608 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1609 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.131 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%input.129, %33, %34, %1835, %1836, %1837, %1600, %1838, %1605, %1606, %1607, %1608, %1609) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1632 : NoneType = prim::Constant()
  %1633 : NoneType = prim::Constant()
  %1634 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1635 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1636 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1637 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1639 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.133 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.131, %35, %36, %1632, %1633, %1634, %1635, %1636, %1637) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1867 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.133, %1639) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1839 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1840 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1841 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1653 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1842 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1658 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1659 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1660 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1661 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1662 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %input.137 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1867, %37, %38, %1839, %1840, %1841, %1653, %1842, %1658, %1659, %1660, %1661, %1662) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1685 : NoneType = prim::Constant()
  %1686 : NoneType = prim::Constant()
  %1687 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1688 : float = prim::Constant[value=0.10000000000000001]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1689 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1690 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1692 : float = prim::Constant[value=0.01]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %input.139 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=1, device=cuda:0) = aten::instance_norm(%input.137, %39, %40, %1685, %1686, %1687, %1688, %1689, %1690) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2431:0
  %1868 : Float(1, 32, 128, 160, 112, strides=[73400320, 2293760, 17920, 112, 1], requires_grad=1, device=cuda:0) = aten::leaky_relu(%input.139, %1692) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1580:0
  %1694 : NoneType = prim::Constant()
  %1843 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1844 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1845 : int[] = prim::Constant[value=[1, 1, 1]]()
  %1707 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1846 : int[] = prim::Constant[value=[0, 0, 0]]()
  %1712 : int = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1713 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1714 : bool = prim::Constant[value=0]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1715 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1716 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  %1717 : Float(1, 10, 128, 160, 112, strides=[22937600, 2293760, 17920, 112, 1], requires_grad=0, device=cuda:0) = aten::_convolution(%1868, %98, %1694, %1843, %1844, %1845, %1707, %1846, %1712, %1713, %1714, %1715, %1716) # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:587:0
  return (%1717, %1560, %1403, %1246, %1089)
, None, False
2023-01-12 15:01:40.651431: 
printing the network instead:

2023-01-12 15:01:40.651791: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 1), stride=(2, 2, 1), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 10, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2023-01-12 15:01:40.654299: 

2023-01-12 15:01:40.708704: 
epoch:  950
2023-01-12 15:04:25.430302: train loss : -0.8649
2023-01-12 15:04:37.567417: validation loss: -0.8349
2023-01-12 15:04:37.588010: Average global foreground Dice: [0.8926, 0.9577, 0.8803, 0.8206, 0.7683, 0.8786, 0.9058, 0.8867, 0.8296]
2023-01-12 15:04:37.591420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:04:39.654017: lr: 0.000662
2023-01-12 15:04:39.888597: saving checkpoint...
2023-01-12 15:04:41.741185: done, saving took 2.09 seconds
2023-01-12 15:04:41.813682: This epoch took 181.103239 s

2023-01-12 15:04:41.814292: 
epoch:  951
2023-01-12 15:07:28.066589: train loss : -0.8658
2023-01-12 15:07:39.715830: validation loss: -0.8310
2023-01-12 15:07:39.736035: Average global foreground Dice: [0.8933, 0.9564, 0.8715, 0.8134, 0.758, 0.8717, 0.9051, 0.884, 0.8299]
2023-01-12 15:07:39.736833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:07:41.447790: lr: 0.00065
2023-01-12 15:07:41.448802: This epoch took 179.634100 s

2023-01-12 15:07:41.449312: 
epoch:  952
2023-01-12 15:10:07.807397: train loss : -0.8719
2023-01-12 15:10:19.556310: validation loss: -0.8322
2023-01-12 15:10:19.568599: Average global foreground Dice: [0.8915, 0.9574, 0.8742, 0.8206, 0.7657, 0.8739, 0.9044, 0.8838, 0.8138]
2023-01-12 15:10:19.577732: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:10:21.115737: lr: 0.000638
2023-01-12 15:10:21.116837: This epoch took 159.662819 s

2023-01-12 15:10:21.117215: 
epoch:  953
2023-01-12 15:12:58.791719: train loss : -0.8699
2023-01-12 15:13:10.111078: validation loss: -0.8224
2023-01-12 15:13:10.116950: Average global foreground Dice: [0.8781, 0.9535, 0.871, 0.8104, 0.7672, 0.8713, 0.8914, 0.8844, 0.8168]
2023-01-12 15:13:10.117592: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:13:11.787252: lr: 0.000626
2023-01-12 15:13:11.788255: This epoch took 170.670705 s

2023-01-12 15:13:11.788737: 
epoch:  954
2023-01-12 15:16:01.147234: train loss : -0.8661
2023-01-12 15:16:12.243592: validation loss: -0.8343
2023-01-12 15:16:12.245445: Average global foreground Dice: [0.8868, 0.9571, 0.8761, 0.8216, 0.7629, 0.871, 0.898, 0.8817, 0.8198]
2023-01-12 15:16:12.246069: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:16:13.127805: lr: 0.000614
2023-01-12 15:16:13.130479: This epoch took 181.341422 s

2023-01-12 15:16:13.130808: 
epoch:  955
2023-01-12 15:18:53.511846: train loss : -0.8708
2023-01-12 15:19:06.190363: validation loss: -0.8265
2023-01-12 15:19:06.206642: Average global foreground Dice: [0.9006, 0.9597, 0.8697, 0.8093, 0.7683, 0.8697, 0.8997, 0.8851, 0.8081]
2023-01-12 15:19:06.207457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:19:08.109251: lr: 0.000601
2023-01-12 15:19:08.110018: This epoch took 174.978901 s

2023-01-12 15:19:08.110383: 
epoch:  956
2023-01-12 15:21:52.983545: train loss : -0.8699
2023-01-12 15:22:04.646976: validation loss: -0.8318
2023-01-12 15:22:04.660717: Average global foreground Dice: [0.8979, 0.9585, 0.8734, 0.8147, 0.7707, 0.873, 0.8875, 0.8862, 0.8172]
2023-01-12 15:22:04.661265: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:22:06.330142: lr: 0.000589
2023-01-12 15:22:06.331146: This epoch took 178.220337 s

2023-01-12 15:22:06.331641: 
epoch:  957
2023-01-12 15:24:47.679237: train loss : -0.8696
2023-01-12 15:24:59.875659: validation loss: -0.8290
2023-01-12 15:24:59.877553: Average global foreground Dice: [0.8881, 0.9568, 0.8742, 0.8124, 0.7615, 0.8674, 0.8965, 0.883, 0.8146]
2023-01-12 15:24:59.878432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:25:01.543932: lr: 0.000577
2023-01-12 15:25:01.545144: This epoch took 175.213166 s

2023-01-12 15:25:01.545456: 
epoch:  958
2023-01-12 15:27:39.021816: train loss : -0.8693
2023-01-12 15:27:51.202291: validation loss: -0.8320
2023-01-12 15:27:51.214433: Average global foreground Dice: [0.8925, 0.961, 0.8732, 0.8245, 0.7729, 0.8725, 0.9063, 0.8844, 0.8116]
2023-01-12 15:27:51.214965: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:27:52.902149: lr: 0.000564
2023-01-12 15:27:52.907801: This epoch took 171.362057 s

2023-01-12 15:27:52.908507: 
epoch:  959
2023-01-12 15:30:36.026233: train loss : -0.8669
2023-01-12 15:30:48.051454: validation loss: -0.8310
2023-01-12 15:30:48.061740: Average global foreground Dice: [0.8916, 0.9551, 0.8768, 0.807, 0.7589, 0.8678, 0.8919, 0.8836, 0.8137]
2023-01-12 15:30:48.062820: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:30:49.927499: lr: 0.000552
2023-01-12 15:30:49.938209: This epoch took 177.029233 s

2023-01-12 15:30:49.938794: 
epoch:  960
2023-01-12 15:33:13.685153: train loss : -0.8741
2023-01-12 15:33:25.040029: validation loss: -0.8266
2023-01-12 15:33:25.041629: Average global foreground Dice: [0.8945, 0.9555, 0.8707, 0.7933, 0.7554, 0.8663, 0.899, 0.8827, 0.8215]
2023-01-12 15:33:25.042260: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:33:26.690243: lr: 0.000539
2023-01-12 15:33:26.691123: This epoch took 156.751981 s

2023-01-12 15:33:26.691564: 
epoch:  961
2023-01-12 15:36:13.474259: train loss : -0.8666
2023-01-12 15:36:25.093852: validation loss: -0.8380
2023-01-12 15:36:25.110020: Average global foreground Dice: [0.8991, 0.9574, 0.8786, 0.8192, 0.7822, 0.8735, 0.9015, 0.8908, 0.819]
2023-01-12 15:36:25.120251: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:36:26.699934: lr: 0.000527
2023-01-12 15:36:26.700800: This epoch took 180.008945 s

2023-01-12 15:36:26.701195: 
epoch:  962
2023-01-12 15:39:17.159937: train loss : -0.8662
2023-01-12 15:39:28.693398: validation loss: -0.8294
2023-01-12 15:39:28.695745: Average global foreground Dice: [0.8955, 0.953, 0.8744, 0.8198, 0.7672, 0.8722, 0.8975, 0.8902, 0.8072]
2023-01-12 15:39:28.698869: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:39:30.649849: lr: 0.000514
2023-01-12 15:39:30.650575: This epoch took 183.948957 s

2023-01-12 15:39:30.657438: 
epoch:  963
2023-01-12 15:42:10.854908: train loss : -0.8675
2023-01-12 15:42:21.634823: validation loss: -0.8380
2023-01-12 15:42:21.644464: Average global foreground Dice: [0.8995, 0.9595, 0.8785, 0.8236, 0.7823, 0.8756, 0.9056, 0.889, 0.8148]
2023-01-12 15:42:21.645520: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:42:23.442163: lr: 0.000502
2023-01-12 15:42:23.454811: This epoch took 172.796738 s

2023-01-12 15:42:23.455476: 
epoch:  964
2023-01-12 15:45:05.391109: train loss : -0.8679
2023-01-12 15:45:16.636305: validation loss: -0.8313
2023-01-12 15:45:16.648620: Average global foreground Dice: [0.8938, 0.9554, 0.8727, 0.8157, 0.767, 0.869, 0.9007, 0.8842, 0.8128]
2023-01-12 15:45:16.649371: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:45:18.357252: lr: 0.000489
2023-01-12 15:45:18.358125: This epoch took 174.902099 s

2023-01-12 15:45:18.358542: 
epoch:  965
2023-01-12 15:48:02.499832: train loss : -0.8699
2023-01-12 15:48:14.174645: validation loss: -0.8342
2023-01-12 15:48:14.209026: Average global foreground Dice: [0.8971, 0.9564, 0.8774, 0.8196, 0.7734, 0.8721, 0.8976, 0.8877, 0.8163]
2023-01-12 15:48:14.209882: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:48:16.259979: lr: 0.000477
2023-01-12 15:48:16.281171: This epoch took 177.922328 s

2023-01-12 15:48:16.290147: 
epoch:  966
2023-01-12 15:51:12.258276: train loss : -0.8661
2023-01-12 15:51:23.964210: validation loss: -0.8310
2023-01-12 15:51:23.966335: Average global foreground Dice: [0.897, 0.9575, 0.8822, 0.815, 0.7829, 0.8755, 0.8913, 0.8827, 0.8178]
2023-01-12 15:51:23.983930: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:51:25.859585: lr: 0.000464
2023-01-12 15:51:25.860418: This epoch took 189.569543 s

2023-01-12 15:51:25.860879: 
epoch:  967
2023-01-12 15:54:07.905697: train loss : -0.8746
2023-01-12 15:54:19.419115: validation loss: -0.8285
2023-01-12 15:54:19.434396: Average global foreground Dice: [0.884, 0.9559, 0.8716, 0.8198, 0.7675, 0.8693, 0.9045, 0.8811, 0.8155]
2023-01-12 15:54:19.435166: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:54:21.008538: lr: 0.000451
2023-01-12 15:54:21.009197: This epoch took 175.148021 s

2023-01-12 15:54:21.009547: 
epoch:  968
2023-01-12 15:57:01.483492: train loss : -0.8733
2023-01-12 15:57:13.343682: validation loss: -0.8308
2023-01-12 15:57:13.345460: Average global foreground Dice: [0.896, 0.9587, 0.8737, 0.8151, 0.7761, 0.8738, 0.898, 0.8902, 0.8174]
2023-01-12 15:57:13.345968: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 15:57:14.611852: lr: 0.000439
2023-01-12 15:57:14.614898: This epoch took 173.605043 s

2023-01-12 15:57:14.615255: 
epoch:  969
2023-01-12 15:59:54.656241: train loss : -0.8724
2023-01-12 16:00:07.570941: validation loss: -0.8319
2023-01-12 16:00:07.592192: Average global foreground Dice: [0.8941, 0.9576, 0.8754, 0.8159, 0.7629, 0.8721, 0.8982, 0.8893, 0.8107]
2023-01-12 16:00:07.592993: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:00:09.448569: lr: 0.000426
2023-01-12 16:00:09.449281: This epoch took 174.833723 s

2023-01-12 16:00:09.449865: 
epoch:  970
2023-01-12 16:02:54.086200: train loss : -0.8670
2023-01-12 16:03:05.892949: validation loss: -0.8357
2023-01-12 16:03:05.903877: Average global foreground Dice: [0.8927, 0.9556, 0.8765, 0.815, 0.768, 0.8699, 0.9022, 0.8868, 0.8216]
2023-01-12 16:03:05.905539: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:03:07.532997: lr: 0.000413
2023-01-12 16:03:07.533857: This epoch took 178.083615 s

2023-01-12 16:03:07.534376: 
epoch:  971
2023-01-12 16:05:48.592278: train loss : -0.8679
2023-01-12 16:06:00.693697: validation loss: -0.8308
2023-01-12 16:06:00.695393: Average global foreground Dice: [0.8948, 0.9578, 0.8747, 0.8191, 0.7707, 0.8714, 0.9051, 0.8885, 0.8254]
2023-01-12 16:06:00.695993: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:06:02.886111: lr: 0.0004
2023-01-12 16:06:02.886945: This epoch took 175.352276 s

2023-01-12 16:06:02.887517: 
epoch:  972
2023-01-12 16:08:44.055439: train loss : -0.8654
2023-01-12 16:08:55.494859: validation loss: -0.8331
2023-01-12 16:08:55.512969: Average global foreground Dice: [0.8945, 0.9542, 0.8768, 0.8126, 0.7694, 0.8691, 0.9044, 0.8913, 0.8127]
2023-01-12 16:08:55.513898: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:08:57.388890: lr: 0.000387
2023-01-12 16:08:57.389917: This epoch took 174.502051 s

2023-01-12 16:08:57.390361: 
epoch:  973
2023-01-12 16:11:40.108007: train loss : -0.8682
2023-01-12 16:11:52.309286: validation loss: -0.8369
2023-01-12 16:11:52.313601: Average global foreground Dice: [0.8879, 0.9552, 0.8772, 0.8075, 0.7706, 0.8742, 0.9053, 0.8888, 0.8394]
2023-01-12 16:11:52.314252: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:11:54.135106: lr: 0.000375
2023-01-12 16:11:54.136740: This epoch took 176.746052 s

2023-01-12 16:11:54.138212: 
epoch:  974
2023-01-12 16:14:30.642164: train loss : -0.8702
2023-01-12 16:14:42.949598: validation loss: -0.8324
2023-01-12 16:14:42.957987: Average global foreground Dice: [0.8916, 0.9567, 0.8737, 0.8236, 0.7702, 0.8732, 0.903, 0.8853, 0.8188]
2023-01-12 16:14:42.963431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:14:45.151249: lr: 0.000362
2023-01-12 16:14:45.152082: This epoch took 171.012420 s

2023-01-12 16:14:45.152519: 
epoch:  975
2023-01-12 16:17:31.487993: train loss : -0.8730
2023-01-12 16:17:43.098356: validation loss: -0.8341
2023-01-12 16:17:43.116924: Average global foreground Dice: [0.8961, 0.9562, 0.8767, 0.8235, 0.7722, 0.8753, 0.9055, 0.8887, 0.82]
2023-01-12 16:17:43.117782: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:17:44.330306: lr: 0.000348
2023-01-12 16:17:44.331064: This epoch took 179.178250 s

2023-01-12 16:17:44.331417: 
epoch:  976
2023-01-12 16:20:21.228802: train loss : -0.8688
2023-01-12 16:20:33.425968: validation loss: -0.8313
2023-01-12 16:20:33.427618: Average global foreground Dice: [0.8932, 0.9537, 0.8706, 0.813, 0.7673, 0.8674, 0.9003, 0.8881, 0.8212]
2023-01-12 16:20:33.428082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:20:34.954533: lr: 0.000335
2023-01-12 16:20:34.955377: This epoch took 170.623685 s

2023-01-12 16:20:34.955844: 
epoch:  977
2023-01-12 16:23:15.092730: train loss : -0.8707
2023-01-12 16:23:26.066752: validation loss: -0.8282
2023-01-12 16:23:26.068455: Average global foreground Dice: [0.8932, 0.9581, 0.8744, 0.8181, 0.7676, 0.8669, 0.9046, 0.88, 0.8326]
2023-01-12 16:23:26.074180: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:23:27.031971: lr: 0.000322
2023-01-12 16:23:27.032706: This epoch took 172.076517 s

2023-01-12 16:23:27.033027: 
epoch:  978
2023-01-12 16:26:11.675274: train loss : -0.8635
2023-01-12 16:26:23.342631: validation loss: -0.8224
2023-01-12 16:26:23.344222: Average global foreground Dice: [0.8887, 0.958, 0.8741, 0.8325, 0.7516, 0.8699, 0.9056, 0.8885, 0.8107]
2023-01-12 16:26:23.344910: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:26:25.322088: lr: 0.000309
2023-01-12 16:26:25.322875: This epoch took 178.289530 s

2023-01-12 16:26:25.323302: 
epoch:  979
2023-01-12 16:29:05.582130: train loss : -0.8688
2023-01-12 16:29:16.986612: validation loss: -0.8351
2023-01-12 16:29:16.999779: Average global foreground Dice: [0.8834, 0.954, 0.8679, 0.8123, 0.7696, 0.8666, 0.9014, 0.8908, 0.8197]
2023-01-12 16:29:17.000410: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:29:18.847052: lr: 0.000296
2023-01-12 16:29:18.848088: This epoch took 173.524363 s

2023-01-12 16:29:18.848784: 
epoch:  980
2023-01-12 16:31:58.199318: train loss : -0.8709
2023-01-12 16:32:09.655818: validation loss: -0.8333
2023-01-12 16:32:09.676860: Average global foreground Dice: [0.8917, 0.9546, 0.8724, 0.8309, 0.7643, 0.8726, 0.9089, 0.8913, 0.8169]
2023-01-12 16:32:09.677734: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:32:12.012841: lr: 0.000282
2023-01-12 16:32:12.027199: This epoch took 173.177933 s

2023-01-12 16:32:12.027758: 
epoch:  981
2023-01-12 16:34:52.464749: train loss : -0.8683
2023-01-12 16:35:03.918557: validation loss: -0.8344
2023-01-12 16:35:03.931508: Average global foreground Dice: [0.8916, 0.9592, 0.8747, 0.826, 0.7767, 0.8672, 0.8993, 0.8919, 0.8141]
2023-01-12 16:35:03.931985: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:35:05.479887: lr: 0.000269
2023-01-12 16:35:05.480778: This epoch took 173.452611 s

2023-01-12 16:35:05.481282: 
epoch:  982
2023-01-12 16:37:47.146590: train loss : -0.8707
2023-01-12 16:37:57.807961: validation loss: -0.8370
2023-01-12 16:37:57.824609: Average global foreground Dice: [0.8929, 0.957, 0.8753, 0.8185, 0.7663, 0.8731, 0.9008, 0.8886, 0.818]
2023-01-12 16:37:57.825223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:37:59.252184: lr: 0.000256
2023-01-12 16:37:59.263989: This epoch took 173.782401 s

2023-01-12 16:37:59.265217: 
epoch:  983
2023-01-12 16:40:47.621331: train loss : -0.8689
2023-01-12 16:40:58.402857: validation loss: -0.8293
2023-01-12 16:41:00.674656: Average global foreground Dice: [0.8947, 0.9559, 0.8736, 0.8119, 0.7675, 0.8728, 0.899, 0.8922, 0.8033]
2023-01-12 16:41:00.704257: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:41:02.706117: lr: 0.000242
2023-01-12 16:41:02.707142: This epoch took 183.440366 s

2023-01-12 16:41:02.707826: 
epoch:  984
2023-01-12 16:43:58.712531: train loss : -0.8718
2023-01-12 16:44:09.800613: validation loss: -0.8321
2023-01-12 16:44:09.818967: Average global foreground Dice: [0.8945, 0.9575, 0.878, 0.8183, 0.7687, 0.8753, 0.9015, 0.8869, 0.8177]
2023-01-12 16:44:09.819894: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:44:11.427337: lr: 0.000228
2023-01-12 16:44:11.428312: This epoch took 188.720045 s

2023-01-12 16:44:11.428611: 
epoch:  985
2023-01-12 16:46:46.773582: train loss : -0.8735
2023-01-12 16:46:57.867557: validation loss: -0.8311
2023-01-12 16:46:57.924961: Average global foreground Dice: [0.8916, 0.9561, 0.874, 0.826, 0.7731, 0.8674, 0.8984, 0.8903, 0.8132]
2023-01-12 16:46:57.929763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:47:07.041538: lr: 0.000215
2023-01-12 16:47:07.052143: This epoch took 175.623253 s

2023-01-12 16:47:07.052639: 
epoch:  986
2023-01-12 16:49:52.750493: train loss : -0.8705
2023-01-12 16:50:04.873413: validation loss: -0.8318
2023-01-12 16:50:04.888682: Average global foreground Dice: [0.8928, 0.9561, 0.8739, 0.8215, 0.7593, 0.8681, 0.8988, 0.8901, 0.8141]
2023-01-12 16:50:04.889421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:50:06.143767: lr: 0.000201
2023-01-12 16:50:06.144928: This epoch took 179.091898 s

2023-01-12 16:50:06.145534: 
epoch:  987
2023-01-12 16:52:34.123662: train loss : -0.8743
2023-01-12 16:52:45.427644: validation loss: -0.8314
2023-01-12 16:52:46.250474: Average global foreground Dice: [0.8898, 0.9544, 0.8781, 0.8146, 0.7693, 0.87, 0.8993, 0.8897, 0.8182]
2023-01-12 16:52:46.278586: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:52:47.666934: lr: 0.000187
2023-01-12 16:52:47.674635: This epoch took 161.528801 s

2023-01-12 16:52:47.675018: 
epoch:  988
2023-01-12 16:55:37.754915: train loss : -0.8722
2023-01-12 16:55:50.208650: validation loss: -0.8336
2023-01-12 16:55:50.228544: Average global foreground Dice: [0.8884, 0.9575, 0.8726, 0.8251, 0.7674, 0.8701, 0.9032, 0.8848, 0.8192]
2023-01-12 16:55:50.229270: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:55:51.740374: lr: 0.000173
2023-01-12 16:55:51.741261: This epoch took 184.065938 s

2023-01-12 16:55:51.741687: 
epoch:  989
2023-01-12 16:58:35.530270: train loss : -0.8707
2023-01-12 16:58:46.869787: validation loss: -0.8250
2023-01-12 16:58:46.874925: Average global foreground Dice: [0.8881, 0.9544, 0.8718, 0.8155, 0.7652, 0.8717, 0.9023, 0.8839, 0.8284]
2023-01-12 16:58:46.876745: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 16:58:48.710160: lr: 0.000158
2023-01-12 16:58:48.710784: This epoch took 176.968774 s

2023-01-12 16:58:48.711116: 
epoch:  990
2023-01-12 17:01:31.069385: train loss : -0.8677
2023-01-12 17:01:42.058038: validation loss: -0.8430
2023-01-12 17:01:42.059923: Average global foreground Dice: [0.9014, 0.9552, 0.8784, 0.8239, 0.7884, 0.8709, 0.8957, 0.8896, 0.8282]
2023-01-12 17:01:42.060940: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 17:01:43.624244: lr: 0.000144
2023-01-12 17:01:43.625202: This epoch took 174.913780 s

2023-01-12 17:01:43.625693: 
epoch:  991
2023-01-12 17:04:11.581346: train loss : -0.8746
2023-01-12 17:04:23.444815: validation loss: -0.8363
2023-01-12 17:04:23.452800: Average global foreground Dice: [0.8953, 0.9591, 0.8764, 0.8294, 0.7821, 0.8705, 0.8988, 0.8889, 0.8135]
2023-01-12 17:04:23.453501: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 17:04:25.232747: lr: 0.00013
2023-01-12 17:04:25.243679: This epoch took 161.617631 s

2023-01-12 17:04:25.244215: 
epoch:  992
2023-01-12 17:07:03.419470: train loss : -0.8750
2023-01-12 17:07:15.429392: validation loss: -0.8305
2023-01-12 17:07:15.459065: Average global foreground Dice: [0.8896, 0.956, 0.8759, 0.8182, 0.7656, 0.8721, 0.9003, 0.8812, 0.8214]
2023-01-12 17:07:15.460484: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 17:07:16.966564: lr: 0.000115
2023-01-12 17:07:16.967351: This epoch took 171.722781 s

2023-01-12 17:07:16.967678: 
epoch:  993
2023-01-12 17:10:00.457833: train loss : -0.8766
2023-01-12 17:10:11.817854: validation loss: -0.8282
2023-01-12 17:10:11.840579: Average global foreground Dice: [0.8757, 0.9551, 0.8733, 0.8235, 0.7653, 0.8696, 0.9025, 0.8936, 0.8064]
2023-01-12 17:10:11.841246: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 17:10:13.794442: lr: 0.0001
2023-01-12 17:10:13.802835: This epoch took 176.834850 s

2023-01-12 17:10:13.803469: 
epoch:  994
2023-01-12 17:12:52.446871: train loss : -0.8715
2023-01-12 17:13:04.359487: validation loss: -0.8340
2023-01-12 17:13:04.361262: Average global foreground Dice: [0.8886, 0.9556, 0.8762, 0.8139, 0.7688, 0.8674, 0.8973, 0.8913, 0.8149]
2023-01-12 17:13:04.361765: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 17:13:06.318250: lr: 8.5e-05
2023-01-12 17:13:06.319009: This epoch took 172.515182 s

2023-01-12 17:13:06.319358: 
epoch:  995
2023-01-12 17:15:48.969229: train loss : -0.8746
2023-01-12 17:16:00.848854: validation loss: -0.8342
2023-01-12 17:16:00.857013: Average global foreground Dice: [0.8886, 0.9581, 0.8755, 0.8319, 0.7698, 0.8734, 0.9083, 0.8918, 0.8085]
2023-01-12 17:16:00.859166: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 17:16:02.662137: lr: 6.9e-05
2023-01-12 17:16:02.671878: This epoch took 176.352229 s

2023-01-12 17:16:02.675967: 
epoch:  996
2023-01-12 17:18:39.712065: train loss : -0.8758
2023-01-12 17:18:51.221695: validation loss: -0.8359
2023-01-12 17:18:51.223511: Average global foreground Dice: [0.8836, 0.9539, 0.8745, 0.815, 0.7674, 0.8698, 0.9013, 0.888, 0.8239]
2023-01-12 17:18:51.229292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 17:18:52.883202: lr: 5.4e-05
2023-01-12 17:18:52.885301: This epoch took 170.208582 s

2023-01-12 17:18:52.885989: 
epoch:  997
2023-01-12 17:21:43.380487: train loss : -0.8733
2023-01-12 17:21:55.193893: validation loss: -0.8321
2023-01-12 17:21:55.863537: Average global foreground Dice: [0.8833, 0.9579, 0.872, 0.826, 0.7694, 0.8722, 0.9051, 0.8877, 0.8189]
2023-01-12 17:21:56.468471: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 17:21:58.645182: lr: 3.7e-05
2023-01-12 17:21:58.645899: This epoch took 185.759471 s

2023-01-12 17:21:58.646207: 
epoch:  998
2023-01-12 17:24:37.709148: train loss : -0.8738
2023-01-12 17:24:49.611745: validation loss: -0.8368
2023-01-12 17:24:49.620126: Average global foreground Dice: [0.895, 0.9571, 0.8762, 0.8221, 0.7786, 0.8722, 0.9025, 0.8878, 0.8196]
2023-01-12 17:24:49.625584: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 17:24:51.483353: lr: 2e-05
2023-01-12 17:24:51.484164: This epoch took 172.837651 s

2023-01-12 17:24:51.484612: 
epoch:  999
2023-01-12 17:27:41.800869: train loss : -0.8704
2023-01-12 17:27:52.893548: validation loss: -0.8345
2023-01-12 17:27:52.901796: Average global foreground Dice: [0.8874, 0.9587, 0.8762, 0.8299, 0.7685, 0.8724, 0.9056, 0.8859, 0.8115]
2023-01-12 17:27:52.902510: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2023-01-12 17:27:55.328351: lr: 0.0
2023-01-12 17:27:55.332171: saving scheduled checkpoint file...
2023-01-12 17:27:55.457319: saving checkpoint...
2023-01-12 17:27:56.942837: done, saving took 1.61 seconds
2023-01-12 17:27:56.997313: done
2023-01-12 17:27:56.997917: This epoch took 185.512948 s

2023-01-12 17:27:57.068119: saving checkpoint...
2023-01-12 17:27:58.043478: done, saving took 1.05 seconds
AEye_005 (2, 176, 255, 175)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 176, 255, 175)
patch size: [128 160 112]
steps (x, y, and z): [[0, 48], [0, 48, 95], [0, 32, 63]]
number of tiles: 18
computing Gaussian
done
prediction done
AEye_008 (2, 176, 255, 175)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 176, 255, 175)
patch size: [128 160 112]
steps (x, y, and z): [[0, 48], [0, 48, 95], [0, 32, 63]]
number of tiles: 18
using precomputed Gaussian
prediction done
AEye_013 (2, 176, 255, 175)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 176, 255, 175)
patch size: [128 160 112]
steps (x, y, and z): [[0, 48], [0, 48, 95], [0, 32, 63]]
number of tiles: 18
using precomputed Gaussian
prediction done
AEye_017 (2, 176, 255, 175)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 176, 255, 175)
patch size: [128 160 112]
steps (x, y, and z): [[0, 48], [0, 48, 95], [0, 32, 63]]
number of tiles: 18
using precomputed Gaussian
prediction done
AEye_020 (2, 176, 255, 175)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 176, 255, 175)
patch size: [128 160 112]
steps (x, y, and z): [[0, 48], [0, 48, 95], [0, 32, 63]]
number of tiles: 18
using precomputed Gaussian
prediction done
AEye_023 (2, 176, 255, 175)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 176, 255, 175)
patch size: [128 160 112]
steps (x, y, and z): [[0, 48], [0, 48, 95], [0, 32, 63]]
number of tiles: 18
using precomputed Gaussian
prediction done
AEye_032 (2, 176, 255, 175)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 176, 255, 175)
patch size: [128 160 112]
steps (x, y, and z): [[0, 48], [0, 48, 95], [0, 32, 63]]
number of tiles: 18
using precomputed Gaussian
prediction done
2023-01-12 17:29:40.739739: finished prediction
2023-01-12 17:29:40.740868: evaluation of raw predictions
2023-01-12 17:29:42.739736: determining postprocessing
Foreground vs background
before: 0.8682657361355319
after:  0.7527105080703931
1
before: 0.8828044633424392
after:  0.8828044633424392
2
before: 0.9583573684194456
after:  0.9583573684194456
3
before: 0.8817651207069023
after:  0.8817651207069023
4
before: 0.8221868008855914
after:  0.8207936065836053
5
before: 0.7709356751652754
after:  0.5956574468147802
6
before: 0.881724935686422
after:  0.8817062881213068
7
before: 0.9085575193923242
after:  0.9084524280758802
8
before: 0.8889008332844005
after:  0.8889008332844005
9
before: 0.819158908336987
after:  0.8205227153598306
Removing all but the largest region for class 9 improved results!
min_valid_object_sizes None
done
for which classes:
[9]
min_object_sizes
None
force_separate_z: None interpolation order: 1
no resampling necessary
force_separate_z: None interpolation order: 1
no resampling necessary
force_separate_z: None interpolation order: 1
no resampling necessary
force_separate_z: None interpolation order: 1
no resampling necessary
force_separate_z: None interpolation order: 1
no resampling necessary
done
