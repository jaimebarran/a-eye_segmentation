{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity metrics for segmentation quality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-labeled dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATLAS vs DL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob, os\n",
    "\n",
    "reg_dir = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/non_labeled_dataset_nifti_reg_2/'\n",
    "dl_dir = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/3D_multilabel/experiment_0/test_orig_reg-cropped_non-labeled'\n",
    "output_path = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/3D_multilabel/experiment_0/test_orig_reg-cropped_non-labeled_allign'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "i=0\n",
    "for folder1 in sorted(os.listdir(reg_dir)):\n",
    "\n",
    "    # Name subject\n",
    "    name_subject = folder1\n",
    "    print(f'subject: {name_subject}')\n",
    "\n",
    "    # Load t1_aux (to allign the other)\n",
    "    t1_aux = nb.load(f'{reg_dir}{folder1}/labels.nii.gz')\n",
    "\n",
    "    # Load t1 image (not alligned)\n",
    "    t1 = nb.load(f'{dl_dir}{folder1}_cropped_seg_res.nii.gz')\n",
    "\n",
    "    # Copy affine from t1_aux to t1\n",
    "    nii = nb.Nifti1Image(t1.dataobj, t1_aux.affine, t1.header)\n",
    "    nii.to_filename(f'{output_path}{name_subject}_cropped_seg_res_allign.nii.gz')\n",
    "    \n",
    "    # Dealing with files in that folder\n",
    "    # for f in glob.glob(base_dir+folder1+'/input/'+folder1+'_T1_oriented_hdr.nii.gz'):\n",
    "    #     os.remove(f)\n",
    "\n",
    "    i+=1\n",
    "    # if (i==1):\n",
    "    #     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nibabel as nb\n",
    "\n",
    "# nDSC (normalized DSC)\n",
    "def dice_norm_metric(ground_truth, predictions):\n",
    "    '''\n",
    "    For a single example returns DSC_norm, fpr, fnr\n",
    "    '''\n",
    "\n",
    "    # Reference for normalized DSC\n",
    "    r = 0.001 # It should be 1/N*(np.sum(voxels_label[i])/np.sum(voxels_image[i])) i belonging to training set\n",
    "    # Cast to float32 type\n",
    "    gt = ground_truth.astype(\"float32\")\n",
    "    seg = predictions.astype(\"float32\")\n",
    "    im_sum = np.sum(seg) + np.sum(gt)\n",
    "    if im_sum == 0:\n",
    "        return 1.0, 1.0, 1.0\n",
    "    else:\n",
    "        if np.sum(gt) == 0:\n",
    "            k = 1.0\n",
    "        else:\n",
    "            k = (1 - r) * np.sum(gt) / (r * (len(gt.flatten()) - np.sum(gt)))\n",
    "        tp = np.sum(seg[gt == 1])\n",
    "        fp = np.sum(seg[gt == 0])\n",
    "        fn = np.sum(gt[seg == 0])\n",
    "        fp_scaled = k * fp\n",
    "        dsc_norm = 2 * tp / (fp_scaled + 2 * tp + fn)\n",
    "\n",
    "        fpr = fp / (len(gt.flatten()) - np.sum(gt))\n",
    "        if np.sum(gt) == 0:\n",
    "            fnr = 1.0\n",
    "        else:\n",
    "            fnr = fn / np.sum(gt)\n",
    "        return dsc_norm # fpr, fnr\n",
    "\n",
    "# Paths - segmentation results\n",
    "reg_dir = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/non_labeled_dataset_nifti_reg_2/'\n",
    "dl_dir = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/3D_multilabel/experiment_0/test_orig_reg-cropped_non-labeled_allign'\n",
    "\n",
    "# List of volumes for each individual label and subject\n",
    "len_path = len([elem for elem in os.listdir(reg_dir)]) # elements in gt path = number of subjects\n",
    "name_subject = [None]*len_path\n",
    "\n",
    "# Save values in an array\n",
    "# All labels\n",
    "val_dsc             = np.zeros(len_path)\n",
    "# val_hau             = np.zeros(len(rest_subjects))\n",
    "val_hau_avg         = np.zeros(len_path)\n",
    "val_vol             = np.zeros(len_path)\n",
    "val_ndsc            = np.zeros(len_path)\n",
    "# Lens\n",
    "val_dsc_lens        = np.zeros(len_path)\n",
    "val_hau_avg_lens    = np.zeros(len_path)\n",
    "val_vol_lens        = np.zeros(len_path)\n",
    "val_ndsc_lens       = np.zeros(len_path)\n",
    "# Globe\n",
    "val_dsc_globe       = np.zeros(len_path)\n",
    "val_hau_avg_globe   = np.zeros(len_path)\n",
    "val_vol_globe       = np.zeros(len_path)\n",
    "val_ndsc_globe      = np.zeros(len_path)\n",
    "# Optic nerve  \n",
    "val_dsc_nerve       = np.zeros(len_path)\n",
    "val_hau_avg_nerve   = np.zeros(len_path)\n",
    "val_vol_nerve       = np.zeros(len_path)\n",
    "val_ndsc_nerve      = np.zeros(len_path)\n",
    "# Intraconal fat\n",
    "val_dsc_int_fat     = np.zeros(len_path)\n",
    "val_hau_avg_int_fat = np.zeros(len_path)\n",
    "val_vol_int_fat     = np.zeros(len_path)\n",
    "val_ndsc_int_fat    = np.zeros(len_path)\n",
    "# Extraconal fat\n",
    "val_dsc_ext_fat     = np.zeros(len_path)\n",
    "val_hau_avg_ext_fat = np.zeros(len_path)\n",
    "val_vol_ext_fat     = np.zeros(len_path)\n",
    "val_ndsc_ext_fat    = np.zeros(len_path)\n",
    "# Lateral rectus muscle\n",
    "val_dsc_lat_mus     = np.zeros(len_path)\n",
    "val_hau_avg_lat_mus = np.zeros(len_path)\n",
    "val_vol_lat_mus     = np.zeros(len_path)\n",
    "val_ndsc_lat_mus    = np.zeros(len_path)\n",
    "# Medial rectus musclenp.zeros(len_path)\n",
    "val_dsc_med_mus     = np.zeros(len_path)\n",
    "val_hau_avg_med_mus = np.zeros(len_path)\n",
    "val_vol_med_mus     = np.zeros(len_path)\n",
    "val_ndsc_med_mus    = np.zeros(len_path)\n",
    "# Inferior rectus muscle\n",
    "val_dsc_inf_mus     = np.zeros(len_path)\n",
    "val_hau_avg_inf_mus = np.zeros(len_path)\n",
    "val_vol_inf_mus     = np.zeros(len_path)\n",
    "val_ndsc_inf_mus    = np.zeros(len_path)\n",
    "# Superior rectus muscnp.zeros(len_path)\n",
    "val_dsc_sup_mus     = np.zeros(len_path)\n",
    "val_hau_avg_sup_mus = np.zeros(len_path)\n",
    "val_vol_sup_mus     = np.zeros(len_path)\n",
    "val_ndsc_sup_mus    = np.zeros(len_path)\n",
    "    \n",
    "reader = sitk.ImageFileReader()\n",
    "\n",
    "i=0\n",
    "for folder1 in sorted(os.listdir(reg_dir)):\n",
    "\n",
    "    # Name subject\n",
    "    name_subject[i] = str(folder1)\n",
    "    print(f'subject: {name_subject[i]}')\n",
    "    \n",
    "    # ATLAS-based registration results\n",
    "    reg_lab_path = f'{reg_dir}{folder1}/labels.nii.gz'\n",
    "    reader.SetFileName(reg_lab_path)\n",
    "    reg_lab_sitk = sitk.Cast(reader.Execute(), sitk.sitkUInt8)\n",
    "    reg_lab_arr = sitk.GetArrayFromImage(reg_lab_sitk)\n",
    "\n",
    "    # Deep Learning results\n",
    "    dl_lab_path = f'{dl_dir}{folder1}_cropped_seg_res_allign.nii.gz'\n",
    "    reader.SetFileName(dl_lab_path)\n",
    "    dl_lab_sitk = sitk.Cast(reader.Execute(), sitk.sitkUInt8)\n",
    "    dl_lab_arr = sitk.GetArrayFromImage(dl_lab_sitk)\n",
    "    \n",
    "    # Image size\n",
    "    im_lab_size = reg_lab_arr.shape[0]*reg_lab_arr.shape[1]*reg_lab_arr.shape[2]\n",
    "\n",
    "    # LENS\n",
    "    # Measures Image Filter \n",
    "    overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "    overlap_measures_filter.Execute(reg_lab_sitk==1, dl_lab_sitk==1)\n",
    "    # DSC\n",
    "    dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "    val_dsc_lens[i] = dsc\n",
    "    # Volume\n",
    "    vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "    val_vol_lens[i] = vol\n",
    "    # Hausdorff distance\n",
    "    if np.count_nonzero(reg_lab_arr==1)==0 or np.count_nonzero(dl_lab_arr==1)==0: val_hau_avg_lens[i] = 100\n",
    "    else :\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==1, dl_lab_sitk==1)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_lens[i] = hausdorf_distance_avg\n",
    "    # nDSC\n",
    "    nDSC = dice_norm_metric(reg_lab_arr==1, dl_lab_arr==1)\n",
    "    val_ndsc_lens[i] = nDSC\n",
    "    \n",
    "    # GLOBE EX LENS\n",
    "    # Measures Image Filter \n",
    "    overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "    overlap_measures_filter.Execute(reg_lab_sitk==2, dl_lab_sitk==2)\n",
    "    # DSC\n",
    "    dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "    val_dsc_globe[i] = dsc\n",
    "    # Volume\n",
    "    vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "    val_vol_globe[i] = vol\n",
    "    # Hausdorff distance\n",
    "    hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "    hausdorf.Execute(reg_lab_sitk==2, dl_lab_sitk==2)\n",
    "    hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "    val_hau_avg_globe[i] = hausdorf_distance_avg\n",
    "    # nDSC\n",
    "    nDSC = dice_norm_metric(reg_lab_arr==2, dl_lab_arr==2)\n",
    "    val_ndsc_globe[i] = nDSC\n",
    "\n",
    "    # OPTIC NERVE\n",
    "    # Measures Image Filter \n",
    "    overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "    overlap_measures_filter.Execute(reg_lab_sitk==3, dl_lab_sitk==3)\n",
    "    # DSC\n",
    "    dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "    val_dsc_nerve[i] = dsc\n",
    "    # Volume\n",
    "    vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "    val_vol_nerve[i] = vol\n",
    "    # Hausdorff distance\n",
    "    hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "    hausdorf.Execute(reg_lab_sitk==3, dl_lab_sitk==3)\n",
    "    hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "    val_hau_avg_nerve[i] = hausdorf_distance_avg\n",
    "    # nDSC\n",
    "    nDSC = dice_norm_metric(reg_lab_arr==3, dl_lab_arr==3)\n",
    "    val_ndsc_nerve[i] = nDSC\n",
    "\n",
    "    # INTRACONAL FAT\n",
    "    # Measures Image Filter \n",
    "    overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "    overlap_measures_filter.Execute(reg_lab_sitk==4, dl_lab_sitk==4)\n",
    "    # DSC\n",
    "    dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "    val_dsc_int_fat[i] = dsc\n",
    "    # Volume\n",
    "    vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "    val_vol_int_fat[i] = vol\n",
    "    # Hausdorff distance\n",
    "    hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "    hausdorf.Execute(reg_lab_sitk==4, dl_lab_sitk==4)\n",
    "    hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "    val_hau_avg_int_fat[i] = hausdorf_distance_avg\n",
    "    # nDSC\n",
    "    nDSC = dice_norm_metric(reg_lab_arr==4, dl_lab_arr==4)\n",
    "    val_ndsc_int_fat[i] = nDSC\n",
    "\n",
    "    # EXTRACONAL FAT\n",
    "    # Measures Image Filter \n",
    "    overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "    overlap_measures_filter.Execute(reg_lab_sitk==5, dl_lab_sitk==5)\n",
    "    # DSC\n",
    "    dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "    val_dsc_ext_fat[i] = dsc\n",
    "    # Volume\n",
    "    vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "    val_vol_ext_fat[i] = vol\n",
    "    # Hausdorff distance\n",
    "    hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "    hausdorf.Execute(reg_lab_sitk==5, dl_lab_sitk==5)\n",
    "    hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "    val_hau_avg_ext_fat[i] = hausdorf_distance_avg\n",
    "    # nDSC\n",
    "    nDSC = dice_norm_metric(reg_lab_arr==5, dl_lab_arr==5)\n",
    "    val_ndsc_ext_fat[i] = nDSC\n",
    "\n",
    "    # LATERAL RECTUS MUSCLE\n",
    "    # Measures Image Filter \n",
    "    overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "    overlap_measures_filter.Execute(reg_lab_sitk==6, dl_lab_sitk==6)\n",
    "    # DSC\n",
    "    dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "    val_dsc_lat_mus[i] = dsc\n",
    "    # Volume\n",
    "    vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "    val_vol_lat_mus[i] = vol\n",
    "    # Hausdorff distance\n",
    "    hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "    hausdorf.Execute(reg_lab_sitk==6, dl_lab_sitk==6)\n",
    "    hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "    val_hau_avg_lat_mus[i] = hausdorf_distance_avg\n",
    "    # nDSC\n",
    "    nDSC = dice_norm_metric(reg_lab_arr==6, dl_lab_arr==6)\n",
    "    val_ndsc_lat_mus[i] = nDSC\n",
    "\n",
    "    # MEDIAL RECTUS MUSCLE\n",
    "    # Measures Image Filter \n",
    "    overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "    overlap_measures_filter.Execute(reg_lab_sitk==7, dl_lab_sitk==7)\n",
    "    # DSC\n",
    "    dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "    val_dsc_med_mus[i] = dsc\n",
    "    # Volume\n",
    "    vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "    val_vol_med_mus[i] = vol\n",
    "    # Hausdorff distance\n",
    "    if np.count_nonzero(reg_lab_arr==7)==0 or np.count_nonzero(dl_lab_arr==7)==0: val_hau_avg_lens[i] = 100\n",
    "    else :\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==7, dl_lab_sitk==7)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_med_mus[i] = hausdorf_distance_avg\n",
    "    # nDSC\n",
    "    nDSC = dice_norm_metric(reg_lab_arr==7, dl_lab_arr==7)\n",
    "    val_ndsc_med_mus[i] = nDSC\n",
    "\n",
    "    # INFERIOR RECTUS MUSCLE\n",
    "    # Measures Image Filter \n",
    "    overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "    overlap_measures_filter.Execute(reg_lab_sitk==8, dl_lab_sitk==8)\n",
    "    # DSC\n",
    "    dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "    val_dsc_inf_mus[i] = dsc\n",
    "    # Volume\n",
    "    vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "    val_vol_inf_mus[i] = vol\n",
    "    # Hausdorff distance\n",
    "    if np.count_nonzero(reg_lab_arr==8)==0 or np.count_nonzero(dl_lab_arr==8)==0: val_hau_avg_lens[i] = 100\n",
    "    else :\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==8, dl_lab_sitk==8)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_inf_mus[i] = hausdorf_distance_avg\n",
    "    # nDSC\n",
    "    nDSC = dice_norm_metric(reg_lab_arr==8, dl_lab_arr==8)\n",
    "    val_ndsc_inf_mus[i] = nDSC\n",
    "\n",
    "    # SUPERIOR RECTUS MUSCLE\n",
    "    # Measures Image Filter \n",
    "    overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "    overlap_measures_filter.Execute(reg_lab_sitk==9, dl_lab_sitk==9)\n",
    "    # DSC\n",
    "    dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "    val_dsc_sup_mus[i] = dsc\n",
    "    # Volume\n",
    "    vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "    val_vol_sup_mus[i] = vol\n",
    "    # Hausdorff distance\n",
    "    hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "    hausdorf.Execute(reg_lab_sitk==9, dl_lab_sitk==9)\n",
    "    hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "    val_hau_avg_sup_mus[i] = hausdorf_distance_avg\n",
    "    # nDSCvol\n",
    "    nDSC = dice_norm_metric(reg_lab_arr==9, dl_lab_arr==9)\n",
    "    val_ndsc_sup_mus[i] = nDSC\n",
    "\n",
    "    # ALL LABELS\n",
    "    # DSC\n",
    "    dsc = (val_dsc_lens[i]+val_dsc_globe[i]+val_dsc_nerve[i]+val_dsc_int_fat[i]+val_dsc_ext_fat[i]+val_dsc_lat_mus[i]+val_dsc_med_mus[i]+val_dsc_inf_mus[i]+val_dsc_sup_mus[i])/9\n",
    "    val_dsc[i] = dsc\n",
    "    # Volume\n",
    "    vol = (val_vol_lens[i]+val_vol_globe[i]+val_vol_nerve[i]+val_vol_int_fat[i]+val_vol_ext_fat[i]+val_vol_lat_mus[i]+val_vol_med_mus[i]+val_vol_inf_mus[i]+val_vol_sup_mus[i])/9\n",
    "    val_vol[i] = vol\n",
    "    # Hausdorff distance\n",
    "    hau_avg = (val_hau_avg_lens[i]+val_hau_avg_globe[i]+val_hau_avg_nerve[i]+val_hau_avg_int_fat[i]+val_hau_avg_ext_fat[i]+val_hau_avg_lat_mus[i]+val_hau_avg_med_mus[i]+val_hau_avg_inf_mus[i]+val_hau_avg_sup_mus[i])/9\n",
    "    val_hau_avg[i] = hau_avg\n",
    "    # nDSC\n",
    "    nDSC = (val_ndsc_lens[i]+val_ndsc_globe[i]+val_ndsc_nerve[i]+val_ndsc_int_fat[i]+val_ndsc_ext_fat[i]+val_ndsc_lat_mus[i]+val_ndsc_med_mus[i]+val_ndsc_inf_mus[i]+val_ndsc_sup_mus[i])/9\n",
    "    val_ndsc[i] = nDSC\n",
    "\n",
    "    i+=1\n",
    "    # if i==2:\n",
    "    #     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save values to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "metrics = [\n",
    "    'Subject',  'DSC_all',     'Haus_avg_all',     'Volume_all',     'nDSC_all', \n",
    "                'DSC_lens',    'Haus_avg_lens',    'Volume_lens',    'nDSC_lens',  \n",
    "                'DSC_globe',   'Haus_avg_globe',   'Volume_globe',   'nDSC_globe', \n",
    "                'DSC_nerve',   'Haus_avg_nerve',   'Volume_nerve',   'nDSC_nerve', \n",
    "                'DSC_int_fat', 'Haus_avg_int_fat', 'Volume_int_fat', 'nDSC_int_fat',\n",
    "                'DSC_ext_fat', 'Haus_avg_ext_fat', 'Volume_ext_fat', 'nDSC_ext_fat',\n",
    "                'DSC_lat_mus', 'Haus_avg_lat_mus', 'Volume_lat_mus', 'nDSC_lat_mus',\n",
    "                'DSC_med_mus', 'Haus_avg_med_mus', 'Volume_med_mus', 'nDSC_med_mus',\n",
    "                'DSC_inf_mus', 'Haus_avg_inf_mus', 'Volume_inf_mus', 'nDSC_inf_mus',\n",
    "                'DSC_sup_mus', 'Haus_avg_sup_mus', 'Volume_sup_mus', 'nDSC_sup_mus'\n",
    "]\n",
    "\n",
    "vals = np.array([\n",
    "    name_subject,   val_dsc,         val_hau_avg,         val_vol,         val_ndsc,        \n",
    "                    val_dsc_lens,    val_hau_avg_lens,    val_vol_lens,    val_ndsc_lens,   \n",
    "                    val_dsc_globe,   val_hau_avg_globe,   val_vol_globe,   val_ndsc_globe,  \n",
    "                    val_dsc_nerve,   val_hau_avg_nerve,   val_vol_nerve,   val_ndsc_nerve,  \n",
    "                    val_dsc_int_fat, val_hau_avg_int_fat, val_vol_int_fat, val_ndsc_int_fat,\n",
    "                    val_dsc_ext_fat, val_hau_avg_ext_fat, val_vol_ext_fat, val_ndsc_ext_fat,\n",
    "                    val_dsc_lat_mus, val_hau_avg_lat_mus, val_vol_lat_mus, val_ndsc_lat_mus,\n",
    "                    val_dsc_med_mus, val_hau_avg_med_mus, val_vol_med_mus, val_ndsc_med_mus,\n",
    "                    val_dsc_inf_mus, val_hau_avg_inf_mus, val_vol_inf_mus, val_ndsc_inf_mus,\n",
    "                    val_dsc_sup_mus, val_hau_avg_sup_mus, val_vol_sup_mus, val_ndsc_sup_mus,\n",
    "])\n",
    "\n",
    "vals = vals.T\n",
    "\n",
    "with open('/mnt/sda1/Repos/a-eye/Output/similarity/sim_reg_vs_dl.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(metrics)\n",
    "    writer.writerows(vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read values from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import Line2D\n",
    "import numpy as np\n",
    "\n",
    "csv_file = pd.read_csv('/mnt/sda1/Repos/a-eye/Output/similarity/sim_reg_vs_dl.csv')\n",
    "\n",
    "# Dataframes {DSC, nDSC, Volume (voxels)} separate labels for N=5 only\n",
    "data_dsc = [csv_file['DSC_all'], csv_file['DSC_lens'], csv_file['DSC_globe'], csv_file['DSC_nerve'], csv_file['DSC_int_fat'], csv_file['DSC_ext_fat'], csv_file['DSC_lat_mus'], csv_file['DSC_med_mus'], csv_file['DSC_inf_mus'], csv_file['DSC_sup_mus']]\n",
    "data_ndsc = [csv_file['nDSC_all'],  csv_file['nDSC_lens'], csv_file['nDSC_globe'], csv_file['nDSC_nerve'], csv_file['nDSC_int_fat'], csv_file['nDSC_ext_fat'], csv_file['nDSC_lat_mus'], csv_file['nDSC_med_mus'], csv_file['nDSC_inf_mus'], csv_file['nDSC_sup_mus']]\n",
    "data_vol = [csv_file['Volume_all'], csv_file['Volume_lens'], csv_file['Volume_globe'], csv_file['Volume_nerve'], csv_file['Volume_int_fat'], csv_file['Volume_ext_fat'], csv_file['Volume_lat_mus'], csv_file['Volume_med_mus'], csv_file['Volume_inf_mus'], csv_file['Volume_sup_mus']]\n",
    "data_haus = [csv_file['Haus_avg_all'], csv_file['Haus_avg_lens'], csv_file['Haus_avg_globe'], csv_file['Haus_avg_nerve'], csv_file['Haus_avg_int_fat'], csv_file['Haus_avg_ext_fat'], csv_file['Haus_avg_lat_mus'], csv_file['Haus_avg_med_mus'], csv_file['Haus_avg_inf_mus'], csv_file['Haus_avg_sup_mus']]\n",
    "\n",
    "labels = ['lens', 'globe', 'nerve', 'intraconal fat', 'extraconal fat', 'lateral rectus muscle', 'medial rectus muscle', 'inferior rectus muscle', 'superior rectus muscle']\n",
    "median = [np.around(np.median(x), 2) for x in data_dsc]\n",
    "for i in range(len(labels)):\n",
    "    print(labels[i], median[i])\n",
    "\n",
    "# Figure\n",
    "fig, axs = plt.subplots(3, figsize=(20,10), sharex=True)\n",
    "fig.canvas.manager.set_window_title('Similarity metrics ATLAS vs DL')\n",
    "fig.suptitle('Similarity metrics ATLAS vs DL')\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Set labels and titles\n",
    "axs[0].set_title('DSC')\n",
    "axs[0].set_ylim([0, 1])\n",
    "axs[1].set_title('Hausdorff distance')\n",
    "axs[1].set_ylim([0, 3])\n",
    "axs[2].set_title('Volume difference')\n",
    "axs[2].set_ylim([-2, 2])\n",
    "\n",
    "# Outliers\n",
    "flierprops = dict(markerfacecolor='0.9', markersize=4, linestyle='none')\n",
    "\n",
    "# Boxplot & Swarmplot (points)\n",
    "graph1 = sns.boxplot(data=data_dsc, ax=axs[0], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "graph2 = sns.boxplot(data=data_haus, ax=axs[1], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "graph3 = sns.boxplot(data=data_vol, ax=axs[2], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "axs[2].set_xticklabels(['all','lens','globe','nerve','int_fat','ext_fat','lat_mus','med_mus','inf_mus','sup_mus'])\n",
    "axs[2].tick_params(bottom=True)\n",
    "\n",
    "plt.show\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('/mnt/sda1/Repos/a-eye/Output/similarity/sim_reg_vs_dl.png', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATLAS vs nnUnet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping foreground by bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "\n",
    "bound = 15 # boundary for the bounding box (margins)\n",
    "\n",
    "reg_dir = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/non_labeled_dataset_nifti_reg/'\n",
    "nnunet_dir = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/nnUNet/nnUNet/nnUNet_inference/no_postprocessing/'\n",
    "output_dir = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/nnUNet/nnUNet/nnUNet_inference/no_postprocessing_cropped/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "i=0\n",
    "for folder1 in sorted(glob.glob(nnunet_dir+'*.nii.gz')):\n",
    "\n",
    "    subject = folder1.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "    print(f'subject = {subject}')\n",
    "    # if subject == '2022160101206': # indent from here\n",
    "    image_path_nnunet = f'{nnunet_dir}AEye_{subject}.nii.gz'\n",
    "    image_path_atlas = f'{reg_dir}{subject}/labels.nii.gz'\n",
    "\n",
    "    # Atlas image size\n",
    "    atlas_image = sitk.ReadImage(image_path_atlas)\n",
    "    atlas_image_x_size, atlas_image_y_size, atlas_image_z_size = atlas_image.GetSize()\n",
    "    print(f\"atlas_image_x_size = {atlas_image_x_size} | atlas_image_y_size = {atlas_image_y_size} | atlas_image_z_size = {atlas_image_z_size}\")\n",
    "\n",
    "    # nnUNet image size\n",
    "    nnunet_image = sitk.ReadImage(image_path_nnunet)\n",
    "    nnunet_image_x_size, nnunet_image_y_size, nnunet_image_z_size = nnunet_image.GetSize()\n",
    "    print(f\"image_x_size = {nnunet_image_x_size} | image_y_size = {nnunet_image_y_size} | image_z_size = {nnunet_image_z_size}\")\n",
    "\n",
    "    # Mask\n",
    "    atlas_image_arr = sitk.GetArrayFromImage(atlas_image)\n",
    "    if np.count_nonzero(atlas_image_arr > 0) == 0:\n",
    "        print(f'Image {subject} is empty')\n",
    "        continue\n",
    "    all_segments_mask = atlas_image > 0\n",
    "\n",
    "    # Bounding box\n",
    "    lsif = sitk.LabelStatisticsImageFilter() # It requires intensity and label images\n",
    "    lsif.Execute(atlas_image, all_segments_mask) # Mask! Where all the labels are 1!\n",
    "    bounding_box = np.array(lsif.GetBoundingBox(1)) # GetBoundingBox(label)\n",
    "    print(f\"Bounding box:  {bounding_box}\") # [xmin, xmax, ymin, ymax, zmin, zmax]\n",
    "\n",
    "    # Expand bounding box\n",
    "    bounding_box_expanded = bounding_box.copy()\n",
    "    bounding_box_expanded[0::2] -= bound # even indexes\n",
    "    bounding_box_expanded[1::2] += bound # odd indexes\n",
    "    print(f\"Expanded bounding box: {bounding_box_expanded}\")\n",
    "\n",
    "    # Limits\n",
    "    if bounding_box_expanded[0] < 0: bounding_box_expanded[0] = 0\n",
    "    if bounding_box_expanded[1] > nnunet_image_x_size: bounding_box_expanded[1] = nnunet_image_x_size\n",
    "    if bounding_box_expanded[2] < 0: bounding_box_expanded[2] = 0\n",
    "    if bounding_box_expanded[3] > nnunet_image_y_size: bounding_box_expanded[3] = nnunet_image_y_size\n",
    "    if bounding_box_expanded[4] < 0: bounding_box_expanded[4] = 0\n",
    "    if bounding_box_expanded[5] > nnunet_image_z_size: bounding_box_expanded[5] = nnunet_image_z_size\n",
    "    print(f\"Expanded bounding box after limits: {bounding_box_expanded}\")\n",
    "\n",
    "    # Crop\n",
    "    print(f'New image size: image_x_size = {bounding_box_expanded[1]-bounding_box_expanded[0]} | image_y_size = {bounding_box_expanded[3]-bounding_box_expanded[2]} | image_z_size = {bounding_box_expanded[5]-bounding_box_expanded[4]}')\n",
    "    image_crop = nnunet_image[int(bounding_box_expanded[0]):int(bounding_box_expanded[1]), # x\n",
    "                    int(bounding_box_expanded[2]):int(bounding_box_expanded[3]), # y\n",
    "                    int(bounding_box_expanded[4]):int(bounding_box_expanded[5])] # z\n",
    "    # sitk.WriteImage(image_crop, f'{output_dir}{subject}_cropped.nii.gz')\n",
    "\n",
    "    i+=1\n",
    "    if (i==1):\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many images are in bytes instead of kB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of files under 1kB in a specific folder\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "path = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/nnUNet/nnUNet/nnUNet_inference/no_postprocessing_cropped/'\n",
    "files = glob.glob(path + '*.nii.gz')\n",
    "bad_files = []\n",
    "\n",
    "i=0\n",
    "for file in sorted(files):\n",
    "    if os.path.getsize(file) < 1000:\n",
    "        subject = file.split('/')[-1].split('.')[0].split('_')[0]\n",
    "        bad_files.append(subject)\n",
    "        print(subject)\n",
    "        i+=1\n",
    "\n",
    "print(f'Number of images under 1kB: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc3_vol_nnunet = pd.read_excel('/home/jaimebarranco/Desktop/MRI-QC/qc3_vol_nnunet.xlsx')\n",
    "\n",
    "# Check for the presence of each file in qc3_vol_nunet\n",
    "matching_files = [file for file in bad_files if file in str(qc3_vol_nnunet['subject'].values)]\n",
    "\n",
    "# difference between matching_files and bad_files\n",
    "difference = [file for file in bad_files if file not in matching_files]\n",
    "print(difference) # that file was already removed in qc1 (mriqc-learn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "\n",
    "reg_dir = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/non_labeled_dataset_nifti_reg_2/'\n",
    "nnunet_dir = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/nnUNet/nnUNet/nnUNet_inference/no_postprocessing_cropped/'\n",
    "output_dir = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/nnUNet/nnUNet/nnUNet_inference/no_postprocessing_cropped_alligned/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "i=0\n",
    "for folder1 in sorted(glob.glob(nnunet_dir+'*.nii.gz')):\n",
    "\n",
    "    subject = folder1.split('/')[-1].split('.')[0].split('_')[0]\n",
    "    print(f'subject = {subject}')\n",
    "    # if subject == '2022160100236': # indent from here\n",
    "    image_path_nnunet = f'{nnunet_dir}{subject}_cropped.nii.gz'\n",
    "    image_path_atlas = f'{reg_dir}{subject}/labels.nii.gz'\n",
    "\n",
    "    # Load t1_aux (to allign the other)\n",
    "    t1_aux = nb.load(image_path_atlas)\n",
    "    # print(f't1_aux.affine: \\n{t1_aux.affine}')\n",
    "    # print(f't1_aux.header: \\n{t1_aux.header}')\n",
    "\n",
    "    # Load t1 image (not alligned)\n",
    "    t1 = nb.load(image_path_nnunet)\n",
    "    # print(f't1.affine: \\n{t1.affine}')\n",
    "    # print(f't1.header: \\n{t1.header}')\n",
    "\n",
    "    # Copy affine from t1_aux to t1\n",
    "    nii = nb.Nifti1Image(t1.dataobj, t1_aux.affine, t1_aux.header)\n",
    "    nii.to_filename(f'{output_dir}{subject}_cropped_alligned.nii.gz')\n",
    "    \n",
    "    # Dealing with files in that folder\n",
    "    # for f in glob.glob(base_dir+folder1+'/input/'+folder1+'_T1_oriented_hdr.nii.gz'):\n",
    "    #     os.remove(f)\n",
    "\n",
    "    i+=1\n",
    "    # if (i==1):\n",
    "    #     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sim. metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nibabel as nb\n",
    "\n",
    "# nDSC (normalized DSC)\n",
    "def dice_norm_metric(ground_truth, predictions):\n",
    "    '''\n",
    "    For a single example returns DSC_norm, fpr, fnr\n",
    "    '''\n",
    "\n",
    "    # Reference for normalized DSC\n",
    "    r = 0.001 # It should be 1/N*(np.sum(voxels_label[i])/np.sum(voxels_image[i])) i belonging to training set\n",
    "    # Cast to float32 type\n",
    "    gt = ground_truth.astype(\"float32\")\n",
    "    seg = predictions.astype(\"float32\")\n",
    "    im_sum = np.sum(seg) + np.sum(gt)\n",
    "    if im_sum == 0:\n",
    "        return 1.0, 1.0, 1.0\n",
    "    else:\n",
    "        if np.sum(gt) == 0:\n",
    "            k = 1.0\n",
    "        else:\n",
    "            k = (1 - r) * np.sum(gt) / (r * (len(gt.flatten()) - np.sum(gt)))\n",
    "        tp = np.sum(seg[gt == 1])\n",
    "        fp = np.sum(seg[gt == 0])\n",
    "        fn = np.sum(gt[seg == 0])\n",
    "        fp_scaled = k * fp\n",
    "        dsc_norm = 2 * tp / (fp_scaled + 2 * tp + fn)\n",
    "\n",
    "        fpr = fp / (len(gt.flatten()) - np.sum(gt))\n",
    "        if np.sum(gt) == 0:\n",
    "            fnr = 1.0\n",
    "        else:\n",
    "            fnr = fn / np.sum(gt)\n",
    "        return dsc_norm # fpr, fnr\n",
    "\n",
    "# Paths - segmentation results\n",
    "reg_dir = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/non_labeled_dataset_nifti_reg_2/'\n",
    "nnunet_dir = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/nnUNet/nnUNet/nnUNet_inference/no_postprocessing_cropped_alligned/'\n",
    "\n",
    "# List of volumes for each individual label and subject\n",
    "len_path = len([elem for elem in os.listdir(nnunet_dir)]) # elements in gt path = number of subjects\n",
    "name_subject = [None]*len_path\n",
    "\n",
    "# Save values in an array\n",
    "# All labels\n",
    "val_dsc             = np.zeros(len_path)\n",
    "# val_hau             = np.zeros(len(rest_subjects))\n",
    "val_hau_avg         = np.zeros(len_path)\n",
    "val_vol             = np.zeros(len_path)\n",
    "val_ndsc            = np.zeros(len_path)\n",
    "# Lens\n",
    "val_dsc_lens        = np.zeros(len_path)\n",
    "val_hau_avg_lens    = np.zeros(len_path)\n",
    "val_vol_lens        = np.zeros(len_path)\n",
    "val_ndsc_lens       = np.zeros(len_path)\n",
    "# Globe\n",
    "val_dsc_globe       = np.zeros(len_path)\n",
    "val_hau_avg_globe   = np.zeros(len_path)\n",
    "val_vol_globe       = np.zeros(len_path)\n",
    "val_ndsc_globe      = np.zeros(len_path)\n",
    "# Optic nerve  \n",
    "val_dsc_nerve       = np.zeros(len_path)\n",
    "val_hau_avg_nerve   = np.zeros(len_path)\n",
    "val_vol_nerve       = np.zeros(len_path)\n",
    "val_ndsc_nerve      = np.zeros(len_path)\n",
    "# Intraconal fat\n",
    "val_dsc_int_fat     = np.zeros(len_path)\n",
    "val_hau_avg_int_fat = np.zeros(len_path)\n",
    "val_vol_int_fat     = np.zeros(len_path)\n",
    "val_ndsc_int_fat    = np.zeros(len_path)\n",
    "# Extraconal fat\n",
    "val_dsc_ext_fat     = np.zeros(len_path)\n",
    "val_hau_avg_ext_fat = np.zeros(len_path)\n",
    "val_vol_ext_fat     = np.zeros(len_path)\n",
    "val_ndsc_ext_fat    = np.zeros(len_path)\n",
    "# Lateral rectus muscle\n",
    "val_dsc_lat_mus     = np.zeros(len_path)\n",
    "val_hau_avg_lat_mus = np.zeros(len_path)\n",
    "val_vol_lat_mus     = np.zeros(len_path)\n",
    "val_ndsc_lat_mus    = np.zeros(len_path)\n",
    "# Medial rectus muscle\n",
    "val_dsc_med_mus     = np.zeros(len_path)\n",
    "val_hau_avg_med_mus = np.zeros(len_path)\n",
    "val_vol_med_mus     = np.zeros(len_path)\n",
    "val_ndsc_med_mus    = np.zeros(len_path)\n",
    "# Inferior rectus muscle\n",
    "val_dsc_inf_mus     = np.zeros(len_path)\n",
    "val_hau_avg_inf_mus = np.zeros(len_path)\n",
    "val_vol_inf_mus     = np.zeros(len_path)\n",
    "val_ndsc_inf_mus    = np.zeros(len_path)\n",
    "# Superior rectus muscle\n",
    "val_dsc_sup_mus     = np.zeros(len_path)\n",
    "val_hau_avg_sup_mus = np.zeros(len_path)\n",
    "val_vol_sup_mus     = np.zeros(len_path)\n",
    "val_ndsc_sup_mus    = np.zeros(len_path)\n",
    "\n",
    "reader = sitk.ImageFileReader()\n",
    "\n",
    "i=0\n",
    "for file in sorted(os.listdir(nnunet_dir)):\n",
    "\n",
    "    # Name subject\n",
    "    name_subject[i] = file.split('_')[0]\n",
    "    print(f'subject: {name_subject[i]}')\n",
    "\n",
    "    # bad files\n",
    "    # if name_subject[i] in bad_files:\n",
    "    #     print('bad file')\n",
    "    #     i+=1\n",
    "    #     continue\n",
    "    \n",
    "    # ATLAS-based registration results\n",
    "    reg_lab_path = f'{reg_dir}{name_subject[i]}/labels.nii.gz'\n",
    "    reader.SetFileName(reg_lab_path)\n",
    "    reg_lab_sitk = sitk.Cast(reader.Execute(), sitk.sitkUInt8)\n",
    "    reg_lab_arr = sitk.GetArrayFromImage(reg_lab_sitk)\n",
    "\n",
    "    # Deep Learning results\n",
    "    dl_lab_path = f'{nnunet_dir}{name_subject[i]}_cropped_alligned.nii.gz'\n",
    "    # check if the file exists\n",
    "    if not os.path.exists(dl_lab_path):\n",
    "        print('file does not exist')\n",
    "        i+=1\n",
    "        continue\n",
    "    reader.SetFileName(dl_lab_path)\n",
    "    dl_lab_sitk = sitk.Cast(reader.Execute(), sitk.sitkUInt8)\n",
    "    dl_lab_arr = sitk.GetArrayFromImage(dl_lab_sitk)\n",
    "    \n",
    "    # Image size\n",
    "    im_lab_size = reg_lab_arr.shape[0]*reg_lab_arr.shape[1]*reg_lab_arr.shape[2]\n",
    "\n",
    "    # LENS\n",
    "    if np.count_nonzero(reg_lab_arr==1)==0 or np.count_nonzero(dl_lab_arr==1)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==1, dl_lab_sitk==1)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_lens[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_lens[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==1, dl_lab_sitk==1)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_lens[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==1, dl_lab_arr==1)\n",
    "        val_ndsc_lens[i] = nDSC\n",
    "    \n",
    "    # GLOBE EX LENS\n",
    "    if np.count_nonzero(reg_lab_arr==2)==0 or np.count_nonzero(dl_lab_arr==2)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==2, dl_lab_sitk==2)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_globe[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_globe[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==2, dl_lab_sitk==2)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_globe[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==2, dl_lab_arr==2)\n",
    "        val_ndsc_globe[i] = nDSC\n",
    "\n",
    "    # OPTIC NERVE\n",
    "    if np.count_nonzero(reg_lab_arr==3)==0 or np.count_nonzero(dl_lab_arr==3)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==3, dl_lab_sitk==3)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_nerve[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_nerve[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==3, dl_lab_sitk==3)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_nerve[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==3, dl_lab_arr==3)\n",
    "        val_ndsc_nerve[i] = nDSC\n",
    "\n",
    "    # INTRACONAL FAT\n",
    "    if np.count_nonzero(reg_lab_arr==4)==0 or np.count_nonzero(dl_lab_arr==4)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==4, dl_lab_sitk==4)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_int_fat[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_int_fat[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==4, dl_lab_sitk==4)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_int_fat[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==4, dl_lab_arr==4)\n",
    "        val_ndsc_int_fat[i] = nDSC\n",
    "\n",
    "    # EXTRACONAL FAT\n",
    "    if np.count_nonzero(reg_lab_arr==5)==0 or np.count_nonzero(dl_lab_arr==5)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==5, dl_lab_sitk==5)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_ext_fat[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_ext_fat[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==5, dl_lab_sitk==5)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_ext_fat[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==5, dl_lab_arr==5)\n",
    "        val_ndsc_ext_fat[i] = nDSC\n",
    "\n",
    "    # LATERAL RECTUS MUSCLE\n",
    "    if np.count_nonzero(reg_lab_arr==6)==0 or np.count_nonzero(dl_lab_arr==6)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==6, dl_lab_sitk==6)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_lat_mus[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_lat_mus[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==6, dl_lab_sitk==6)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_lat_mus[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==6, dl_lab_arr==6)\n",
    "        val_ndsc_lat_mus[i] = nDSC\n",
    "\n",
    "    # MEDIAL RECTUS MUSCLE\n",
    "    if np.count_nonzero(reg_lab_arr==7)==0 or np.count_nonzero(dl_lab_arr==7)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==7, dl_lab_sitk==7)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_med_mus[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_med_mus[i] = vol\n",
    "        # Hausdorff distance\n",
    "        if np.count_nonzero(reg_lab_arr==7)==0 or np.count_nonzero(dl_lab_arr==7)==0: val_hau_avg_lens[i] = 100\n",
    "        else :\n",
    "            hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "            hausdorf.Execute(reg_lab_sitk==7, dl_lab_sitk==7)\n",
    "            hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "            val_hau_avg_med_mus[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==7, dl_lab_arr==7)\n",
    "        val_ndsc_med_mus[i] = nDSC\n",
    "\n",
    "    # INFERIOR RECTUS MUSCLE\n",
    "    if np.count_nonzero(reg_lab_arr==8)==0 or np.count_nonzero(dl_lab_arr==8)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==8, dl_lab_sitk==8)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_inf_mus[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_inf_mus[i] = vol\n",
    "        # Hausdorff distance\n",
    "        if np.count_nonzero(reg_lab_arr==8)==0 or np.count_nonzero(dl_lab_arr==8)==0: val_hau_avg_lens[i] = 100\n",
    "        else :\n",
    "            hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "            hausdorf.Execute(reg_lab_sitk==8, dl_lab_sitk==8)\n",
    "            hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "            val_hau_avg_inf_mus[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==8, dl_lab_arr==8)\n",
    "        val_ndsc_inf_mus[i] = nDSC\n",
    "\n",
    "    # SUPERIOR RECTUS MUSCLE\n",
    "    if np.count_nonzero(reg_lab_arr==9)==0 or np.count_nonzero(dl_lab_arr==9)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==9, dl_lab_sitk==9)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_sup_mus[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_sup_mus[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==9, dl_lab_sitk==9)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_sup_mus[i] = hausdorf_distance_avg\n",
    "        # nDSCvol\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==9, dl_lab_arr==9)\n",
    "        val_ndsc_sup_mus[i] = nDSC\n",
    "\n",
    "    # ALL LABELS\n",
    "    # DSC\n",
    "    dsc = (val_dsc_lens[i]+val_dsc_globe[i]+val_dsc_nerve[i]+val_dsc_int_fat[i]+val_dsc_ext_fat[i]+val_dsc_lat_mus[i]+val_dsc_med_mus[i]+val_dsc_inf_mus[i]+val_dsc_sup_mus[i])/9\n",
    "    val_dsc[i] = dsc\n",
    "    # Volume\n",
    "    vol = (val_vol_lens[i]+val_vol_globe[i]+val_vol_nerve[i]+val_vol_int_fat[i]+val_vol_ext_fat[i]+val_vol_lat_mus[i]+val_vol_med_mus[i]+val_vol_inf_mus[i]+val_vol_sup_mus[i])/9\n",
    "    val_vol[i] = vol\n",
    "    # Hausdorff distance\n",
    "    hau_avg = (val_hau_avg_lens[i]+val_hau_avg_globe[i]+val_hau_avg_nerve[i]+val_hau_avg_int_fat[i]+val_hau_avg_ext_fat[i]+val_hau_avg_lat_mus[i]+val_hau_avg_med_mus[i]+val_hau_avg_inf_mus[i]+val_hau_avg_sup_mus[i])/9\n",
    "    val_hau_avg[i] = hau_avg\n",
    "    # nDSC\n",
    "    nDSC = (val_ndsc_lens[i]+val_ndsc_globe[i]+val_ndsc_nerve[i]+val_ndsc_int_fat[i]+val_ndsc_ext_fat[i]+val_ndsc_lat_mus[i]+val_ndsc_med_mus[i]+val_ndsc_inf_mus[i]+val_ndsc_sup_mus[i])/9\n",
    "    val_ndsc[i] = nDSC\n",
    "\n",
    "    i+=1\n",
    "    # if i==1:\n",
    "    #     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save values to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "metrics = [\n",
    "    'Subject',  'DSC_all',     'Haus_avg_all',     'Volume_all',     'nDSC_all', \n",
    "                'DSC_lens',    'Haus_avg_lens',    'Volume_lens',    'nDSC_lens',  \n",
    "                'DSC_globe',   'Haus_avg_globe',   'Volume_globe',   'nDSC_globe', \n",
    "                'DSC_nerve',   'Haus_avg_nerve',   'Volume_nerve',   'nDSC_nerve', \n",
    "                'DSC_int_fat', 'Haus_avg_int_fat', 'Volume_int_fat', 'nDSC_int_fat',\n",
    "                'DSC_ext_fat', 'Haus_avg_ext_fat', 'Volume_ext_fat', 'nDSC_ext_fat',\n",
    "                'DSC_lat_mus', 'Haus_avg_lat_mus', 'Volume_lat_mus', 'nDSC_lat_mus',\n",
    "                'DSC_med_mus', 'Haus_avg_med_mus', 'Volume_med_mus', 'nDSC_med_mus',\n",
    "                'DSC_inf_mus', 'Haus_avg_inf_mus', 'Volume_inf_mus', 'nDSC_inf_mus',\n",
    "                'DSC_sup_mus', 'Haus_avg_sup_mus', 'Volume_sup_mus', 'nDSC_sup_mus'\n",
    "]\n",
    "\n",
    "vals = np.array([\n",
    "    name_subject,   val_dsc,         val_hau_avg,         val_vol,         val_ndsc,        \n",
    "                    val_dsc_lens,    val_hau_avg_lens,    val_vol_lens,    val_ndsc_lens,   \n",
    "                    val_dsc_globe,   val_hau_avg_globe,   val_vol_globe,   val_ndsc_globe,  \n",
    "                    val_dsc_nerve,   val_hau_avg_nerve,   val_vol_nerve,   val_ndsc_nerve,  \n",
    "                    val_dsc_int_fat, val_hau_avg_int_fat, val_vol_int_fat, val_ndsc_int_fat,\n",
    "                    val_dsc_ext_fat, val_hau_avg_ext_fat, val_vol_ext_fat, val_ndsc_ext_fat,\n",
    "                    val_dsc_lat_mus, val_hau_avg_lat_mus, val_vol_lat_mus, val_ndsc_lat_mus,\n",
    "                    val_dsc_med_mus, val_hau_avg_med_mus, val_vol_med_mus, val_ndsc_med_mus,\n",
    "                    val_dsc_inf_mus, val_hau_avg_inf_mus, val_vol_inf_mus, val_ndsc_inf_mus,\n",
    "                    val_dsc_sup_mus, val_hau_avg_sup_mus, val_vol_sup_mus, val_ndsc_sup_mus,\n",
    "])\n",
    "\n",
    "vals = vals.T\n",
    "\n",
    "with open('/mnt/sda1/Repos/a-eye/Output/similarity/sim_reg_vs_nnunet_raw.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(metrics)\n",
    "    writer.writerows(vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read values from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import Line2D\n",
    "import numpy as np\n",
    "\n",
    "csv_file = pd.read_csv('/mnt/sda1/Repos/a-eye/Output/similarity/sim_reg_vs_nnunet_raw.csv')\n",
    "# csv_file = csv_file[~csv_file['Subject'].isin([int(x) for x in bad_files])].reset_index(drop=True)\n",
    "\n",
    "# Dataframes {DSC, nDSC, Volume (voxels)} separate labels for N=5 only\n",
    "data_dsc = [csv_file['DSC_all'], csv_file['DSC_lens'], csv_file['DSC_globe'], csv_file['DSC_nerve'], csv_file['DSC_int_fat'], csv_file['DSC_ext_fat'], csv_file['DSC_lat_mus'], csv_file['DSC_med_mus'], csv_file['DSC_inf_mus'], csv_file['DSC_sup_mus']]\n",
    "data_ndsc = [csv_file['nDSC_all'],  csv_file['nDSC_lens'], csv_file['nDSC_globe'], csv_file['nDSC_nerve'], csv_file['nDSC_int_fat'], csv_file['nDSC_ext_fat'], csv_file['nDSC_lat_mus'], csv_file['nDSC_med_mus'], csv_file['nDSC_inf_mus'], csv_file['nDSC_sup_mus']]\n",
    "data_vol = [csv_file['Volume_all'], csv_file['Volume_lens'], csv_file['Volume_globe'], csv_file['Volume_nerve'], csv_file['Volume_int_fat'], csv_file['Volume_ext_fat'], csv_file['Volume_lat_mus'], csv_file['Volume_med_mus'], csv_file['Volume_inf_mus'], csv_file['Volume_sup_mus']]\n",
    "data_haus = [csv_file['Haus_avg_all'], csv_file['Haus_avg_lens'], csv_file['Haus_avg_globe'], csv_file['Haus_avg_nerve'], csv_file['Haus_avg_int_fat'], csv_file['Haus_avg_ext_fat'], csv_file['Haus_avg_lat_mus'], csv_file['Haus_avg_med_mus'], csv_file['Haus_avg_inf_mus'], csv_file['Haus_avg_sup_mus']]\n",
    "\n",
    "labels = ['lens', 'globe', 'nerve', 'intraconal fat', 'extraconal fat', 'lateral rectus muscle', 'medial rectus muscle', 'inferior rectus muscle', 'superior rectus muscle']\n",
    "median = [np.around(np.median(x), 2) for x in data_dsc]\n",
    "for i in range(len(labels)):\n",
    "    print(labels[i], median[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "fig, axs = plt.subplots(3, figsize=(20,10), sharex=True)\n",
    "fig.canvas.manager.set_window_title('Similarity metrics ATLAS vs DL')\n",
    "fig.suptitle('Similarity metrics ATLAS vs nnUNet')\n",
    "fig.patch.set_facecolor('white')\n",
    "# fig.tight_layout(pad=2)\n",
    "\n",
    "# Set labels and titles\n",
    "axs[0].set_title('DSC')\n",
    "axs[0].set_ylim([0, 1])\n",
    "axs[1].set_title('Hausdorff distance')\n",
    "axs[1].set_ylim([0, 3])\n",
    "axs[2].set_title('Volume difference')\n",
    "axs[2].set_ylim([-2, 2])\n",
    "\n",
    "# Outliers\n",
    "flierprops = dict(markerfacecolor='0.9', markersize=2, linestyle='none')\n",
    "\n",
    "# Boxplot & Swarmplot (points)\n",
    "graph1 = sns.boxplot(data=data_dsc, ax=axs[0], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "graph2 = sns.boxplot(data=data_haus, ax=axs[1], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "graph3 = sns.boxplot(data=data_vol, ax=axs[2], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "axs[2].set_xticklabels(['all','lens','globe','nerve','int_fat','ext_fat','lat_mus','med_mus','inf_mus','sup_mus'])\n",
    "\n",
    "plt.show\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('/mnt/sda1/Repos/a-eye/Output/similarity/sim_reg_vs_nnunet.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nDSC columns from csv_file\n",
    "csv_file = csv_file.drop(columns=['nDSC_all', 'nDSC_lens', 'nDSC_globe', 'nDSC_nerve', 'nDSC_int_fat', 'nDSC_ext_fat', 'nDSC_lat_mus', 'nDSC_med_mus', 'nDSC_inf_mus', 'nDSC_sup_mus'])\n",
    "# reorder columns, first the DSCs, then the Hausdorff distances, then the volumes\n",
    "csv_file = csv_file[['Subject', 'DSC_all', 'DSC_lens', 'DSC_globe', 'DSC_nerve', 'DSC_int_fat', 'DSC_ext_fat', 'DSC_lat_mus', 'DSC_med_mus', 'DSC_inf_mus', 'DSC_sup_mus', 'Haus_avg_all', 'Haus_avg_lens', 'Haus_avg_globe', 'Haus_avg_nerve', 'Haus_avg_int_fat', 'Haus_avg_ext_fat', 'Haus_avg_lat_mus', 'Haus_avg_med_mus', 'Haus_avg_inf_mus', 'Haus_avg_sup_mus', 'Volume_all', 'Volume_lens', 'Volume_globe', 'Volume_nerve', 'Volume_int_fat', 'Volume_ext_fat', 'Volume_lat_mus', 'Volume_med_mus', 'Volume_inf_mus', 'Volume_sup_mus']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk test for normality for each column of csv_file\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "for i in range(1, len(csv_file.columns)):\n",
    "    stat, p = shapiro(csv_file.iloc[:,i])\n",
    "    print(f'{csv_file.columns[i]}: Statistics={stat}, p={p}')\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('Sample does not look Gaussian (reject H0)')\n",
    "    # histogram plot\n",
    "    plt.hist(csv_file.iloc[:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers - IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_df1 = pd.DataFrame(columns=['Column', 'Outlier Subject'])\n",
    "bounds_df = pd.DataFrame(columns=['Column', 'Lower Bound', 'Upper Bound']) # dataframe for bounds\n",
    "\n",
    "# Calculate the IQR for each column\n",
    "Q1 = csv_file.quantile(0.25)\n",
    "Q3 = csv_file.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Find the outliers for each column\n",
    "for column in csv_file.columns[1:]:\n",
    "    lower_bound = Q1[column] - 1.5 * IQR[column]\n",
    "    upper_bound = Q3[column] + 1.5 * IQR[column]\n",
    "\n",
    "    # Append bounds to the bounds_df DataFrame\n",
    "    new_row = pd.DataFrame({'Column': [column], 'Lower Bound': [lower_bound], 'Upper Bound': [upper_bound]})\n",
    "    bounds_df = pd.concat([bounds_df, new_row], ignore_index=True)\n",
    "\n",
    "    column_outliers = csv_file[(csv_file[column] < lower_bound) | (csv_file[column] > upper_bound)]\n",
    "    new_row = pd.DataFrame({'Column': [column], 'Outlier Subject': [column_outliers['Subject'].values]})\n",
    "    outliers_df1 = pd.concat([outliers_df1, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new DataFrame with the same structure as csv_file but filled with False\n",
    "outliers_df2 = pd.DataFrame(False, index=csv_file.index, columns=csv_file.columns)\n",
    "\n",
    "# Copy the 'Subject' column from csv_file to outliers_df\n",
    "outliers_df2['Subject'] = csv_file['Subject']\n",
    "\n",
    "# Calculate the IQR for each column excluding 'Subject'\n",
    "Q1 = csv_file.drop('Subject', axis=1).quantile(0.25)\n",
    "Q3 = csv_file.drop('Subject', axis=1).quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Find the outliers for each column excluding 'Subject'\n",
    "for column in csv_file.columns:\n",
    "    if column != 'Subject':\n",
    "        lower_bound = Q1[column] - 1.5 * IQR[column]\n",
    "        upper_bound = Q3[column] + 1.5 * IQR[column]\n",
    "        # Update outliers_df with True for outliers\n",
    "        outliers_df2[column] = (csv_file[column] < lower_bound) | (csv_file[column] > upper_bound)\n",
    "\n",
    "# Replace all False values with ''\n",
    "outliers_df2 = outliers_df2.replace(False, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdataframe of outliers_df2 with 'Subject' and DSC columns\n",
    "outliers_df2_dsc = outliers_df2[['Subject', 'DSC_all', 'DSC_lens', 'DSC_globe', 'DSC_nerve', 'DSC_int_fat', 'DSC_ext_fat', 'DSC_lat_mus', 'DSC_med_mus', 'DSC_inf_mus', 'DSC_sup_mus']]\n",
    "# subdataframe of outliers_df2 with 'Subject' and Hausdorff columns\n",
    "outliers_df2_haus = outliers_df2[['Subject', 'Haus_avg_all', 'Haus_avg_lens', 'Haus_avg_globe', 'Haus_avg_nerve', 'Haus_avg_int_fat', 'Haus_avg_ext_fat', 'Haus_avg_lat_mus', 'Haus_avg_med_mus', 'Haus_avg_inf_mus', 'Haus_avg_sup_mus']]\n",
    "# subdataframe of outliers_df2 with 'Subject' and Volume columns\n",
    "outliers_df2_vol = outliers_df2[['Subject', 'Volume_all', 'Volume_lens', 'Volume_globe', 'Volume_nerve', 'Volume_int_fat', 'Volume_ext_fat', 'Volume_lat_mus', 'Volume_med_mus', 'Volume_inf_mus', 'Volume_sup_mus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of 'subject' from outliers_df2_dsc that appears more than once as true\n",
    "outliers_dsc = []\n",
    "for column in outliers_df2_dsc.columns[1:]:\n",
    "    outliers_dsc.append(outliers_df2_dsc[outliers_df2_dsc[column] == True]['Subject'].values)\n",
    "outliers_dsc = [item for sublist in outliers_dsc for item in sublist]\n",
    "outliers_dsc = [item for item in outliers_dsc if outliers_dsc.count(item) > 2]\n",
    "# remove duplicates\n",
    "outliers_dsc = list(dict.fromkeys(outliers_dsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of 'subject' from outliers_df2_haus that appears more than once as true\n",
    "outliers_haus = []\n",
    "for column in outliers_df2_haus.columns[1:]:\n",
    "    outliers_haus.append(outliers_df2_haus[outliers_df2_haus[column] == True]['Subject'].values)\n",
    "outliers_haus = [item for sublist in outliers_haus for item in sublist]\n",
    "outliers_haus = [item for item in outliers_haus if outliers_haus.count(item) > 2]\n",
    "# remove duplicates\n",
    "outliers_haus = list(dict.fromkeys(outliers_haus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of 'subject' from outliers_df2_vol that appears more than once as true\n",
    "outliers_vol = []\n",
    "for column in outliers_df2_vol.columns[1:]:\n",
    "    outliers_vol.append(outliers_df2_vol[outliers_df2_vol[column] == True]['Subject'].values)\n",
    "outliers_vol = [item for sublist in outliers_vol for item in sublist]\n",
    "outliers_vol = [item for item in outliers_vol if outliers_vol.count(item) > 2]\n",
    "# remove duplicates\n",
    "outliers_vol = list(dict.fromkeys(outliers_vol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint dataframe of outliers_dsc, outliers_haus, outliers_vol without 'subject' duplicates\n",
    "outliers_df = pd.DataFrame({'Subject': outliers_dsc + outliers_haus + outliers_vol})\n",
    "# remove duplicates\n",
    "outliers_df = outliers_df.drop_duplicates(subset=['Subject']).reset_index(drop=True)\n",
    "# to list\n",
    "outliers_list = outliers_df['Subject'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reports to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc2_atlas = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_atlas.xlsx\")\n",
    "qc3_atlas = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_vol_atlas.xlsx\")\n",
    "qc2_nnunet = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_nnunet.xlsx\")\n",
    "qc3_nnunet = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_vol_nnunet.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_aux = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/df_aux.csv\")\n",
    "\n",
    "# subdataframe of df_aux with the outliers_list\n",
    "outliers_reports_df = df_aux[df_aux['subject'].isin(outliers_list)]\n",
    "# add 'my_rate' column to outliers_reports_df\n",
    "outliers_reports_df.loc[:, 'my_rate'] = 0.0\n",
    "# order outliers_reports_df by 'report'\n",
    "outliers_reports_df = outliers_reports_df.sort_values(by=['report'])\n",
    "# remove subjects from outliers_reports_df that are in qc3_atlas - useful to view the non-repeated reports\n",
    "outliers_reports_df = outliers_reports_df[~outliers_reports_df['subject'].isin(qc3_atlas['subject'])]\n",
    "outliers_reports_df = outliers_reports_df[~outliers_reports_df['subject'].isin(qc2_atlas['subject'])]\n",
    "outliers_reports_df = outliers_reports_df[~outliers_reports_df['subject'].isin(qc3_nnunet['subject'])]\n",
    "outliers_reports_df = outliers_reports_df[~outliers_reports_df['subject'].isin(qc2_nnunet['subject'])]\n",
    "# add column 'comments' to outliers_reports_df\n",
    "outliers_reports_df.loc[:, 'comments'] = ''\n",
    "# save outliers_reports_df to excel file\n",
    "# outliers_reports_df.to_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_atlas.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy reports that appear in outliers_reports from /home/jaimebarranco/Desktop/MRI-QC/fetal/fetalqc_non-labeled-dataset to /home/jaimebarranco/Downloads/reports \n",
    "import shutil\n",
    "import os\n",
    "\n",
    "reports_folder = '/home/jaimebarranco/Downloads/reports/'\n",
    "# create reports folder if it doesn't exist\n",
    "if not os.path.exists(reports_folder):\n",
    "    os.makedirs(reports_folder)\n",
    "else:\n",
    "    # remove content from reports folder\n",
    "    for filename in os.listdir(reports_folder):\n",
    "        file_path = os.path.join(reports_folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "for report in outliers_reports_df['report']:\n",
    "    src = f'/home/jaimebarranco/Desktop/MRI-QC/fetal/fetalqc_non-labeled-dataset/{report}_report.html'\n",
    "    dst = f'/home/jaimebarranco/Downloads/reports/{report}_report.html'\n",
    "    shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace row in outliers_reports_df with the same subject as in qc2_atlas\n",
    "for i in range(len(qc2_atlas)):\n",
    "    outliers_reports_df.loc[outliers_reports_df['subject'] == qc2_atlas.iloc[i]['subject'], 'my_rate'] = qc2_atlas.iloc[i]['my_rate']\n",
    "    outliers_reports_df.loc[outliers_reports_df['subject'] == qc2_atlas.iloc[i]['subject'], 'comments'] = qc2_atlas.iloc[i]['comments']\n",
    "    # replace row in outliers_reports_df with the same subject as in qc2_atlas\n",
    "\n",
    "# replace row in outliers_reports_df with the same subject as in qc3_atlas\n",
    "for i in range(len(qc3_atlas)):\n",
    "    outliers_reports_df.loc[outliers_reports_df['subject'] == qc3_atlas.iloc[i]['subject'], 'my_rate'] = qc3_atlas.iloc[i]['my_rate']\n",
    "    outliers_reports_df.loc[outliers_reports_df['subject'] == qc3_atlas.iloc[i]['subject'], 'comments'] = qc3_atlas.iloc[i]['comments']\n",
    "\n",
    "# replace row in outliers_reports_df with the same subject as in qc2_nnunet\n",
    "for i in range(len(qc2_nnunet)):\n",
    "    outliers_reports_df.loc[outliers_reports_df['subject'] == qc2_nnunet.iloc[i]['subject'], 'my_rate'] = qc2_nnunet.iloc[i]['my_rate']\n",
    "    outliers_reports_df.loc[outliers_reports_df['subject'] == qc2_nnunet.iloc[i]['subject'], 'comments'] = qc2_nnunet.iloc[i]['comments']\n",
    "\n",
    "# replace row in outliers_reports_df with the same subject as in qc3_nnunet\n",
    "for i in range(len(qc3_nnunet)):\n",
    "    outliers_reports_df.loc[outliers_reports_df['subject'] == qc3_nnunet.iloc[i]['subject'], 'my_rate'] = qc3_nnunet.iloc[i]['my_rate']\n",
    "    outliers_reports_df.loc[outliers_reports_df['subject'] == qc3_nnunet.iloc[i]['subject'], 'comments'] = qc3_nnunet.iloc[i]['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save outliers_reports_df to excel file\n",
    "outliers_reports_df.to_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_atlas_nnunet.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "qc2_atlas_nnunet = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_atlas_nnunet.xlsx\")\n",
    "\n",
    "qc2_atlas_nnunet.to_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_atlas_nnunet.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeled dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATLAS vs nnUNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import Line2D\n",
    "import pandas as pd\n",
    "\n",
    "nnunet_path = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/nnUNet/nnUNet/nnUNet_inference/nnUNet_inference_labeled_dataset/' \n",
    "\n",
    "# CSVs\n",
    "csv_dsc_reg = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/3D_multilabel/experiment_0/test_orig/data_dsc_reg.csv'\n",
    "csv_dsc_dl = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/3D_multilabel/experiment_0/test_orig/data_dsc.csv'\n",
    "csv_dsc_nn = f'{nnunet_path}data_dsc_nn.csv'\n",
    "\n",
    "# Pandas read CSV\n",
    "df_reg = pd.read_csv(csv_dsc_reg)\n",
    "df_dl = pd.read_csv(csv_dsc_dl)\n",
    "df_nn = pd.read_csv(csv_dsc_nn)\n",
    "\n",
    "# Gather data from generated dataframes\n",
    "df_dsc = [\n",
    "    df_reg['DSC_all'], df_nn['DSC_all'], \n",
    "    df_reg['DSC_lens'], df_nn['DSC_lens'], \n",
    "    df_reg['DSC_globe'], df_nn['DSC_globe'], \n",
    "    df_reg['DSC_nerve'], df_nn['DSC_nerve'], \n",
    "    df_reg['DSC_int_fat'], df_nn['DSC_int_fat'], \n",
    "    df_reg['DSC_ext_fat'], df_nn['DSC_ext_fat'], \n",
    "    df_reg['DSC_lat_mus'], df_nn['DSC_lat_mus'], \n",
    "    df_reg['DSC_med_mus'], df_nn['DSC_med_mus'], \n",
    "    df_reg['DSC_inf_mus'], df_nn['DSC_inf_mus'], \n",
    "    df_reg['DSC_sup_mus'], df_nn['DSC_sup_mus']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import Line2D\n",
    "import numpy as np\n",
    "\n",
    "# Figure\n",
    "fig, axs = plt.subplots(figsize=(28,10))\n",
    "fig.canvas.manager.set_window_title('DSC per label')\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Legend\n",
    "legend_elements = [Line2D([0], [0], color='green', lw=4, label='Atlas-based'),\n",
    "    Line2D([0], [0], color='purple', lw=4, label='nnUNet'),\n",
    "    Line2D([], [], color='black', label='mean', marker='+', markersize=5, linestyle='None')]\n",
    "\n",
    "# Axis\n",
    "colours_palette = ['green','purple','green','purple','green','purple','green','purple','green','purple','green','purple','green','purple','green','purple','green','purple','green','purple']\n",
    "meanpointprops = {\"marker\":\"+\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\", \"markersize\":\"10\"}\n",
    "ax = sns.boxplot(data=df_dsc, palette=colours_palette, showmeans=True, meanprops=meanpointprops)\n",
    "# ax = sns.swarmplot(data=df_dsc)\n",
    "ax.set_title('DSC')\n",
    "ax.legend(handles=legend_elements)\n",
    "ax.set(ylabel=\"Value\")\n",
    "ax.set_xticklabels([\n",
    "    f'all \\n{np.around(np.mean(df_dsc[0]), 3)}', f'all \\n{np.around(np.mean(df_dsc[1]), 3)}',\n",
    "    f'lens \\n{np.around(np.mean(df_dsc[2]), 3)}', f'lens \\n{np.around(np.mean(df_dsc[3]), 3)}',\n",
    "    f'globe \\n{np.around(np.mean(df_dsc[4]), 3)}', f'globe \\n{np.around(np.mean(df_dsc[5]), 3)}',\n",
    "    f'nerve \\n{np.around(np.mean(df_dsc[6]), 3)}', f'nerve \\n{np.around(np.mean(df_dsc[7]), 3)}',\n",
    "    f'int_fat \\n{np.around(np.mean(df_dsc[8]), 3)}', f'int_fat \\n{np.around(np.mean(df_dsc[9]), 3)}',\n",
    "    f'ext_fat \\n{np.around(np.mean(df_dsc[10]), 3)}', f'ext_fat \\n{np.around(np.mean(df_dsc[11]), 3)}',\n",
    "    f'lat_mus \\n{np.around(np.mean(df_dsc[12]), 3)}', f'lat_mus \\n{np.around(np.mean(df_dsc[12]), 3)}',\n",
    "    f'med_mus \\n{np.around(np.mean(df_dsc[14]), 3)}', f'med_mus \\n{np.around(np.mean(df_dsc[13]), 3)}',\n",
    "    f'inf_mus \\n{np.around(np.mean(df_dsc[16]), 3)}', f'inf_mus \\n{np.around(np.mean(df_dsc[14]), 3)}',\n",
    "    f'sup_mus \\n{np.around(np.mean(df_dsc[18]), 3)}', f'sup_mus \\n{np.around(np.mean(df_dsc[15]), 3)}'])\n",
    "\n",
    "ax.set_yticks(np.arange(0.5, 1.02, 0.02))\n",
    "\n",
    "plt.show\n",
    "\n",
    "# plt.savefig(f'{nnunet_path}reg_vs_nn.png', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL vs nnUNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import Line2D\n",
    "import pandas as pd\n",
    "\n",
    "nnunet_path = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/nnUNet/nnUNet/nnUNet_inference/nnUNet_inference_labeled_dataset/' \n",
    "\n",
    "# CSVs\n",
    "csv_dsc_reg = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/3D_multilabel/experiment_0/test_orig/data_dsc_reg.csv'\n",
    "csv_dsc_dl = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/3D_multilabel/experiment_0/test_orig/data_dsc.csv'\n",
    "csv_dsc_nn = f'{nnunet_path}data_dsc_nn.csv'\n",
    "\n",
    "# Pandas read CSV\n",
    "df_reg = pd.read_csv(csv_dsc_reg)\n",
    "df_dl = pd.read_csv(csv_dsc_dl)\n",
    "df_nn = pd.read_csv(csv_dsc_nn)\n",
    "\n",
    "# Gather data from generated dataframes\n",
    "df_dsc = [\n",
    "    df_dl['DSC_all'], df_nn['DSC_all'], \n",
    "    df_dl['DSC_lens'], df_nn['DSC_lens'], \n",
    "    df_dl['DSC_globe'], df_nn['DSC_globe'], \n",
    "    df_dl['DSC_nerve'], df_nn['DSC_nerve'], \n",
    "    df_dl['DSC_int_fat'], df_nn['DSC_int_fat'], \n",
    "    df_dl['DSC_ext_fat'], df_nn['DSC_ext_fat'], \n",
    "    df_dl['DSC_lat_mus'], df_nn['DSC_lat_mus'], \n",
    "    df_dl['DSC_med_mus'], df_nn['DSC_med_mus'], \n",
    "    df_dl['DSC_inf_mus'], df_nn['DSC_inf_mus'], \n",
    "    df_dl['DSC_sup_mus'], df_nn['DSC_sup_mus']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import Line2D\n",
    "import numpy as np\n",
    "\n",
    "# Figure\n",
    "fig, axs = plt.subplots(figsize=(28,10))\n",
    "fig.canvas.manager.set_window_title('DSC per label')\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Legend\n",
    "legend_elements = [Line2D([0], [0], color='orange', lw=4, label='DL'),\n",
    "    Line2D([0], [0], color='purple', lw=4, label='nnUNet'),\n",
    "    Line2D([], [], color='black', label='mean', marker='+', markersize=5, linestyle='None')]\n",
    "\n",
    "# Axis\n",
    "colours_palette = ['orange','purple','orange','purple','orange','purple','orange','purple','orange','purple','orange','purple','orange','purple','orange','purple','orange','purple','orange','purple']\n",
    "meanpointprops = {\"marker\":\"+\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\", \"markersize\":\"10\"}\n",
    "ax = sns.boxplot(data=df_dsc, palette=colours_palette, showmeans=True, meanprops=meanpointprops)\n",
    "# ax = sns.swarmplot(data=df_dsc)\n",
    "ax.set_title('DSC')\n",
    "ax.legend(handles=legend_elements)\n",
    "ax.set(ylabel=\"Value\")\n",
    "ax.set_xticklabels([\n",
    "    f'all \\n{np.around(np.mean(df_dsc[0]), 3)}', f'all \\n{np.around(np.mean(df_dsc[1]), 3)}',\n",
    "    f'lens \\n{np.around(np.mean(df_dsc[2]), 3)}', f'lens \\n{np.around(np.mean(df_dsc[3]), 3)}',\n",
    "    f'globe \\n{np.around(np.mean(df_dsc[4]), 3)}', f'globe \\n{np.around(np.mean(df_dsc[5]), 3)}',\n",
    "    f'nerve \\n{np.around(np.mean(df_dsc[6]), 3)}', f'nerve \\n{np.around(np.mean(df_dsc[7]), 3)}',\n",
    "    f'int_fat \\n{np.around(np.mean(df_dsc[8]), 3)}', f'int_fat \\n{np.around(np.mean(df_dsc[9]), 3)}',\n",
    "    f'ext_fat \\n{np.around(np.mean(df_dsc[10]), 3)}', f'ext_fat \\n{np.around(np.mean(df_dsc[11]), 3)}',\n",
    "    f'lat_mus \\n{np.around(np.mean(df_dsc[12]), 3)}', f'lat_mus \\n{np.around(np.mean(df_dsc[12]), 3)}',\n",
    "    f'med_mus \\n{np.around(np.mean(df_dsc[14]), 3)}', f'med_mus \\n{np.around(np.mean(df_dsc[13]), 3)}',\n",
    "    f'inf_mus \\n{np.around(np.mean(df_dsc[16]), 3)}', f'inf_mus \\n{np.around(np.mean(df_dsc[14]), 3)}',\n",
    "    f'sup_mus \\n{np.around(np.mean(df_dsc[18]), 3)}', f'sup_mus \\n{np.around(np.mean(df_dsc[15]), 3)}'])\n",
    "ax.set_yticks(np.arange(0.5, 1.02, 0.02))\n",
    "\n",
    "plt.show\n",
    "\n",
    "plt.savefig(f'{nnunet_path}dl_vs_nn.png', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATLAS vs DL vs nnUNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import Line2D\n",
    "import pandas as pd\n",
    "\n",
    "nnunet_path = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/nnUNet/nnUNet/nnUNet_inference/nnUNet_inference_labeled_dataset/' \n",
    "\n",
    "# CSVs\n",
    "csv_dsc_reg = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/3D_multilabel/experiment_0/test_orig/data_dsc_reg.csv'\n",
    "csv_dsc_dl = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/3D_multilabel/experiment_0/test_orig/data_dsc.csv'\n",
    "csv_dsc_nn = f'{nnunet_path}data_dsc_nn.csv'\n",
    "\n",
    "# Pandas read CSV\n",
    "df_reg = pd.read_csv(csv_dsc_reg)\n",
    "df_dl = pd.read_csv(csv_dsc_dl)\n",
    "df_nn = pd.read_csv(csv_dsc_nn)\n",
    "\n",
    "# Gather data from generated dataframes\n",
    "df_dsc = [\n",
    "    df_reg['DSC_all'], df_dl['DSC_all'], df_nn['DSC_all'],\n",
    "    df_reg['DSC_lens'], df_dl['DSC_lens'], df_nn['DSC_lens'],\n",
    "    df_reg['DSC_globe'], df_dl['DSC_globe'], df_nn['DSC_globe'],\n",
    "    df_reg['DSC_nerve'], df_dl['DSC_nerve'], df_nn['DSC_nerve'],\n",
    "    df_reg['DSC_int_fat'], df_dl['DSC_int_fat'], df_nn['DSC_int_fat'],\n",
    "    df_reg['DSC_ext_fat'], df_dl['DSC_ext_fat'], df_nn['DSC_ext_fat'],\n",
    "    df_reg['DSC_lat_mus'], df_dl['DSC_lat_mus'], df_nn['DSC_lat_mus'],\n",
    "    df_reg['DSC_med_mus'], df_dl['DSC_med_mus'], df_nn['DSC_med_mus'],\n",
    "    df_reg['DSC_inf_mus'], df_dl['DSC_inf_mus'], df_nn['DSC_inf_mus'],\n",
    "    df_reg['DSC_sup_mus'], df_dl['DSC_sup_mus'], df_nn['DSC_sup_mus']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import Line2D\n",
    "import numpy as np\n",
    "\n",
    "# Figure\n",
    "fig, axs = plt.subplots(figsize=(30,10))\n",
    "fig.canvas.manager.set_window_title('DSC per label')\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='green', lw=4, label='Atlas-based'),\n",
    "    Line2D([0], [0], color='orange', lw=4, label='DL'),\n",
    "    Line2D([0], [0], color='purple', lw=4, label='nnUNet'),\n",
    "    Line2D([], [], color='black', label='mean', marker='+', markersize=5, linestyle='None')]\n",
    "\n",
    "# Axis\n",
    "colours_palette = ['green','orange','purple']*10\n",
    "meanpointprops = {\"marker\":\"+\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\", \"markersize\":\"10\"}\n",
    "ax = sns.boxplot(data=df_dsc, palette=colours_palette, showmeans=True, meanprops=meanpointprops)\n",
    "# ax = sns.swarmplot(data=df_dsc)\n",
    "ax.set_title('DSC')\n",
    "ax.legend(handles=legend_elements)\n",
    "ax.set(ylabel=\"Value\")\n",
    "ax.set_xticklabels([\n",
    "    f'all \\n{np.around(np.mean(df_dsc[0]), 3)}', f'all \\n{np.around(np.mean(df_dsc[1]), 3)}', f'all \\n{np.around(np.mean(df_dsc[2]), 3)}',\n",
    "    f'lens \\n{np.around(np.mean(df_dsc[3]), 3)}', f'lens \\n{np.around(np.mean(df_dsc[4]), 3)}', f'lens \\n{np.around(np.mean(df_dsc[5]), 3)}',\n",
    "    f'globe \\n{np.around(np.mean(df_dsc[6]), 3)}', f'globe \\n{np.around(np.mean(df_dsc[7]), 3)}', f'globe \\n{np.around(np.mean(df_dsc[8]), 3)}',\n",
    "    f'nerve \\n{np.around(np.mean(df_dsc[9]), 3)}', f'nerve \\n{np.around(np.mean(df_dsc[10]), 3)}', f'nerve \\n{np.around(np.mean(df_dsc[11]), 3)}',\n",
    "    f'int_fat \\n{np.around(np.mean(df_dsc[12]), 3)}', f'int_fat \\n{np.around(np.mean(df_dsc[13]), 3)}', f'int_fat \\n{np.around(np.mean(df_dsc[14]), 3)}',\n",
    "    f'ext_fat \\n{np.around(np.mean(df_dsc[15]), 3)}', f'ext_fat \\n{np.around(np.mean(df_dsc[16]), 3)}', f'ext_fat \\n{np.around(np.mean(df_dsc[17]), 3)}',\n",
    "    f'lat_mus \\n{np.around(np.mean(df_dsc[18]), 3)}', f'lat_mus \\n{np.around(np.mean(df_dsc[19]), 3)}', f'lat_mus \\n{np.around(np.mean(df_dsc[20]), 3)}',\n",
    "    f'med_mus \\n{np.around(np.mean(df_dsc[21]), 3)}', f'med_mus \\n{np.around(np.mean(df_dsc[22]), 3)}', f'med_mus \\n{np.around(np.mean(df_dsc[23]), 3)}',\n",
    "    f'inf_mus \\n{np.around(np.mean(df_dsc[24]), 3)}', f'inf_mus \\n{np.around(np.mean(df_dsc[25]), 3)}', f'inf_mus \\n{np.around(np.mean(df_dsc[26]), 3)}',\n",
    "    f'sup_mus \\n{np.around(np.mean(df_dsc[27]), 3)}', f'sup_mus \\n{np.around(np.mean(df_dsc[28]), 3)}', f'sup_mus \\n{np.around(np.mean(df_dsc[29]), 3)}'])\n",
    "ax.set_yticks(np.arange(0.5, 1.02, 0.02))\n",
    "\n",
    "plt.show\n",
    "\n",
    "plt.savefig(f'{nnunet_path}reg_vs_dl_vs_nn.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New manual annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QC1: remove subjects from QC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_aux = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/df_aux.csv\")\n",
    "qc1 = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_qc1 = df_aux.loc[df_aux['bids'].isin(qc1['bids'])]['subject'].tolist()\n",
    "list_qc1 = [str(x) for x in list_qc1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATLAS vs Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,sys, glob\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "atlas_seg_path = '/home/jaimebarranco/Desktop/new_manual_annotations/segmentations/atlas'\n",
    "atlas_cropped_path = '/home/jaimebarranco/Desktop/new_manual_annotations/segmentations/atlas_cropped'\n",
    "manual_seg_path = '/home/jaimebarranco/Desktop/new_manual_annotations/segmentations/manual'\n",
    "output_path = '/home/jaimebarranco/Desktop/new_manual_annotations/segmentations/manual_cropped'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "bound = 15 # for the expanded bounding box\n",
    "\n",
    "i=0\n",
    "for file in sorted(glob.glob(atlas_seg_path+'/*.nii.gz')):\n",
    "\n",
    "    subject = os.path.basename(file).split('.')[0]\n",
    "    # print(f'subject = {subject}')\n",
    "\n",
    "    if os.path.exists(os.path.join(output_path, f'{subject}.nii.gz')):\n",
    "        continue\n",
    "    else:\n",
    "        # Paths\n",
    "        atlas_seg = f'{atlas_seg_path}/{subject}.nii.gz'\n",
    "        manual_seg = f'{manual_seg_path}/{subject}.nii.gz'\n",
    "        atlas_cropped = f'{atlas_cropped_path}/{subject}.nii.gz'\n",
    "        \n",
    "        # sizes\n",
    "        atlas_image = sitk.ReadImage(atlas_seg)\n",
    "        atlas_cropped_image = sitk.ReadImage(atlas_cropped)\n",
    "        manual_image = sitk.ReadImage(manual_seg)\n",
    "        atlas_x_size, atlas_y_size, atlas_z_size = atlas_image.GetSize()\n",
    "        atlas_cropped_x_size, atlas_cropped_y_size, atlas_cropped_z_size = atlas_cropped_image.GetSize()\n",
    "        manual_x_size, manual_y_size, manual_z_size = manual_image.GetSize()\n",
    "        print(f\"atlas size: ({atlas_x_size}, {atlas_y_size}, {atlas_z_size})\")\n",
    "        print(f\"atlas cropped size: ({atlas_cropped_x_size}, {atlas_cropped_y_size}, {atlas_cropped_z_size})\")\n",
    "        print(f\"manual size: ({manual_x_size}, {manual_y_size}, {manual_z_size})\")\n",
    "\n",
    "        # Bounding box\n",
    "        all_segments_mask = atlas_image > 0\n",
    "        lsif = sitk.LabelStatisticsImageFilter() # It requires intensity and label images\n",
    "        lsif.Execute(atlas_image, all_segments_mask) # Mask! Where all the labels are 1!\n",
    "        bounding_box = np.array(lsif.GetBoundingBox(1)) # GetBoundingBox(label)\n",
    "        print(f\"Bounding box:  {bounding_box}\") # [xmin, xmax, ymin, ymax, zmin, zmax]\n",
    "        print(f'New manual size: ({bounding_box[1]-bounding_box[0]}, {bounding_box[3]-bounding_box[2]}, {bounding_box[5]-bounding_box[4]})')\n",
    "\n",
    "        # Expand bounding box\n",
    "        bounding_box_expanded = bounding_box.copy()\n",
    "        bounding_box_expanded[0::2] -= bound # even indexes\n",
    "        bounding_box_expanded[1::2] += bound # odd indexes\n",
    "        print(f\"Expanded bounding box: {bounding_box_expanded}\")\n",
    "        print(f'new manual size expanded: ({bounding_box_expanded[1]-bounding_box_expanded[0]}, {bounding_box_expanded[3]-bounding_box_expanded[2]}, {bounding_box_expanded[5]-bounding_box_expanded[4]})')\n",
    "\n",
    "        # Limits\n",
    "        if bounding_box_expanded[0] < 0: bounding_box_expanded[0] = 0\n",
    "        if bounding_box_expanded[1] > manual_x_size: bounding_box_expanded[1] = manual_x_size\n",
    "        if bounding_box_expanded[2] < 0: bounding_box_expanded[2] = 0\n",
    "        if bounding_box_expanded[3] > manual_y_size: bounding_box_expanded[3] = manual_y_size\n",
    "        if bounding_box_expanded[4] < 0: bounding_box_expanded[4] = 0\n",
    "        if bounding_box_expanded[5] > manual_z_size: bounding_box_expanded[5] = manual_z_size\n",
    "        print(f\"Expanded bounding box after limits: {bounding_box_expanded}\")\n",
    "        print(f'new manual size expanded after limits: ({bounding_box_expanded[1]-bounding_box_expanded[0]}, {bounding_box_expanded[3]-bounding_box_expanded[2]}, {bounding_box_expanded[5]-bounding_box_expanded[4]})')\n",
    "\n",
    "        # Crop\n",
    "        manual_crop = manual_image[int(bounding_box_expanded[0]):int(bounding_box_expanded[1]), # x\n",
    "                            int(bounding_box_expanded[2]):int(bounding_box_expanded[3]), # y\n",
    "                            int(bounding_box_expanded[4]):int(bounding_box_expanded[5])] # z\n",
    "        sitk.WriteImage(manual_crop, f'{output_path}/{subject}.nii.gz')\n",
    "\n",
    "        i+=1\n",
    "        # if (i==4):\n",
    "        #     break             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sim. metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nibabel as nb\n",
    "\n",
    "# nDSC (normalized DSC)\n",
    "def dice_norm_metric(ground_truth, predictions):\n",
    "    '''\n",
    "    For a single example returns DSC_norm, fpr, fnr\n",
    "    '''\n",
    "\n",
    "    # Reference for normalized DSC\n",
    "    r = 0.001 # It should be 1/N*(np.sum(voxels_label[i])/np.sum(voxels_image[i])) i belonging to training set\n",
    "    # Cast to float32 type\n",
    "    gt = ground_truth.astype(\"float32\")\n",
    "    seg = predictions.astype(\"float32\")\n",
    "    im_sum = np.sum(seg) + np.sum(gt)\n",
    "    if im_sum == 0:\n",
    "        return 1.0, 1.0, 1.0\n",
    "    else:\n",
    "        if np.sum(gt) == 0:\n",
    "            k = 1.0\n",
    "        else:\n",
    "            k = (1 - r) * np.sum(gt) / (r * (len(gt.flatten()) - np.sum(gt)))\n",
    "        tp = np.sum(seg[gt == 1])\n",
    "        fp = np.sum(seg[gt == 0])\n",
    "        fn = np.sum(gt[seg == 0])\n",
    "        fp_scaled = k * fp\n",
    "        dsc_norm = 2 * tp / (fp_scaled + 2 * tp + fn)\n",
    "\n",
    "        fpr = fp / (len(gt.flatten()) - np.sum(gt))\n",
    "        if np.sum(gt) == 0:\n",
    "            fnr = 1.0\n",
    "        else:\n",
    "            fnr = fn / np.sum(gt)\n",
    "        return dsc_norm # fpr, fnr\n",
    "\n",
    "# Paths - segmentation results\n",
    "reg_dir = '/home/jaimebarranco/Desktop/new_manual_annotations/segmentations/atlas_cropped'\n",
    "manual_dir = '/home/jaimebarranco/Desktop/new_manual_annotations/segmentations/manual_cropped'\n",
    "\n",
    "list_subjects = sorted(os.listdir(reg_dir))\n",
    "list_subjects_clean = []\n",
    "\n",
    "for file in list_subjects:\n",
    "    # Name subject\n",
    "    name_subject = file.split('.')[0]\n",
    "    # only non-excluded subjects\n",
    "    if name_subject not in list_qc1:\n",
    "        print(f'subject: {name_subject}')\n",
    "        list_subjects_clean.append(name_subject)\n",
    "        continue\n",
    "\n",
    "# List of volumes for each individual label and subject\n",
    "len_path = len(list_subjects_clean) # elements in gt path = number of subjects\n",
    "name_subject = [None]*len_path\n",
    "\n",
    "# Save values in an array\n",
    "# All labels\n",
    "val_dsc             = np.zeros(len_path)\n",
    "# val_hau             = np.zeros(len(rest_subjects))\n",
    "val_hau_avg         = np.zeros(len_path)\n",
    "val_vol             = np.zeros(len_path)\n",
    "val_ndsc            = np.zeros(len_path)\n",
    "# Lens\n",
    "val_dsc_lens        = np.zeros(len_path)\n",
    "val_hau_avg_lens    = np.zeros(len_path)\n",
    "val_vol_lens        = np.zeros(len_path)\n",
    "val_ndsc_lens       = np.zeros(len_path)\n",
    "# Globe\n",
    "val_dsc_globe       = np.zeros(len_path)\n",
    "val_hau_avg_globe   = np.zeros(len_path)\n",
    "val_vol_globe       = np.zeros(len_path)\n",
    "val_ndsc_globe      = np.zeros(len_path)\n",
    "# Optic nerve  \n",
    "val_dsc_nerve       = np.zeros(len_path)\n",
    "val_hau_avg_nerve   = np.zeros(len_path)\n",
    "val_vol_nerve       = np.zeros(len_path)\n",
    "val_ndsc_nerve      = np.zeros(len_path)\n",
    "# Intraconal fat\n",
    "val_dsc_int_fat     = np.zeros(len_path)\n",
    "val_hau_avg_int_fat = np.zeros(len_path)\n",
    "val_vol_int_fat     = np.zeros(len_path)\n",
    "val_ndsc_int_fat    = np.zeros(len_path)\n",
    "# Extraconal fat\n",
    "val_dsc_ext_fat     = np.zeros(len_path)\n",
    "val_hau_avg_ext_fat = np.zeros(len_path)\n",
    "val_vol_ext_fat     = np.zeros(len_path)\n",
    "val_ndsc_ext_fat    = np.zeros(len_path)\n",
    "# Lateral rectus muscle\n",
    "val_dsc_lat_mus     = np.zeros(len_path)\n",
    "val_hau_avg_lat_mus = np.zeros(len_path)\n",
    "val_vol_lat_mus     = np.zeros(len_path)\n",
    "val_ndsc_lat_mus    = np.zeros(len_path)\n",
    "# Medial rectus muscle\n",
    "val_dsc_med_mus     = np.zeros(len_path)\n",
    "val_hau_avg_med_mus = np.zeros(len_path)\n",
    "val_vol_med_mus     = np.zeros(len_path)\n",
    "val_ndsc_med_mus    = np.zeros(len_path)\n",
    "# Inferior rectus muscle\n",
    "val_dsc_inf_mus     = np.zeros(len_path)\n",
    "val_hau_avg_inf_mus = np.zeros(len_path)\n",
    "val_vol_inf_mus     = np.zeros(len_path)\n",
    "val_ndsc_inf_mus    = np.zeros(len_path)\n",
    "# Superior rectus muscle\n",
    "val_dsc_sup_mus     = np.zeros(len_path)\n",
    "val_hau_avg_sup_mus = np.zeros(len_path)\n",
    "val_vol_sup_mus     = np.zeros(len_path)\n",
    "val_ndsc_sup_mus    = np.zeros(len_path)\n",
    "\n",
    "reader = sitk.ImageFileReader()\n",
    "\n",
    "i=0\n",
    "for file in list_subjects_clean:\n",
    "\n",
    "    # Name subject\n",
    "    name_subject[i] = file\n",
    "\n",
    "    # ATLAS-based results\n",
    "    reg_lab_path = f'{reg_dir}/{name_subject[i]}.nii.gz'\n",
    "    reader.SetFileName(reg_lab_path)\n",
    "    reg_lab_sitk = sitk.Cast(reader.Execute(), sitk.sitkUInt8)\n",
    "    reg_lab_arr = sitk.GetArrayFromImage(reg_lab_sitk)\n",
    "\n",
    "    # MANUAL-based results\n",
    "    dl_lab_path = f'{manual_dir}/{name_subject[i]}.nii.gz'\n",
    "    # check if the file exists\n",
    "    if not os.path.exists(dl_lab_path):\n",
    "        print('file does not exist')\n",
    "        i+=1\n",
    "        continue\n",
    "    reader.SetFileName(dl_lab_path)\n",
    "    dl_lab_sitk = sitk.Cast(reader.Execute(), sitk.sitkUInt8)\n",
    "    dl_lab_arr = sitk.GetArrayFromImage(dl_lab_sitk)\n",
    "    \n",
    "    # Image size\n",
    "    im_lab_size = reg_lab_arr.shape[0]*reg_lab_arr.shape[1]*reg_lab_arr.shape[2]\n",
    "\n",
    "    # LENS\n",
    "    if np.count_nonzero(reg_lab_arr==1)==0 or np.count_nonzero(dl_lab_arr==1)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==1, dl_lab_sitk==1)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_lens[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_lens[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==1, dl_lab_sitk==1)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_lens[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==1, dl_lab_arr==1)\n",
    "        val_ndsc_lens[i] = nDSC\n",
    "    \n",
    "    # GLOBE EX LENS\n",
    "    if np.count_nonzero(reg_lab_arr==2)==0 or np.count_nonzero(dl_lab_arr==2)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==2, dl_lab_sitk==2)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_globe[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_globe[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==2, dl_lab_sitk==2)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_globe[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==2, dl_lab_arr==2)\n",
    "        val_ndsc_globe[i] = nDSC\n",
    "\n",
    "    # OPTIC NERVE\n",
    "    if np.count_nonzero(reg_lab_arr==3)==0 or np.count_nonzero(dl_lab_arr==3)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==3, dl_lab_sitk==3)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_nerve[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_nerve[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==3, dl_lab_sitk==3)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_nerve[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==3, dl_lab_arr==3)\n",
    "        val_ndsc_nerve[i] = nDSC\n",
    "\n",
    "    # INTRACONAL FAT\n",
    "    if np.count_nonzero(reg_lab_arr==4)==0 or np.count_nonzero(dl_lab_arr==4)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==4, dl_lab_sitk==4)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_int_fat[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_int_fat[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==4, dl_lab_sitk==4)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_int_fat[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==4, dl_lab_arr==4)\n",
    "        val_ndsc_int_fat[i] = nDSC\n",
    "\n",
    "    # EXTRACONAL FAT\n",
    "    if np.count_nonzero(reg_lab_arr==5)==0 or np.count_nonzero(dl_lab_arr==5)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==5, dl_lab_sitk==5)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_ext_fat[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_ext_fat[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==5, dl_lab_sitk==5)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_ext_fat[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==5, dl_lab_arr==5)\n",
    "        val_ndsc_ext_fat[i] = nDSC\n",
    "\n",
    "    # LATERAL RECTUS MUSCLE\n",
    "    if np.count_nonzero(reg_lab_arr==6)==0 or np.count_nonzero(dl_lab_arr==6)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==6, dl_lab_sitk==6)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_lat_mus[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_lat_mus[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==6, dl_lab_sitk==6)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_lat_mus[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==6, dl_lab_arr==6)\n",
    "        val_ndsc_lat_mus[i] = nDSC\n",
    "\n",
    "    # MEDIAL RECTUS MUSCLE\n",
    "    if np.count_nonzero(reg_lab_arr==7)==0 or np.count_nonzero(dl_lab_arr==7)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==7, dl_lab_sitk==7)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_med_mus[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_med_mus[i] = vol\n",
    "        # Hausdorff distance\n",
    "        if np.count_nonzero(reg_lab_arr==7)==0 or np.count_nonzero(dl_lab_arr==7)==0: val_hau_avg_lens[i] = 100\n",
    "        else :\n",
    "            hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "            hausdorf.Execute(reg_lab_sitk==7, dl_lab_sitk==7)\n",
    "            hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "            val_hau_avg_med_mus[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==7, dl_lab_arr==7)\n",
    "        val_ndsc_med_mus[i] = nDSC\n",
    "\n",
    "    # INFERIOR RECTUS MUSCLE\n",
    "    if np.count_nonzero(reg_lab_arr==8)==0 or np.count_nonzero(dl_lab_arr==8)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==8, dl_lab_sitk==8)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_inf_mus[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_inf_mus[i] = vol\n",
    "        # Hausdorff distance\n",
    "        if np.count_nonzero(reg_lab_arr==8)==0 or np.count_nonzero(dl_lab_arr==8)==0: val_hau_avg_lens[i] = 100\n",
    "        else :\n",
    "            hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "            hausdorf.Execute(reg_lab_sitk==8, dl_lab_sitk==8)\n",
    "            hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "            val_hau_avg_inf_mus[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==8, dl_lab_arr==8)\n",
    "        val_ndsc_inf_mus[i] = nDSC\n",
    "\n",
    "    # SUPERIOR RECTUS MUSCLE\n",
    "    if np.count_nonzero(reg_lab_arr==9)==0 or np.count_nonzero(dl_lab_arr==9)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==9, dl_lab_sitk==9)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_sup_mus[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_sup_mus[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==9, dl_lab_sitk==9)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_sup_mus[i] = hausdorf_distance_avg\n",
    "        # nDSCvol\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==9, dl_lab_arr==9)\n",
    "        val_ndsc_sup_mus[i] = nDSC\n",
    "\n",
    "    # ALL LABELS\n",
    "    # DSC\n",
    "    dsc = (val_dsc_lens[i]+val_dsc_globe[i]+val_dsc_nerve[i]+val_dsc_int_fat[i]+val_dsc_ext_fat[i]+val_dsc_lat_mus[i]+val_dsc_med_mus[i]+val_dsc_inf_mus[i]+val_dsc_sup_mus[i])/9\n",
    "    val_dsc[i] = dsc\n",
    "    # Volume\n",
    "    vol = (val_vol_lens[i]+val_vol_globe[i]+val_vol_nerve[i]+val_vol_int_fat[i]+val_vol_ext_fat[i]+val_vol_lat_mus[i]+val_vol_med_mus[i]+val_vol_inf_mus[i]+val_vol_sup_mus[i])/9\n",
    "    val_vol[i] = vol\n",
    "    # Hausdorff distance\n",
    "    hau_avg = (val_hau_avg_lens[i]+val_hau_avg_globe[i]+val_hau_avg_nerve[i]+val_hau_avg_int_fat[i]+val_hau_avg_ext_fat[i]+val_hau_avg_lat_mus[i]+val_hau_avg_med_mus[i]+val_hau_avg_inf_mus[i]+val_hau_avg_sup_mus[i])/9\n",
    "    val_hau_avg[i] = hau_avg\n",
    "    # nDSC\n",
    "    nDSC = (val_ndsc_lens[i]+val_ndsc_globe[i]+val_ndsc_nerve[i]+val_ndsc_int_fat[i]+val_ndsc_ext_fat[i]+val_ndsc_lat_mus[i]+val_ndsc_med_mus[i]+val_ndsc_inf_mus[i]+val_ndsc_sup_mus[i])/9\n",
    "    val_ndsc[i] = nDSC\n",
    "\n",
    "    i+=1\n",
    "    # if i==1:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write values to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "metrics = [\n",
    "    'Subject',  'DSC_all',     'Haus_avg_all',     'Volume_all',     'nDSC_all', \n",
    "                'DSC_lens',    'Haus_avg_lens',    'Volume_lens',    'nDSC_lens',  \n",
    "                'DSC_globe',   'Haus_avg_globe',   'Volume_globe',   'nDSC_globe', \n",
    "                'DSC_nerve',   'Haus_avg_nerve',   'Volume_nerve',   'nDSC_nerve', \n",
    "                'DSC_int_fat', 'Haus_avg_int_fat', 'Volume_int_fat', 'nDSC_int_fat',\n",
    "                'DSC_ext_fat', 'Haus_avg_ext_fat', 'Volume_ext_fat', 'nDSC_ext_fat',\n",
    "                'DSC_lat_mus', 'Haus_avg_lat_mus', 'Volume_lat_mus', 'nDSC_lat_mus',\n",
    "                'DSC_med_mus', 'Haus_avg_med_mus', 'Volume_med_mus', 'nDSC_med_mus',\n",
    "                'DSC_inf_mus', 'Haus_avg_inf_mus', 'Volume_inf_mus', 'nDSC_inf_mus',\n",
    "                'DSC_sup_mus', 'Haus_avg_sup_mus', 'Volume_sup_mus', 'nDSC_sup_mus'\n",
    "]\n",
    "\n",
    "vals = np.array([\n",
    "    name_subject,   val_dsc,         val_hau_avg,         val_vol,         val_ndsc,        \n",
    "                    val_dsc_lens,    val_hau_avg_lens,    val_vol_lens,    val_ndsc_lens,   \n",
    "                    val_dsc_globe,   val_hau_avg_globe,   val_vol_globe,   val_ndsc_globe,  \n",
    "                    val_dsc_nerve,   val_hau_avg_nerve,   val_vol_nerve,   val_ndsc_nerve,  \n",
    "                    val_dsc_int_fat, val_hau_avg_int_fat, val_vol_int_fat, val_ndsc_int_fat,\n",
    "                    val_dsc_ext_fat, val_hau_avg_ext_fat, val_vol_ext_fat, val_ndsc_ext_fat,\n",
    "                    val_dsc_lat_mus, val_hau_avg_lat_mus, val_vol_lat_mus, val_ndsc_lat_mus,\n",
    "                    val_dsc_med_mus, val_hau_avg_med_mus, val_vol_med_mus, val_ndsc_med_mus,\n",
    "                    val_dsc_inf_mus, val_hau_avg_inf_mus, val_vol_inf_mus, val_ndsc_inf_mus,\n",
    "                    val_dsc_sup_mus, val_hau_avg_sup_mus, val_vol_sup_mus, val_ndsc_sup_mus,\n",
    "])\n",
    "\n",
    "vals = vals.T\n",
    "\n",
    "with open('/home/jaimebarranco/Desktop/new_manual_annotations/similarity/sim_manual_atlas_N43.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(metrics)\n",
    "    writer.writerows(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import Line2D\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "csv_file = pd.read_csv('/home/jaimebarranco/Desktop/new_manual_annotations/similarity/sim_manual_atlas_N43.csv')\n",
    "\n",
    "# Dataframes\n",
    "data_dsc = [csv_file['DSC_all'], csv_file['DSC_lens'], csv_file['DSC_globe'], csv_file['DSC_nerve'], csv_file['DSC_int_fat'], csv_file['DSC_ext_fat'], csv_file['DSC_lat_mus'], csv_file['DSC_med_mus'], csv_file['DSC_inf_mus'], csv_file['DSC_sup_mus']]\n",
    "data_ndsc = [csv_file['nDSC_all'],  csv_file['nDSC_lens'], csv_file['nDSC_globe'], csv_file['nDSC_nerve'], csv_file['nDSC_int_fat'], csv_file['nDSC_ext_fat'], csv_file['nDSC_lat_mus'], csv_file['nDSC_med_mus'], csv_file['nDSC_inf_mus'], csv_file['nDSC_sup_mus']]\n",
    "data_vol = [csv_file['Volume_all'], csv_file['Volume_lens'], csv_file['Volume_globe'], csv_file['Volume_nerve'], csv_file['Volume_int_fat'], csv_file['Volume_ext_fat'], csv_file['Volume_lat_mus'], csv_file['Volume_med_mus'], csv_file['Volume_inf_mus'], csv_file['Volume_sup_mus']]\n",
    "data_haus = [csv_file['Haus_avg_all'], csv_file['Haus_avg_lens'], csv_file['Haus_avg_globe'], csv_file['Haus_avg_nerve'], csv_file['Haus_avg_int_fat'], csv_file['Haus_avg_ext_fat'], csv_file['Haus_avg_lat_mus'], csv_file['Haus_avg_med_mus'], csv_file['Haus_avg_inf_mus'], csv_file['Haus_avg_sup_mus']]\n",
    "\n",
    "labels = ['overall', 'lens', 'globe', 'nerve', 'intraconal fat', 'extraconal fat', 'lateral rectus muscle', 'medial rectus muscle', 'inferior rectus muscle', 'superior rectus muscle']\n",
    "median = [np.around(np.median(x), 2) for x in data_dsc]\n",
    "print('median DSC:')\n",
    "for i in range(len(labels)):\n",
    "    print(labels[i], median[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "fig, axs = plt.subplots(3, figsize=(20,10), sharex=True)\n",
    "fig.canvas.manager.set_window_title(f'Similarity metrics MANUAL vs ATLAS (N={len(csv_file)})')\n",
    "fig.suptitle(f'Similarity metrics MANUAL vs ATLAS (N={len(csv_file)})')\n",
    "fig.patch.set_facecolor('white')\n",
    "# fig.tight_layout(pad=2)\n",
    "\n",
    "# Set labels and titles\n",
    "axs[0].set_title('DSC')\n",
    "axs[0].set_ylim([0, 1])\n",
    "axs[1].set_title('Hausdorff distance')\n",
    "axs[1].set_ylim([0, 3])\n",
    "axs[2].set_title('Volume difference')\n",
    "axs[2].set_ylim([-2, 2])\n",
    "\n",
    "# Outliers\n",
    "flierprops = dict(markerfacecolor='0.9', markersize=2, linestyle='none')\n",
    "\n",
    "# Boxplot & Swarmplot (points)\n",
    "graph1 = sns.boxplot(data=data_dsc, ax=axs[0], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "# graph1 = sns.swarmplot(data=data_dsc, ax=axs[0]).set(ylabel=\"Value\")\n",
    "graph2 = sns.boxplot(data=data_haus, ax=axs[1], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "graph3 = sns.boxplot(data=data_vol, ax=axs[2], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "axs[2].set_xticklabels(['all','lens','globe','nerve','int_fat','ext_fat','lat_mus','med_mus','inf_mus','sup_mus'])\n",
    "\n",
    "plt.show\n",
    "\n",
    "# Save figure\n",
    "# plt.savefig('/home/jaimebarranco/Desktop/new_manual_annotations/similarity/sim_manual_atlas_N43.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check annotator bias for the lens' dsc\n",
    "fig = px.scatter(y=data_dsc[1], labels={'x':'Subject', 'y':'Value'}, title='DSC Lens', height=600, width=800)\n",
    "fig.update_traces(marker=dict(size=6, opacity=0.5))\n",
    "fig.show()\n",
    "# fig.write_image('/home/jaimebarranco/Desktop/new_manual_annotations/similarity/lens_dsc_atlas_manual.png')\n",
    "\n",
    "# It seems Philip (first 20 subjects [4-23]) has more discrepancy with the atlas, but it also means that he has higher and lower values than\n",
    "# Adrian. Adrian (second 14 subjects [23-36]), however, seems to be more focused on the 0.4-0.7 range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nDSC columns from csv_file\n",
    "csv_file = csv_file.drop(columns=['nDSC_all', 'nDSC_lens', 'nDSC_globe', 'nDSC_nerve', 'nDSC_int_fat', 'nDSC_ext_fat', 'nDSC_lat_mus', 'nDSC_med_mus', 'nDSC_inf_mus', 'nDSC_sup_mus'])\n",
    "# reorder columns, first the DSCs, then the Hausdorff distances, then the volumes\n",
    "csv_file = csv_file[['Subject', 'DSC_all', 'DSC_lens', 'DSC_globe', 'DSC_nerve', 'DSC_int_fat', 'DSC_ext_fat', 'DSC_lat_mus', 'DSC_med_mus', 'DSC_inf_mus', 'DSC_sup_mus', 'Haus_avg_all', 'Haus_avg_lens', 'Haus_avg_globe', 'Haus_avg_nerve', 'Haus_avg_int_fat', 'Haus_avg_ext_fat', 'Haus_avg_lat_mus', 'Haus_avg_med_mus', 'Haus_avg_inf_mus', 'Haus_avg_sup_mus', 'Volume_all', 'Volume_lens', 'Volume_globe', 'Volume_nerve', 'Volume_int_fat', 'Volume_ext_fat', 'Volume_lat_mus', 'Volume_med_mus', 'Volume_inf_mus', 'Volume_sup_mus']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk test for normality for each column of csv_file\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "for i in range(1, len(csv_file.columns)):\n",
    "    stat, p = shapiro(csv_file.iloc[:,i])\n",
    "    print(f'{csv_file.columns[i]}: Statistics={stat}, p={p}')\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('Sample does not look Gaussian (reject H0)')\n",
    "    # histogram plot\n",
    "    plt.hist(csv_file.iloc[:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers - IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_df1 = pd.DataFrame(columns=['Column', 'Outlier Subject'])\n",
    "bounds_df = pd.DataFrame(columns=['Column', 'Lower Bound', 'Upper Bound']) # dataframe for bounds\n",
    "\n",
    "# Calculate the IQR for each column\n",
    "Q1 = csv_file.quantile(0.25)\n",
    "Q3 = csv_file.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Find the outliers for each column\n",
    "for column in csv_file.columns[1:]:\n",
    "    lower_bound = Q1[column] - 1.5 * IQR[column]\n",
    "    upper_bound = Q3[column] + 1.5 * IQR[column]\n",
    "\n",
    "    # Append bounds to the bounds_df DataFrame\n",
    "    new_row = pd.DataFrame({'Column': [column], 'Lower Bound': [lower_bound], 'Upper Bound': [upper_bound]})\n",
    "    bounds_df = pd.concat([bounds_df, new_row], ignore_index=True)\n",
    "\n",
    "    column_outliers = csv_file[(csv_file[column] < lower_bound) | (csv_file[column] > upper_bound)]\n",
    "    new_row = pd.DataFrame({'Column': [column], 'Outlier Subject': [column_outliers['Subject'].values]})\n",
    "    outliers_df1 = pd.concat([outliers_df1, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new DataFrame with the same structure as csv_file but filled with False\n",
    "outliers_df2 = pd.DataFrame(False, index=csv_file.index, columns=csv_file.columns)\n",
    "\n",
    "# Copy the 'Subject' column from csv_file to outliers_df\n",
    "outliers_df2['Subject'] = csv_file['Subject']\n",
    "\n",
    "# Calculate the IQR for each column excluding 'Subject'\n",
    "Q1 = csv_file.drop('Subject', axis=1).quantile(0.25)\n",
    "Q3 = csv_file.drop('Subject', axis=1).quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Find the outliers for each column excluding 'Subject'\n",
    "for column in csv_file.columns:\n",
    "    if column != 'Subject':\n",
    "        lower_bound = Q1[column] - 1.5 * IQR[column]\n",
    "        upper_bound = Q3[column] + 1.5 * IQR[column]\n",
    "        # Update outliers_df with True for outliers\n",
    "        outliers_df2[column] = (csv_file[column] < lower_bound) | (csv_file[column] > upper_bound)\n",
    "\n",
    "# Replace all False values with ''\n",
    "outliers_df2 = outliers_df2.replace(False, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# make a list of 'Outlier Subject' without duplicates in row and column\n",
    "outliers_list = []\n",
    "for i in range(len(outliers_df1)):\n",
    "    for j in range(len(outliers_df1.iloc[i,1])):\n",
    "        outliers_list.append(outliers_df1.iloc[i,1][j])\n",
    "\n",
    "# Count the occurrences of each outlier\n",
    "outliers_counter = Counter(outliers_list)\n",
    "\n",
    "# Keep only the outliers that appear more than once\n",
    "outliers_list = [item for item, count in outliers_counter.items() if count > 1]\n",
    "\n",
    "outliers_list = list(sorted(set(outliers_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reports to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_aux = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/df_aux.csv\")\n",
    "\n",
    "# subdataframe of df_aux with the outliers_list\n",
    "outliers_reports_df = df_aux[df_aux['subject'].isin(outliers_list)]\n",
    "# add 'my_rate' column to outliers_reports_df\n",
    "outliers_reports_df.loc[:, 'my_rate'] = 0.0\n",
    "# order outliers_reports_df by 'report'\n",
    "outliers_reports_df = outliers_reports_df.sort_values(by=['report'])\n",
    "# save outliers_reports_df to excel file\n",
    "# outliers_reports_df.to_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_atlas.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Old and new subjects (N=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import Line2D\n",
    "import numpy as np\n",
    "\n",
    "csv_file = pd.read_csv('/home/jaimebarranco/Desktop/new_manual_annotations/similarity/sim_manual_atlas_N43.csv')\n",
    "csv_old = pd.read_csv('/mnt/sda1/Repos/a-eye/a-eye_preprocessing/ANTs/best_subjects_eye_cc/CustomTemplate_5_n1/sim_metrics_labels2subject3_N5.csv')\n",
    "\n",
    "# group dataframes together\n",
    "csv_file = pd.concat([csv_file, csv_old])\n",
    "# remove four first rows (4 repeated subjects)\n",
    "csv_file = csv_file.iloc[4:]\n",
    "\n",
    "# Dataframes\n",
    "data_dsc = [csv_file['DSC_all'], csv_file['DSC_lens'], csv_file['DSC_globe'], csv_file['DSC_nerve'], csv_file['DSC_int_fat'], csv_file['DSC_ext_fat'], csv_file['DSC_lat_mus'], csv_file['DSC_med_mus'], csv_file['DSC_inf_mus'], csv_file['DSC_sup_mus']]\n",
    "data_ndsc = [csv_file['nDSC_all'],  csv_file['nDSC_lens'], csv_file['nDSC_globe'], csv_file['nDSC_nerve'], csv_file['nDSC_int_fat'], csv_file['nDSC_ext_fat'], csv_file['nDSC_lat_mus'], csv_file['nDSC_med_mus'], csv_file['nDSC_inf_mus'], csv_file['nDSC_sup_mus']]\n",
    "data_vol = [csv_file['Volume_all'], csv_file['Volume_lens'], csv_file['Volume_globe'], csv_file['Volume_nerve'], csv_file['Volume_int_fat'], csv_file['Volume_ext_fat'], csv_file['Volume_lat_mus'], csv_file['Volume_med_mus'], csv_file['Volume_inf_mus'], csv_file['Volume_sup_mus']]\n",
    "data_haus = [csv_file['Haus_avg_all'], csv_file['Haus_avg_lens'], csv_file['Haus_avg_globe'], csv_file['Haus_avg_nerve'], csv_file['Haus_avg_int_fat'], csv_file['Haus_avg_ext_fat'], csv_file['Haus_avg_lat_mus'], csv_file['Haus_avg_med_mus'], csv_file['Haus_avg_inf_mus'], csv_file['Haus_avg_sup_mus']]\n",
    "\n",
    "labels = ['overall', 'lens', 'globe', 'nerve', 'intraconal fat', 'extraconal fat', 'lateral rectus muscle', 'medial rectus muscle', 'inferior rectus muscle', 'superior rectus muscle']\n",
    "median = [np.around(np.median(x), 2) for x in data_dsc]\n",
    "for i in range(len(labels)):\n",
    "    print(labels[i], median[i])\n",
    "\n",
    "# Figure\n",
    "fig, axs = plt.subplots(3, figsize=(20,10), sharex=True)\n",
    "fig.canvas.manager.set_window_title(f'Similarity metrics MANUAL vs ATLAS (N={len(csv_file)})')\n",
    "fig.suptitle(f'Similarity metrics MANUAL vs ATLAS (N={len(csv_file)})')\n",
    "fig.patch.set_facecolor('white')\n",
    "# fig.tight_layout(pad=2)\n",
    "\n",
    "# Set labels and titles\n",
    "axs[0].set_title('DSC')\n",
    "axs[0].set_ylim([0, 1])\n",
    "axs[1].set_title('Hausdorff distance')\n",
    "axs[1].set_ylim([0, 3])\n",
    "axs[2].set_title('Volume difference')\n",
    "axs[2].set_ylim([-2, 2])\n",
    "\n",
    "# Outliers\n",
    "flierprops = dict(markerfacecolor='0.9', markersize=2, linestyle='none')\n",
    "\n",
    "# Boxplot & Swarmplot (points)\n",
    "graph1 = sns.boxplot(data=data_dsc, ax=axs[0], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "graph2 = sns.boxplot(data=data_haus, ax=axs[1], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "graph3 = sns.boxplot(data=data_vol, ax=axs[2], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "axs[2].set_xticklabels(['all','lens','globe','nerve','int_fat','ext_fat','lat_mus','med_mus','inf_mus','sup_mus'])\n",
    "\n",
    "plt.show\n",
    "\n",
    "# Save figure\n",
    "# plt.savefig('/home/jaimebarranco/Desktop/new_manual_annotations/similarity/sim_manual_atlas_N69.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nnUNet vs Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of files under 1kB in a specific folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of files under 1kB in a specific folder\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "path = '/home/jaimebarranco/Desktop/new_manual_annotations/segmentations/nnunet'\n",
    "files = glob.glob(path + '*.nii.gz')\n",
    "bad_files = []\n",
    "\n",
    "i=0\n",
    "for file in sorted(files):\n",
    "    if os.path.getsize(file) < 1000:\n",
    "        subject = file.split('/')[-1].split('.')[0].split('_')[0]\n",
    "        bad_files.append(subject)\n",
    "        print(subject)\n",
    "        i+=1\n",
    "\n",
    "print(f'Number of images under 1kB: {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "\n",
    "reg_dir = '/home/jaimebarranco/Desktop/new_manual_annotations/segmentations/manual'\n",
    "nnunet_dir = '/home/jaimebarranco/Desktop/new_manual_annotations/segmentations/nnunet'\n",
    "output_dir = '/home/jaimebarranco/Desktop/new_manual_annotations/segmentations/nnunet_alligned'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "i=0\n",
    "for file in sorted(glob.glob(nnunet_dir+'/*.nii.gz')):\n",
    "\n",
    "    subject = os.path.basename(file).split('.')[0]\n",
    "    # print(f'subject = {subject}')\n",
    "\n",
    "    if os.path.exists(os.path.join(output_dir, f'{subject}.nii.gz')):\n",
    "        continue\n",
    "    else:\n",
    "        # if subject == '2022160100236': # indent from here\n",
    "        image_path_nnunet = f'{nnunet_dir}/{subject}.nii.gz'\n",
    "        image_path_atlas = f'{reg_dir}/{subject}.nii.gz'\n",
    "\n",
    "        # Load t1_aux (to allign the other)\n",
    "        t1_aux = nb.load(image_path_atlas)\n",
    "        # print(f't1_aux.affine: \\n{t1_aux.affine}')\n",
    "        # print(f't1_aux.header: \\n{t1_aux.header}')\n",
    "\n",
    "        # Load t1 image (not alligned)\n",
    "        t1 = nb.load(image_path_nnunet)\n",
    "        # print(f't1.affine: \\n{t1.affine}')\n",
    "        # print(f't1.header: \\n{t1.header}')\n",
    "\n",
    "        # Copy affine from t1_aux to t1\n",
    "        nii = nb.Nifti1Image(t1.dataobj, t1_aux.affine, t1_aux.header)\n",
    "        nii.to_filename(f'{output_dir}/{subject}.nii.gz')\n",
    "        \n",
    "        # Dealing with files in that folder\n",
    "        # for f in glob.glob(base_dir+folder1+'/input/'+folder1+'_T1_oriented_hdr.nii.gz'):\n",
    "        #     os.remove(f)\n",
    "\n",
    "        i+=1\n",
    "        # if (i==1):\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sim metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nibabel as nb\n",
    "\n",
    "# nDSC (normalized DSC)\n",
    "def dice_norm_metric(ground_truth, predictions):\n",
    "    '''\n",
    "    For a single example returns DSC_norm, fpr, fnr\n",
    "    '''\n",
    "\n",
    "    # Reference for normalized DSC\n",
    "    r = 0.001 # It should be 1/N*(np.sum(voxels_label[i])/np.sum(voxels_image[i])) i belonging to training set\n",
    "    # Cast to float32 type\n",
    "    gt = ground_truth.astype(\"float32\")\n",
    "    seg = predictions.astype(\"float32\")\n",
    "    im_sum = np.sum(seg) + np.sum(gt)\n",
    "    if im_sum == 0:\n",
    "        return 1.0, 1.0, 1.0\n",
    "    else:\n",
    "        if np.sum(gt) == 0:\n",
    "            k = 1.0\n",
    "        else:\n",
    "            k = (1 - r) * np.sum(gt) / (r * (len(gt.flatten()) - np.sum(gt)))\n",
    "        tp = np.sum(seg[gt == 1])\n",
    "        fp = np.sum(seg[gt == 0])\n",
    "        fn = np.sum(gt[seg == 0])\n",
    "        fp_scaled = k * fp\n",
    "        dsc_norm = 2 * tp / (fp_scaled + 2 * tp + fn)\n",
    "\n",
    "        fpr = fp / (len(gt.flatten()) - np.sum(gt))\n",
    "        if np.sum(gt) == 0:\n",
    "            fnr = 1.0\n",
    "        else:\n",
    "            fnr = fn / np.sum(gt)\n",
    "        return dsc_norm # fpr, fnr\n",
    "\n",
    "# Paths - segmentation results\n",
    "reg_dir = '/home/jaimebarranco/Desktop/new_manual_annotations/segmentations/manual'\n",
    "nnunet_dir = '/home/jaimebarranco/Desktop/new_manual_annotations/segmentations/nnunet_alligned'\n",
    "\n",
    "list_subjects = sorted(os.listdir(nnunet_dir))\n",
    "list_subjects_clean = []\n",
    "\n",
    "for file in list_subjects:\n",
    "    # Name subject\n",
    "    name_subject = file.split('.')[0]\n",
    "    # only non-excluded subjects\n",
    "    if name_subject not in list_qc1:\n",
    "        print(f'subject: {name_subject}')\n",
    "        list_subjects_clean.append(name_subject)\n",
    "        continue\n",
    "\n",
    "# List of volumes for each individual label and subject\n",
    "len_path = len(list_subjects_clean) # elements in gt path = number of subjects\n",
    "name_subject = [None]*len_path\n",
    "\n",
    "# Save values in an array\n",
    "# All labels\n",
    "val_dsc             = np.zeros(len_path)\n",
    "# val_hau             = np.zeros(len(rest_subjects))\n",
    "val_hau_avg         = np.zeros(len_path)\n",
    "val_vol             = np.zeros(len_path)\n",
    "val_ndsc            = np.zeros(len_path)\n",
    "# Lens\n",
    "val_dsc_lens        = np.zeros(len_path)\n",
    "val_hau_avg_lens    = np.zeros(len_path)\n",
    "val_vol_lens        = np.zeros(len_path)\n",
    "val_ndsc_lens       = np.zeros(len_path)\n",
    "# Globe\n",
    "val_dsc_globe       = np.zeros(len_path)\n",
    "val_hau_avg_globe   = np.zeros(len_path)\n",
    "val_vol_globe       = np.zeros(len_path)\n",
    "val_ndsc_globe      = np.zeros(len_path)\n",
    "# Optic nerve  \n",
    "val_dsc_nerve       = np.zeros(len_path)\n",
    "val_hau_avg_nerve   = np.zeros(len_path)\n",
    "val_vol_nerve       = np.zeros(len_path)\n",
    "val_ndsc_nerve      = np.zeros(len_path)\n",
    "# Intraconal fat\n",
    "val_dsc_int_fat     = np.zeros(len_path)\n",
    "val_hau_avg_int_fat = np.zeros(len_path)\n",
    "val_vol_int_fat     = np.zeros(len_path)\n",
    "val_ndsc_int_fat    = np.zeros(len_path)\n",
    "# Extraconal fat\n",
    "val_dsc_ext_fat     = np.zeros(len_path)\n",
    "val_hau_avg_ext_fat = np.zeros(len_path)\n",
    "val_vol_ext_fat     = np.zeros(len_path)\n",
    "val_ndsc_ext_fat    = np.zeros(len_path)\n",
    "# Lateral rectus muscle\n",
    "val_dsc_lat_mus     = np.zeros(len_path)\n",
    "val_hau_avg_lat_mus = np.zeros(len_path)\n",
    "val_vol_lat_mus     = np.zeros(len_path)\n",
    "val_ndsc_lat_mus    = np.zeros(len_path)\n",
    "# Medial rectus muscle\n",
    "val_dsc_med_mus     = np.zeros(len_path)\n",
    "val_hau_avg_med_mus = np.zeros(len_path)\n",
    "val_vol_med_mus     = np.zeros(len_path)\n",
    "val_ndsc_med_mus    = np.zeros(len_path)\n",
    "# Inferior rectus muscle\n",
    "val_dsc_inf_mus     = np.zeros(len_path)\n",
    "val_hau_avg_inf_mus = np.zeros(len_path)\n",
    "val_vol_inf_mus     = np.zeros(len_path)\n",
    "val_ndsc_inf_mus    = np.zeros(len_path)\n",
    "# Superior rectus muscle\n",
    "val_dsc_sup_mus     = np.zeros(len_path)\n",
    "val_hau_avg_sup_mus = np.zeros(len_path)\n",
    "val_vol_sup_mus     = np.zeros(len_path)\n",
    "val_ndsc_sup_mus    = np.zeros(len_path)\n",
    "\n",
    "reader = sitk.ImageFileReader()\n",
    "\n",
    "i=0\n",
    "for file in list_subjects_clean:\n",
    "\n",
    "    # Name subject\n",
    "    name_subject[i] = file\n",
    "\n",
    "    # bad files\n",
    "    if name_subject[i] in bad_files:\n",
    "        print('bad file')\n",
    "        i+=1\n",
    "        continue\n",
    "    \n",
    "    # MANUAL-based results\n",
    "    reg_lab_path = f'{reg_dir}/{name_subject[i]}.nii.gz'\n",
    "    reader.SetFileName(reg_lab_path)\n",
    "    reg_lab_sitk = sitk.Cast(reader.Execute(), sitk.sitkUInt8)\n",
    "    reg_lab_arr = sitk.GetArrayFromImage(reg_lab_sitk)\n",
    "\n",
    "    # Deep Learning results\n",
    "    dl_lab_path = f'{nnunet_dir}/{name_subject[i]}.nii.gz'\n",
    "    # check if the file exists\n",
    "    if not os.path.exists(dl_lab_path):\n",
    "        print('file does not exist')\n",
    "        i+=1\n",
    "        continue\n",
    "    reader.SetFileName(dl_lab_path)\n",
    "    dl_lab_sitk = sitk.Cast(reader.Execute(), sitk.sitkUInt8)\n",
    "    dl_lab_arr = sitk.GetArrayFromImage(dl_lab_sitk)\n",
    "    \n",
    "    # Image size\n",
    "    im_lab_size = reg_lab_arr.shape[0]*reg_lab_arr.shape[1]*reg_lab_arr.shape[2]\n",
    "\n",
    "    # LENS\n",
    "    if np.count_nonzero(reg_lab_arr==1)==0 or np.count_nonzero(dl_lab_arr==1)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==1, dl_lab_sitk==1)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_lens[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_lens[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==1, dl_lab_sitk==1)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_lens[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==1, dl_lab_arr==1)\n",
    "        val_ndsc_lens[i] = nDSC\n",
    "    \n",
    "    # GLOBE EX LENS\n",
    "    if np.count_nonzero(reg_lab_arr==2)==0 or np.count_nonzero(dl_lab_arr==2)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==2, dl_lab_sitk==2)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_globe[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_globe[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==2, dl_lab_sitk==2)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_globe[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==2, dl_lab_arr==2)\n",
    "        val_ndsc_globe[i] = nDSC\n",
    "\n",
    "    # OPTIC NERVE\n",
    "    if np.count_nonzero(reg_lab_arr==3)==0 or np.count_nonzero(dl_lab_arr==3)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==3, dl_lab_sitk==3)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_nerve[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_nerve[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==3, dl_lab_sitk==3)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_nerve[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==3, dl_lab_arr==3)\n",
    "        val_ndsc_nerve[i] = nDSC\n",
    "\n",
    "    # INTRACONAL FAT\n",
    "    if np.count_nonzero(reg_lab_arr==4)==0 or np.count_nonzero(dl_lab_arr==4)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==4, dl_lab_sitk==4)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_int_fat[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_int_fat[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==4, dl_lab_sitk==4)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_int_fat[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==4, dl_lab_arr==4)\n",
    "        val_ndsc_int_fat[i] = nDSC\n",
    "\n",
    "    # EXTRACONAL FAT\n",
    "    if np.count_nonzero(reg_lab_arr==5)==0 or np.count_nonzero(dl_lab_arr==5)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==5, dl_lab_sitk==5)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_ext_fat[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_ext_fat[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==5, dl_lab_sitk==5)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_ext_fat[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==5, dl_lab_arr==5)\n",
    "        val_ndsc_ext_fat[i] = nDSC\n",
    "\n",
    "    # LATERAL RECTUS MUSCLE\n",
    "    if np.count_nonzero(reg_lab_arr==6)==0 or np.count_nonzero(dl_lab_arr==6)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==6, dl_lab_sitk==6)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_lat_mus[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_lat_mus[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==6, dl_lab_sitk==6)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_lat_mus[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==6, dl_lab_arr==6)\n",
    "        val_ndsc_lat_mus[i] = nDSC\n",
    "\n",
    "    # MEDIAL RECTUS MUSCLE\n",
    "    if np.count_nonzero(reg_lab_arr==7)==0 or np.count_nonzero(dl_lab_arr==7)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter \n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==7, dl_lab_sitk==7)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_med_mus[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_med_mus[i] = vol\n",
    "        # Hausdorff distance\n",
    "        if np.count_nonzero(reg_lab_arr==7)==0 or np.count_nonzero(dl_lab_arr==7)==0: val_hau_avg_lens[i] = 100\n",
    "        else :\n",
    "            hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "            hausdorf.Execute(reg_lab_sitk==7, dl_lab_sitk==7)\n",
    "            hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "            val_hau_avg_med_mus[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==7, dl_lab_arr==7)\n",
    "        val_ndsc_med_mus[i] = nDSC\n",
    "\n",
    "    # INFERIOR RECTUS MUSCLE\n",
    "    if np.count_nonzero(reg_lab_arr==8)==0 or np.count_nonzero(dl_lab_arr==8)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==8, dl_lab_sitk==8)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_inf_mus[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_inf_mus[i] = vol\n",
    "        # Hausdorff distance\n",
    "        if np.count_nonzero(reg_lab_arr==8)==0 or np.count_nonzero(dl_lab_arr==8)==0: val_hau_avg_lens[i] = 100\n",
    "        else :\n",
    "            hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "            hausdorf.Execute(reg_lab_sitk==8, dl_lab_sitk==8)\n",
    "            hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "            val_hau_avg_inf_mus[i] = hausdorf_distance_avg\n",
    "        # nDSC\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==8, dl_lab_arr==8)\n",
    "        val_ndsc_inf_mus[i] = nDSC\n",
    "\n",
    "    # SUPERIOR RECTUS MUSCLE\n",
    "    if np.count_nonzero(reg_lab_arr==9)==0 or np.count_nonzero(dl_lab_arr==9)==0: # if there is no label in the image\n",
    "        val_hau_avg_lens[i] = 100 # set hausdorff distance to 100 [-inf, inf]\n",
    "        val_dsc_lens[i] = 0 # set dice coefficient to 0 [0, 1]\n",
    "        val_vol_lens[i] = 2 # set volume similarity to 2 [-2, 2]\n",
    "        val_ndsc_lens[i] = 0 # set normalized dice coefficient to 0 [0, 1]\n",
    "    else:\n",
    "        # Measures Image Filter\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "        overlap_measures_filter.Execute(reg_lab_sitk==9, dl_lab_sitk==9)\n",
    "        # DSC\n",
    "        dsc = overlap_measures_filter.GetDiceCoefficient() # Get the mean overlap (Dice coefficient) over all labels\n",
    "        val_dsc_sup_mus[i] = dsc\n",
    "        # Volume\n",
    "        vol = overlap_measures_filter.GetVolumeSimilarity() # Get the volume similarity over all labels\n",
    "        val_vol_sup_mus[i] = vol\n",
    "        # Hausdorff distance\n",
    "        hausdorf = sitk.HausdorffDistanceImageFilter()\n",
    "        hausdorf.Execute(reg_lab_sitk==9, dl_lab_sitk==9)\n",
    "        hausdorf_distance_avg = hausdorf.GetAverageHausdorffDistance() # Return the computed Hausdorff distance\n",
    "        val_hau_avg_sup_mus[i] = hausdorf_distance_avg\n",
    "        # nDSCvol\n",
    "        nDSC = dice_norm_metric(reg_lab_arr==9, dl_lab_arr==9)\n",
    "        val_ndsc_sup_mus[i] = nDSC\n",
    "\n",
    "    # ALL LABELS\n",
    "    # DSC\n",
    "    dsc = (val_dsc_lens[i]+val_dsc_globe[i]+val_dsc_nerve[i]+val_dsc_int_fat[i]+val_dsc_ext_fat[i]+val_dsc_lat_mus[i]+val_dsc_med_mus[i]+val_dsc_inf_mus[i]+val_dsc_sup_mus[i])/9\n",
    "    val_dsc[i] = dsc\n",
    "    # Volume\n",
    "    vol = (val_vol_lens[i]+val_vol_globe[i]+val_vol_nerve[i]+val_vol_int_fat[i]+val_vol_ext_fat[i]+val_vol_lat_mus[i]+val_vol_med_mus[i]+val_vol_inf_mus[i]+val_vol_sup_mus[i])/9\n",
    "    val_vol[i] = vol\n",
    "    # Hausdorff distance\n",
    "    hau_avg = (val_hau_avg_lens[i]+val_hau_avg_globe[i]+val_hau_avg_nerve[i]+val_hau_avg_int_fat[i]+val_hau_avg_ext_fat[i]+val_hau_avg_lat_mus[i]+val_hau_avg_med_mus[i]+val_hau_avg_inf_mus[i]+val_hau_avg_sup_mus[i])/9\n",
    "    val_hau_avg[i] = hau_avg\n",
    "    # nDSC\n",
    "    nDSC = (val_ndsc_lens[i]+val_ndsc_globe[i]+val_ndsc_nerve[i]+val_ndsc_int_fat[i]+val_ndsc_ext_fat[i]+val_ndsc_lat_mus[i]+val_ndsc_med_mus[i]+val_ndsc_inf_mus[i]+val_ndsc_sup_mus[i])/9\n",
    "    val_ndsc[i] = nDSC\n",
    "\n",
    "    i+=1\n",
    "    # if i==1:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write values to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "metrics = [\n",
    "    'Subject',  'DSC_all',     'Haus_avg_all',     'Volume_all',     'nDSC_all', \n",
    "                'DSC_lens',    'Haus_avg_lens',    'Volume_lens',    'nDSC_lens',  \n",
    "                'DSC_globe',   'Haus_avg_globe',   'Volume_globe',   'nDSC_globe', \n",
    "                'DSC_nerve',   'Haus_avg_nerve',   'Volume_nerve',   'nDSC_nerve', \n",
    "                'DSC_int_fat', 'Haus_avg_int_fat', 'Volume_int_fat', 'nDSC_int_fat',\n",
    "                'DSC_ext_fat', 'Haus_avg_ext_fat', 'Volume_ext_fat', 'nDSC_ext_fat',\n",
    "                'DSC_lat_mus', 'Haus_avg_lat_mus', 'Volume_lat_mus', 'nDSC_lat_mus',\n",
    "                'DSC_med_mus', 'Haus_avg_med_mus', 'Volume_med_mus', 'nDSC_med_mus',\n",
    "                'DSC_inf_mus', 'Haus_avg_inf_mus', 'Volume_inf_mus', 'nDSC_inf_mus',\n",
    "                'DSC_sup_mus', 'Haus_avg_sup_mus', 'Volume_sup_mus', 'nDSC_sup_mus'\n",
    "]\n",
    "\n",
    "vals = np.array([\n",
    "    name_subject,   val_dsc,         val_hau_avg,         val_vol,         val_ndsc,        \n",
    "                    val_dsc_lens,    val_hau_avg_lens,    val_vol_lens,    val_ndsc_lens,   \n",
    "                    val_dsc_globe,   val_hau_avg_globe,   val_vol_globe,   val_ndsc_globe,  \n",
    "                    val_dsc_nerve,   val_hau_avg_nerve,   val_vol_nerve,   val_ndsc_nerve,  \n",
    "                    val_dsc_int_fat, val_hau_avg_int_fat, val_vol_int_fat, val_ndsc_int_fat,\n",
    "                    val_dsc_ext_fat, val_hau_avg_ext_fat, val_vol_ext_fat, val_ndsc_ext_fat,\n",
    "                    val_dsc_lat_mus, val_hau_avg_lat_mus, val_vol_lat_mus, val_ndsc_lat_mus,\n",
    "                    val_dsc_med_mus, val_hau_avg_med_mus, val_vol_med_mus, val_ndsc_med_mus,\n",
    "                    val_dsc_inf_mus, val_hau_avg_inf_mus, val_vol_inf_mus, val_ndsc_inf_mus,\n",
    "                    val_dsc_sup_mus, val_hau_avg_sup_mus, val_vol_sup_mus, val_ndsc_sup_mus,\n",
    "])\n",
    "\n",
    "vals = vals.T\n",
    "\n",
    "with open('/home/jaimebarranco/Desktop/new_manual_annotations/similarity/sim_manual_nnunet_N43.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(metrics)\n",
    "    writer.writerows(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import Line2D\n",
    "import numpy as np\n",
    "\n",
    "csv_file = pd.read_csv('/home/jaimebarranco/Desktop/new_manual_annotations/similarity/sim_manual_nnunet_N43.csv')\n",
    "num_subjects = len(csv_file)\n",
    "csv_file = csv_file[~csv_file['Subject'].isin([int(x) for x in bad_files])].reset_index(drop=True)\n",
    "\n",
    "# Dataframes {DSC, nDSC, Volume (voxels)} separate labels for N=5 only\n",
    "data_dsc = [csv_file['DSC_all'], csv_file['DSC_lens'], csv_file['DSC_globe'], csv_file['DSC_nerve'], csv_file['DSC_int_fat'], csv_file['DSC_ext_fat'], csv_file['DSC_lat_mus'], csv_file['DSC_med_mus'], csv_file['DSC_inf_mus'], csv_file['DSC_sup_mus']]\n",
    "data_ndsc = [csv_file['nDSC_all'],  csv_file['nDSC_lens'], csv_file['nDSC_globe'], csv_file['nDSC_nerve'], csv_file['nDSC_int_fat'], csv_file['nDSC_ext_fat'], csv_file['nDSC_lat_mus'], csv_file['nDSC_med_mus'], csv_file['nDSC_inf_mus'], csv_file['nDSC_sup_mus']]\n",
    "data_vol = [csv_file['Volume_all'], csv_file['Volume_lens'], csv_file['Volume_globe'], csv_file['Volume_nerve'], csv_file['Volume_int_fat'], csv_file['Volume_ext_fat'], csv_file['Volume_lat_mus'], csv_file['Volume_med_mus'], csv_file['Volume_inf_mus'], csv_file['Volume_sup_mus']]\n",
    "data_haus = [csv_file['Haus_avg_all'], csv_file['Haus_avg_lens'], csv_file['Haus_avg_globe'], csv_file['Haus_avg_nerve'], csv_file['Haus_avg_int_fat'], csv_file['Haus_avg_ext_fat'], csv_file['Haus_avg_lat_mus'], csv_file['Haus_avg_med_mus'], csv_file['Haus_avg_inf_mus'], csv_file['Haus_avg_sup_mus']]\n",
    "\n",
    "labels = ['overall', 'lens', 'globe', 'nerve', 'intraconal fat', 'extraconal fat', 'lateral rectus muscle', 'medial rectus muscle', 'inferior rectus muscle', 'superior rectus muscle']\n",
    "median = [np.around(np.median(x), 2) for x in data_dsc]\n",
    "print('median DSC:')\n",
    "for i in range(len(labels)):\n",
    "    print(labels[i], median[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "fig, axs = plt.subplots(3, figsize=(20,10), sharex=True)\n",
    "fig.canvas.manager.set_window_title(f'Similarity metrics MANUAL vs nnUNet (N={num_subjects})')\n",
    "fig.suptitle(f'Similarity metrics MANUAL vs nnUNet (N={num_subjects})')\n",
    "fig.patch.set_facecolor('white')\n",
    "# fig.tight_layout(pad=2)\n",
    "\n",
    "# Set labels and titles\n",
    "axs[0].set_title('DSC')\n",
    "axs[0].set_ylim([0, 1])\n",
    "axs[1].set_title('Hausdorff distance')\n",
    "axs[1].set_ylim([0, 3])\n",
    "axs[2].set_title('Volume difference')\n",
    "axs[2].set_ylim([-2, 2])\n",
    "\n",
    "# Outliers\n",
    "flierprops = dict(markerfacecolor='0.9', markersize=2, linestyle='none')\n",
    "\n",
    "# Boxplot & Swarmplot (points)\n",
    "graph1 = sns.boxplot(data=data_dsc, ax=axs[0], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "graph2 = sns.boxplot(data=data_haus, ax=axs[1], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "graph3 = sns.boxplot(data=data_vol, ax=axs[2], flierprops=flierprops).set(ylabel=\"Value\")\n",
    "axs[2].set_xticklabels(['all','lens','globe','nerve','int_fat','ext_fat','lat_mus','med_mus','inf_mus','sup_mus'])\n",
    "\n",
    "# Save figure\n",
    "# plt.savefig('/home/jaimebarranco/Desktop/new_manual_annotations/similarity/sim_manual_nnunet_N43.png', bbox_inches='tight')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nDSC columns from csv_file\n",
    "csv_file = csv_file.drop(columns=['nDSC_all', 'nDSC_lens', 'nDSC_globe', 'nDSC_nerve', 'nDSC_int_fat', 'nDSC_ext_fat', 'nDSC_lat_mus', 'nDSC_med_mus', 'nDSC_inf_mus', 'nDSC_sup_mus'])\n",
    "# reorder columns, first the DSCs, then the Hausdorff distances, then the volumes\n",
    "csv_file = csv_file[['Subject', 'DSC_all', 'DSC_lens', 'DSC_globe', 'DSC_nerve', 'DSC_int_fat', 'DSC_ext_fat', 'DSC_lat_mus', 'DSC_med_mus', 'DSC_inf_mus', 'DSC_sup_mus', 'Haus_avg_all', 'Haus_avg_lens', 'Haus_avg_globe', 'Haus_avg_nerve', 'Haus_avg_int_fat', 'Haus_avg_ext_fat', 'Haus_avg_lat_mus', 'Haus_avg_med_mus', 'Haus_avg_inf_mus', 'Haus_avg_sup_mus', 'Volume_all', 'Volume_lens', 'Volume_globe', 'Volume_nerve', 'Volume_int_fat', 'Volume_ext_fat', 'Volume_lat_mus', 'Volume_med_mus', 'Volume_inf_mus', 'Volume_sup_mus']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk test for normality for each column of csv_file\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "for i in range(1, len(csv_file.columns)):\n",
    "    stat, p = shapiro(csv_file.iloc[:,i])\n",
    "    print(f'{csv_file.columns[i]}: Statistics={stat}, p={p}')\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('Sample does not look Gaussian (reject H0)')\n",
    "    # histogram plot\n",
    "    plt.hist(csv_file.iloc[:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers - IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_df1 = pd.DataFrame(columns=['Column', 'Outlier Subject'])\n",
    "bounds_df = pd.DataFrame(columns=['Column', 'Lower Bound', 'Upper Bound']) # dataFrame for bounds\n",
    "\n",
    "# Calculate the IQR for each column\n",
    "Q1 = csv_file.quantile(0.25)\n",
    "Q3 = csv_file.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Find the outliers for each column\n",
    "for column in csv_file.columns[1:]:\n",
    "    lower_bound = Q1[column] - 1.5 * IQR[column]\n",
    "    upper_bound = Q3[column] + 1.5 * IQR[column]\n",
    "\n",
    "    # Append bounds to the bounds_df DataFrame\n",
    "    new_row = pd.DataFrame({'Column': [column], 'Lower Bound': [lower_bound], 'Upper Bound': [upper_bound]})\n",
    "    bounds_df = pd.concat([bounds_df, new_row], ignore_index=True)\n",
    "\n",
    "    column_outliers = csv_file[(csv_file[column] < lower_bound) | (csv_file[column] > upper_bound)]\n",
    "    new_row = pd.DataFrame({'Column': [column], 'Outlier Subject': [column_outliers['Subject'].values]})\n",
    "    outliers_df1 = pd.concat([outliers_df1, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new DataFrame with the same structure as csv_file but filled with False\n",
    "outliers_df2 = pd.DataFrame(False, index=csv_file.index, columns=csv_file.columns)\n",
    "\n",
    "# Copy the 'Subject' column from csv_file to outliers_df\n",
    "outliers_df2['Subject'] = csv_file['Subject']\n",
    "\n",
    "# Calculate the IQR for each column excluding 'Subject'\n",
    "Q1 = csv_file.drop('Subject', axis=1).quantile(0.25)\n",
    "Q3 = csv_file.drop('Subject', axis=1).quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Find the outliers for each column excluding 'Subject'\n",
    "for column in csv_file.columns:\n",
    "    if column != 'Subject':\n",
    "        lower_bound = Q1[column] - 1.5 * IQR[column]\n",
    "        upper_bound = Q3[column] + 1.5 * IQR[column]\n",
    "        # Update outliers_df with True for outliers\n",
    "        outliers_df2[column] = (csv_file[column] < lower_bound) | (csv_file[column] > upper_bound)\n",
    "\n",
    "# Replace all False values with ''\n",
    "outliers_df2 = outliers_df2.replace(False, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# make a list of 'Outlier Subject' without duplicates in row and column\n",
    "outliers_list = []\n",
    "for i in range(len(outliers_df1)):\n",
    "    for j in range(len(outliers_df1.iloc[i,1])):\n",
    "        outliers_list.append(outliers_df1.iloc[i,1][j])\n",
    "\n",
    "# Count the occurrences of each outlier\n",
    "outliers_counter = Counter(outliers_list)\n",
    "\n",
    "# Keep only the outliers that appear more than once\n",
    "outliers_list = [item for item, count in outliers_counter.items() if count > 1]\n",
    "\n",
    "outliers_list = list(sorted(set(outliers_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reports to look at - removing already analysed subjects from atlas qc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc2_atlas = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_atlas.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_aux = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/df_aux.csv\")\n",
    "\n",
    "# subdataframe of df_aux with the outliers_list\n",
    "outliers_reports_df = df_aux[df_aux['subject'].isin(outliers_list)]\n",
    "# add 'my_rate' column to outliers_reports_df\n",
    "outliers_reports_df.loc[:, 'my_rate'] = 0.0\n",
    "# order outliers_reports_df by 'report'\n",
    "outliers_reports_df = outliers_reports_df.sort_values(by=['report'])\n",
    "# remove subjects from outliers_reports_df that are in qc2_atlas\n",
    "# outliers_reports_df = outliers_reports_df[~outliers_reports_df['subject'].isin(qc2_atlas['subject'])]\n",
    "# save outliers_reports_df to excel file\n",
    "# outliers_reports_df.to_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_nnunet.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc2_atlas = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_atlas.xlsx\")\n",
    "qc2_nnunet = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_nnunet.xlsx\")\n",
    "\n",
    "# joint dataframes\n",
    "qc2 = pd.concat([qc2_atlas, qc2_nnunet], ignore_index=True)\n",
    "# keep only the rows with '0' in my_rate column\n",
    "qc2 = qc2[qc2['my_rate'] == 0]\n",
    "# save it to .csv\n",
    "qc2.to_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATLAS vs nnUNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# CSVs\n",
    "csv_sm_reg = '/home/jaimebarranco/Desktop/new_manual_annotations/similarity/sim_manual_atlas_N43.csv'\n",
    "csv_sm_nn = '/home/jaimebarranco/Desktop/new_manual_annotations/similarity/sim_manual_nnunet_N43.csv'\n",
    "\n",
    "# Pandas read CSV\n",
    "df_reg = pd.read_csv(csv_sm_reg)\n",
    "df_nn = pd.read_csv(csv_sm_nn)\n",
    "\n",
    "# Gather data from generated dataframes\n",
    "df_dsc = np.array([\n",
    "    df_reg['DSC_all'], df_nn['DSC_all'],\n",
    "    df_reg['DSC_lens'], df_nn['DSC_lens'], \n",
    "    df_reg['DSC_globe'], df_nn['DSC_globe'], \n",
    "    df_reg['DSC_nerve'], df_nn['DSC_nerve'], \n",
    "    df_reg['DSC_int_fat'], df_nn['DSC_int_fat'], \n",
    "    df_reg['DSC_ext_fat'], df_nn['DSC_ext_fat'], \n",
    "    df_reg['DSC_lat_mus'], df_nn['DSC_lat_mus'], \n",
    "    df_reg['DSC_med_mus'], df_nn['DSC_med_mus'], \n",
    "    df_reg['DSC_inf_mus'], df_nn['DSC_inf_mus'], \n",
    "    df_reg['DSC_sup_mus'], df_nn['DSC_sup_mus']])\n",
    "df_hd = np.array([\n",
    "    df_reg['Haus_avg_all'], df_nn['Haus_avg_all'], \n",
    "    df_reg['Haus_avg_lens'], df_nn['Haus_avg_lens'], \n",
    "    df_reg['Haus_avg_globe'], df_nn['Haus_avg_globe'], \n",
    "    df_reg['Haus_avg_nerve'], df_nn['Haus_avg_nerve'], \n",
    "    df_reg['Haus_avg_int_fat'], df_nn['Haus_avg_int_fat'], \n",
    "    df_reg['Haus_avg_ext_fat'], df_nn['Haus_avg_ext_fat'], \n",
    "    df_reg['Haus_avg_lat_mus'], df_nn['Haus_avg_lat_mus'], \n",
    "    df_reg['Haus_avg_med_mus'], df_nn['Haus_avg_med_mus'], \n",
    "    df_reg['Haus_avg_inf_mus'], df_nn['Haus_avg_inf_mus'], \n",
    "    df_reg['Haus_avg_sup_mus'], df_nn['Haus_avg_sup_mus']])\n",
    "df_vol = np.array([\n",
    "    df_reg['Volume_all'], df_nn['Volume_all'], \n",
    "    df_reg['Volume_lens'], df_nn['Volume_lens'], \n",
    "    df_reg['Volume_globe'], df_nn['Volume_globe'], \n",
    "    df_reg['Volume_nerve'], df_nn['Volume_nerve'], \n",
    "    df_reg['Volume_int_fat'], df_nn['Volume_int_fat'], \n",
    "    df_reg['Volume_ext_fat'], df_nn['Volume_ext_fat'], \n",
    "    df_reg['Volume_lat_mus'], df_nn['Volume_lat_mus'], \n",
    "    df_reg['Volume_med_mus'], df_nn['Volume_med_mus'], \n",
    "    df_reg['Volume_inf_mus'], df_nn['Volume_inf_mus'], \n",
    "    df_reg['Volume_sup_mus'], df_nn['Volume_sup_mus']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import Line2D\n",
    "import numpy as np\n",
    "\n",
    "# Figure\n",
    "fig, axs = plt.subplots(3, sharex=True, figsize=(28,20))\n",
    "fig.canvas.manager.set_window_title(f'Similarity metrics ATLAS vs nnUNet (N={len(df_reg)})')\n",
    "fig.suptitle(f'Similarity metrics ATLAS vs nnUNet (N={len(df_reg)})')\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.tight_layout(pad=3)\n",
    "\n",
    "# Legend\n",
    "colours_palette = sns.color_palette(\"Blues\", 2)\n",
    "legend_elements = [Line2D([0], [0], color=colours_palette[0], lw=4, label='Atlas-based'),\n",
    "    Line2D([0], [0], color=colours_palette[1], lw=4, label='nnUNet'),\n",
    "    Line2D([], [], color='black', label='mean', marker='+', markersize=5, linestyle='None')]\n",
    "axs[0].legend(handles=legend_elements)\n",
    "\n",
    "# Axis\n",
    "axs[0].set_title('DSC')\n",
    "axs[0].set_ylim([0, 1])\n",
    "axs[1].set_title('Hausdorff distance')\n",
    "axs[1].set_ylim([0, 3])\n",
    "axs[2].set_title('Volume difference')\n",
    "axs[2].set_ylim([-2, 2])\n",
    "\n",
    "# Boxplots\n",
    "# colours_palette = ['green','purple','green','purple','green','purple','green','purple','green','purple','green','purple','green','purple','green','purple','green','purple','green','purple']\n",
    "meanpointprops = {\"marker\":\"+\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\", \"markersize\":\"10\"}\n",
    "graph1 = sns.boxplot(data=df_dsc.T, ax=axs[0], palette=colours_palette, showmeans=True, meanprops=meanpointprops).set(ylabel=\"Value\")\n",
    "graph2 = sns.boxplot(data=df_hd.T, ax=axs[1], palette=colours_palette, showmeans=True, meanprops=meanpointprops).set(ylabel=\"Value\")\n",
    "graph3 = sns.boxplot(data=df_vol.T, ax=axs[2], palette=colours_palette, showmeans=True, meanprops=meanpointprops).set(ylabel=\"Value\")\n",
    "# ax = sns.swarmplot(data=df_dsc)\n",
    "\n",
    "# axs[0].set_xticklabels([\n",
    "#     f'all \\n{np.around(np.median(df_dsc[0]), 3)}', f'all \\n{np.around(np.median(df_dsc[1]), 3)}',\n",
    "#     f'lens \\n{np.around(np.median(df_dsc[2]), 3)}', f'lens \\n{np.around(np.median(df_dsc[3]), 3)}',\n",
    "#     f'globe \\n{np.around(np.median(df_dsc[4]), 3)}', f'globe \\n{np.around(np.median(df_dsc[5]), 3)}',\n",
    "#     f'nerve \\n{np.around(np.median(df_dsc[6]), 3)}', f'nerve \\n{np.around(np.median(df_dsc[7]), 3)}',\n",
    "#     f'int_fat \\n{np.around(np.median(df_dsc[8]), 3)}', f'int_fat \\n{np.around(np.median(df_dsc[9]), 3)}',\n",
    "#     f'ext_fat \\n{np.around(np.median(df_dsc[10]), 3)}', f'ext_fat \\n{np.around(np.median(df_dsc[11]), 3)}',\n",
    "#     f'lat_mus \\n{np.around(np.median(df_dsc[12]), 3)}', f'lat_mus \\n{np.around(np.median(df_dsc[13]), 3)}',\n",
    "#     f'med_mus \\n{np.around(np.median(df_dsc[14]), 3)}', f'med_mus \\n{np.around(np.median(df_dsc[15]), 3)}',\n",
    "#     f'inf_mus \\n{np.around(np.median(df_dsc[16]), 3)}', f'inf_mus \\n{np.around(np.median(df_dsc[17]), 3)}',\n",
    "#     f'sup_mus \\n{np.around(np.median(df_dsc[18]), 3)}', f'sup_mus \\n{np.around(np.median(df_dsc[19]), 3)}'])\n",
    "\n",
    "axs[0].set_xticklabels([\n",
    "    f'all', f'all',\n",
    "    f'lens', f'lens',\n",
    "    f'globe', f'globe',\n",
    "    f'nerve', f'nerve',\n",
    "    f'int_fat', f'int_fat',\n",
    "    f'ext_fat', f'ext_fat',\n",
    "    f'lat_mus', f'lat_mus',\n",
    "    f'med_mus', f'med_mus',\n",
    "    f'inf_mus', f'inf_mus',\n",
    "    f'sup_mus', f'sup_mus'])\n",
    "\n",
    "# plt.savefig(f'/home/jaimebarranco/Desktop/new_manual_annotations/similarity/sim_atlas_vs_nn_N43.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair-wise comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapiro-Wilk test for Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# List to hold p-values for each metric\n",
    "p_values_shapiro = []\n",
    "\n",
    "# Shapiro-Wilk test for normality for each metric\n",
    "for metric_data in [df_dsc, df_hd, df_vol]:\n",
    "    for data in metric_data:\n",
    "        # Shapiro-Wilk test\n",
    "        stat, p_val = shapiro(data)\n",
    "        p_values_shapiro.append(p_val)\n",
    "\n",
    "# Check normality based on p-values (considering 0.05 significance level)\n",
    "is_normal = [p > 0.05 for p in p_values_shapiro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list labels DSC\n",
    "labels_DSC = ['DSC_all_reg', 'DSC_all_nn', 'DSC_lens_reg', 'DSC_lens_nn', 'DSC_globe_reg', 'DSC_globe_nn', 'DSC_nerve_reg', 'DSC_nerve_nn', 'DSC_int_fat_reg', 'DSC_int_fat_nn', 'DSC_ext_fat_reg', 'DSC_ext_fat_nn', 'DSC_lat_mus_reg', 'DSC_lat_mus_nn', 'DSC_med_mus_reg', 'DSC_med_mus_nn', 'DSC_inf_mus_reg', 'DSC_inf_mus_nn', 'DSC_sup_mus_reg', 'DSC_sup_mus_nn']\n",
    "# list labels Hausdorff distance\n",
    "labels_hd = ['HD_all_reg', 'HD_all_nn', 'HD_lens_reg', 'HD_lens_nn', 'HD_globe_reg', 'HD_globe_nn', 'HD_nerve_reg', 'HD_nerve_nn', 'HD_int_fat_reg', 'HD_int_fat_nn', 'HD_ext_fat_reg', 'HD_ext_fat_nn', 'HD_lat_mus_reg', 'HD_lat_mus_nn', 'HD_med_mus_reg', 'HD_med_mus_nn', 'HD_inf_mus_reg', 'HD_inf_mus_nn', 'HD_sup_mus_reg', 'HD_sup_mus_nn']\n",
    "# list labels Volume difference\n",
    "labels_vol = ['VD_all_reg', 'VD_all_nn', 'VD_lens_reg', 'VD_lens_nn', 'VD_globe_reg', 'VD_globe_nn', 'VD_nerve_reg', 'VD_nerve_nn', 'VD_int_fat_reg', 'VD_int_fat_nn', 'VD_ext_fat_reg', 'VD_ext_fat_nn', 'VD_lat_mus_reg', 'VD_lat_mus_nn', 'VD_med_mus_reg', 'VD_med_mus_nn', 'VD_inf_mus_reg', 'VD_inf_mus_nn', 'VD_sup_mus_reg', 'VD_sup_mus_nn']\n",
    "\n",
    "# concatenate labels\n",
    "labels = labels_DSC + labels_hd + labels_vol\n",
    "\n",
    "# dataframe with labels and is_normal\n",
    "df_normal = pd.DataFrame({'labels': labels, 'is_normal': is_normal})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison tests: Wilcoxon or Student's t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu, ttest_ind, ttest_rel, wilcoxon\n",
    "\n",
    "# For independent subjects: mannwhitneyu if not normal and ttest_ind if normal\n",
    "# For metrics on the same subject (our case): ttes_rel if normal and wilcoxon if not normal\n",
    "\n",
    "# List to hold u-values, p-values\n",
    "t_values_test = []\n",
    "u_values_test = []\n",
    "p_values_test = []\n",
    "\n",
    "# Perform comparison tests for each metric\n",
    "for metric_data in [df_dsc, df_hd, df_vol]:\n",
    "    for i in range(0, len(metric_data), 2):\n",
    "        method_1 = metric_data[i]\n",
    "        method_2 = metric_data[i + 1]\n",
    "        \n",
    "        if is_normal[i] and is_normal[i + 1]:\n",
    "            # If both are normal, use Student's t-test\n",
    "            t_val, p_val = ttest_rel(method_1, method_2) # ttest_ind, ttest_rel\n",
    "            t_values_test.append(t_val)\n",
    "        else:\n",
    "            # If not normal, use Mann-Whitney U test\n",
    "            u_val, p_val = wilcoxon(method_1, method_2) # mannwhitneyu, wilcoxon\n",
    "            u_values_test.append(u_val)\n",
    "        \n",
    "        p_values_test.append(p_val)\n",
    "\n",
    "# significant p-values\n",
    "is_significant = [p < 0.05 for p in p_values_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list pair-labels DSC\n",
    "pair_labels_DSC = ['DSC_all', 'DSC_lens', 'DSC_globe', 'DSC_nerve', 'DSC_int_fat', 'DSC_ext_fat', 'DSC_lat_mus', 'DSC_med_mus', 'DSC_inf_mus', 'DSC_sup_mus']\n",
    "# list labels Hausdorff distance\n",
    "pair_labels_hd = ['HD_all', 'HD_lens', 'HD_globe', 'HD_nerve', 'HD_int_fat', 'HD_ext_fat', 'HD_lat_mus', 'HD_med_mus', 'HD_inf_mus', 'HD_sup_mus']\n",
    "# list labels Volume difference\n",
    "pair_labels_vol = ['VD_all', 'VD_lens', 'VD_globe', 'VD_nerve', 'VD_int_fat', 'VD_ext_fat', 'VD_lat_mus', 'VD_med_mus', 'VD_inf_mus', 'VD_sup_mus']\n",
    "\n",
    "# concatenate labels\n",
    "pair_labels = pair_labels_DSC + pair_labels_hd + pair_labels_vol\n",
    "\n",
    "# dataframe with labels and is_significant\n",
    "df_significant = pd.DataFrame({'labels': pair_labels, 'is_significant': is_significant})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FDR correction (False Discovery Rate) - Benjamini-Hochberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Apply Benjamini-Hochberg procedure\n",
    "rejected, adjusted_p_values, _, _ = multipletests(p_values_test, method='fdr_bh')\n",
    "\n",
    "is_significant_fdr = [p < 0.05 for p in adjusted_p_values]\n",
    "\n",
    "# Find significant p-values after FDR correction\n",
    "significant_indices = [i for i, rej in enumerate(rejected) if rej]\n",
    "\n",
    "# Retrieve the significant p-values after FDR correction\n",
    "significant_p_values_fdr = [adjusted_p_values[i] for i in significant_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with labels and is_significant\n",
    "df_significant_fdr = pd.DataFrame({'labels': pair_labels, 'is_significant_fdr': is_significant_fdr})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohen's d values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "# Function to calculate confidence interval for Cohen's d\n",
    "def cohen_d_confidence_interval(x, y, alpha=0.05):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2  # Degrees of freedom\n",
    "\n",
    "    # Calculate Cohen's d\n",
    "    d = (np.mean(x) - np.mean(y)) / np.sqrt(((nx - 1) * np.var(x, ddof=1) + (ny - 1) * np.var(y, ddof=1)) / dof)\n",
    "    \n",
    "    # Calculate pooled standard deviation\n",
    "    pooled_var = ((nx - 1) * np.var(x, ddof=1) + (ny - 1) * np.var(y, ddof=1)) / dof\n",
    "    \n",
    "    # Calculate standard error\n",
    "    se = np.sqrt(pooled_var * (1 / nx + 1 / ny))\n",
    "    \n",
    "    # Calculate t-value for the confidence interval\n",
    "    t_val = t.ppf(1 - alpha / 2, dof)\n",
    "    \n",
    "    # Calculate margin of error\n",
    "    margin_error = t_val * se\n",
    "    \n",
    "    # Calculate lower and upper bounds of the confidence interval\n",
    "    lower_bound = d - margin_error\n",
    "    upper_bound = d + margin_error\n",
    "    \n",
    "    return d, lower_bound, upper_bound\n",
    "\n",
    "# List to hold the d values and the confidence intervals\n",
    "d_values = []\n",
    "confidence_intervals_low = []\n",
    "confidence_intervals_up = []\n",
    "effect = []\n",
    "\n",
    "# Perform comparison for each metric\n",
    "for metric_data in [df_dsc, df_hd, df_vol]:\n",
    "    for i in range(0, len(metric_data), 2):\n",
    "        method_1 = metric_data[i]\n",
    "        method_2 = metric_data[i + 1]\n",
    "\n",
    "        d, ci_low, ci_up = cohen_d_confidence_interval(method_1, method_2)\n",
    "\n",
    "        d_values.append(d)\n",
    "        confidence_intervals_low.append(ci_low)\n",
    "        confidence_intervals_up.append(ci_up)\n",
    "\n",
    "        if np.abs(d) < 0.5:\n",
    "            effect.append('low')\n",
    "        elif np.abs(d) > 0.5 and np.abs(d) < 0.8:\n",
    "            effect.append('medium')\n",
    "        else:\n",
    "            effect.append('strong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with labels, d_values and confidence intervals\n",
    "df_cohen_d = pd.DataFrame({'labels': pair_labels, 'd_values': d_values, 'confidence_intervals_low': confidence_intervals_low, 'confidence_intervals_up': confidence_intervals_up, 'effect': effect})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohen's d values bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bootstrap sampling N=5000\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "# Function to calculate confidence interval for Cohen's d\n",
    "def cohen_d(x, y, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calculate Cohen's d and confidence interval for the difference between two sample means.\n",
    "\n",
    "    Parameters:\n",
    "    x (array-like): First sample data.\n",
    "    y (array-like): Second sample data.\n",
    "    alpha (float, optional): Significance level for the confidence interval. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Tuple containing Cohen's d, lower bound of the confidence interval, and upper bound of the confidence interval.\n",
    "    \"\"\"\n",
    "\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2  # Degrees of freedom\n",
    "\n",
    "    # Calculate Cohen's d\n",
    "    d = (np.mean(x) - np.mean(y)) / np.sqrt(((nx - 1) * np.var(x, ddof=1) + (ny - 1) * np.var(y, ddof=1)) / dof)\n",
    "    \n",
    "    return d\n",
    "\n",
    "# Function to calculate confidence interval of an array of values\n",
    "def confidence_interval(x, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calculate confidence interval for an array of values.\n",
    "\n",
    "    Parameters:\n",
    "    x (array-like): Array of values.\n",
    "    alpha (float, optional): Significance level for the confidence interval. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Tuple containing lower bound of the confidence interval and upper bound of the confidence interval.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate mean\n",
    "    mean = np.mean(x)\n",
    "\n",
    "    # Calculate standard error\n",
    "    se = np.std(x) / np.sqrt(len(x))\n",
    "\n",
    "    # Calculate t-value for the confidence interval\n",
    "    t_val = t.ppf(1 - alpha / 2, len(x) - 1)\n",
    "\n",
    "    # Calculate margin of error\n",
    "    margin_error = t_val * se\n",
    "\n",
    "    # Calculate lower and upper bounds of the confidence interval\n",
    "    lower_bound = mean - margin_error\n",
    "    upper_bound = mean + margin_error\n",
    "\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# List to hold the d values and the confidence intervals\n",
    "d_values = []\n",
    "confidence_intervals_low = []\n",
    "confidence_intervals_up = []\n",
    "effect = []\n",
    "\n",
    "# Number of bootstrap iterations\n",
    "n_iterations = 5000\n",
    "\n",
    "# Perform comparison for each metric\n",
    "for metric_data in [df_dsc, df_hd, df_vol]:\n",
    "    for i in range(0, len(metric_data), 2):\n",
    "        method_1 = metric_data[i]\n",
    "        method_2 = metric_data[i + 1]\n",
    "        d_values_iter = []\n",
    "\n",
    "        # Bootstrap sampling\n",
    "        for _ in range(n_iterations):\n",
    "            sample_1 = np.random.choice(method_1, size=int(0.8 * len(method_1)), replace=True)\n",
    "            sample_2 = np.random.choice(method_2, size=int(0.8 * len(method_2)), replace=True)\n",
    "\n",
    "            d = cohen_d(sample_1, sample_2)\n",
    "\n",
    "            d_values_iter.append(d)\n",
    "\n",
    "        # Calculate mean and confidence intervals\n",
    "        d_values.append(np.mean(d_values_iter))\n",
    "        confidence_intervals_low.append(confidence_interval(d_values_iter))\n",
    "        confidence_intervals_up.append(confidence_interval(d_values_iter))\n",
    "\n",
    "# Measure effect\n",
    "for d_value in d_values:\n",
    "    if np.abs(d_value) < 0.5:\n",
    "        effect.append('low')\n",
    "    elif np.abs(d_value) > 0.5 and np.abs(d_value) < 0.8:\n",
    "        effect.append('medium')\n",
    "    else:\n",
    "        effect.append('strong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with labels, d_values and confidence intervals\n",
    "df_cohen_d_bootstrap = pd.DataFrame({'labels': pair_labels, 'd_values': d_values, 'confidence_intervals_low': confidence_intervals_low, 'confidence_intervals_up': confidence_intervals_up, 'effect': effect})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('3dmultilabel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "236677abf66ddcf33094279068f0bab187d6786b2da11104f264e332fab0dfcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
