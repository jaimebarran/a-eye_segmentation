{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract biometrics from segmentation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age, Sex, Height, Weight, BMI (= weight/height² [kg/m²])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import sys, os, glob\n",
    "import pydicomext as pydcm\n",
    "from pydicom.fileset import FileSet\n",
    "from deid.data import get_dataset\n",
    "from deid.dicom import get_files, get_identifiers\n",
    "from pathlib import Path\n",
    "\n",
    "input_path = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/labeled_dataset/a123_t1_dicom/'\n",
    "\n",
    "# List of volumes for each individual label and subject\n",
    "len_path = len([elem for elem in os.listdir(input_path)])\n",
    "name_subject = [None]*len_path\n",
    "age_subject = [None]*len_path\n",
    "sex_subject = [None]*len_path\n",
    "height_subject = [None]*len_path\n",
    "weight_subject = [None]*len_path\n",
    "bmi_subject = [None]*len_path\n",
    "\n",
    "# Create sorted list\n",
    "i=0\n",
    "list_subs = [None]*len_path\n",
    "for folder1 in sorted(os.listdir(input_path)):\n",
    "    list_subs[i] = folder1\n",
    "    i+=1\n",
    "\n",
    "# Start subloop from specific subject (0 if it's from the beginning)\n",
    "index_sub = 0  # list_subs.index('2022160103683') # index_sub = 0 # if it's from the beginning\n",
    "# print(f'subject index: {index_sub}')\n",
    "\n",
    "# Loop sublist\n",
    "k=0\n",
    "for j in range(index_sub, len_path):\n",
    "\n",
    "    dicom_folder = f'{input_path}{list_subs[j]}/Kopf_t1_mpr_tra_iso_p2_FIL/'\n",
    "    dicom_files = sorted(glob.glob(os.path.join(dicom_folder, \"*.dcm\")))\n",
    "    ids = get_identifiers(dicom_files)\n",
    "\n",
    "    print(ids[dicom_files[0]].keys())\n",
    "\n",
    "    # ID\n",
    "    field_id = ids[dicom_files[0]]['(0010, 0020)']\n",
    "    id = field_id.element.value\n",
    "    name_subject[j] = id\n",
    "    print(f'subject: {id}')\n",
    "\n",
    "    # Sex\n",
    "    field_sex = ids[dicom_files[0]]['(0010, 0040)']\n",
    "    sex = field_sex.element.value\n",
    "    sex_subject[j] = sex\n",
    "    print(f'sex: {sex}')\n",
    "    # name = field_sex.name\n",
    "    # uid = field_sex.uid\n",
    "\n",
    "    # Age\n",
    "    field_age = ids[dicom_files[0]]['(0010, 1010)']\n",
    "    age = field_age.element.value\n",
    "    age = age[1:3]\n",
    "    age_subject[j] = age\n",
    "    print(f'age: {age}')\n",
    "\n",
    "    # Height\n",
    "    try:\n",
    "        field_height = ids[dicom_files[0]]['(0010, 1020)']\n",
    "        height = field_height.element.value\n",
    "        height_subject[j] = height\n",
    "    except KeyError:\n",
    "        field_height = None\n",
    "        height = None\n",
    "        height_subject[j] = None\n",
    "    print(f'height: {height} m')\n",
    "\n",
    "    # Weight\n",
    "    field_weight = ids[dicom_files[0]]['(0010, 1030)']\n",
    "    weight = field_weight.element.value\n",
    "    weight_subject[j] = weight\n",
    "    print(f'weight: {weight} kg')\n",
    "\n",
    "    # BMI (kg/m²)\n",
    "    if height != None:\n",
    "        bmi_subject[j] = weight / (height**2)\n",
    "    print(f'BMI: {bmi_subject[j]} kg/m²')\n",
    "\n",
    "    k+=1\n",
    "    # if k==1:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save values to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "column_names = ['Subject','Sex','Age','Height','Weight','BMI']\n",
    "vals = np.array([name_subject, sex_subject, age_subject, height_subject, weight_subject, bmi_subject])\n",
    "vals = vals.T\n",
    "vals = vals[index_sub:]\n",
    "\n",
    "# if index_sub != 0:\n",
    "#     # Reader\n",
    "#     with open('/mnt/sda1/Repos/a-eye/Output/sub_metadata_labeled.csv', 'r') as read_file:\n",
    "#         reader = csv.reader(read_file)\n",
    "#         lines = list(reader)\n",
    "#         lines = lines[0:index_sub+1]\n",
    "#         lines.extend(list(vals))\n",
    "# Writer\n",
    "with open('/mnt/sda1/Repos/a-eye/Output/sub_metadata_labeled_dataset.csv', 'w') as write_file:\n",
    "    writer = csv.writer(write_file)\n",
    "    if index_sub==0: # only writing columns if not starting from the first subject\n",
    "        writer.writerow(column_names)\n",
    "        lines = vals\n",
    "    writer.writerows(lines)\n",
    "\n",
    "# read_file.close()\n",
    "write_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read values from.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "csv_file = '/mnt/sda1/Repos/a-eye/Output/metadata/sub_metadata.csv'\n",
    "pd_csv = pd.read_csv(csv_file)\n",
    "\n",
    "# Data from .csv\n",
    "sex_csv = np.array([pd_csv[\"Sex\"]], dtype='<U7')\n",
    "age_csv = np.array([pd_csv[\"Age\"]])\n",
    "num_males = np.count_nonzero(np.char.count(sex_csv, \"M\"))\n",
    "num_females = np.count_nonzero(np.char.count(sex_csv, \"F\"))\n",
    "\n",
    "print(f'mean age is: {np.around(np.mean(age_csv), 1)}, std: {int(np.std(age_csv))}, min age is: {np.amin(age_csv)}, max age is: {np.amax(age_csv)}')\n",
    "print(f'men: {num_males}, women: {num_females}')\n",
    "\n",
    "# Sex group using pandas\n",
    "sex_group = pd_csv.groupby([\"Sex\"], dropna=True)\n",
    "\n",
    "# Print sex group\n",
    "# for name, group in sex_group:\n",
    "#     print(name)\n",
    "#     print(group)\n",
    "\n",
    "# Male group\n",
    "male_group = sex_group.get_group(\"M\").dropna() # group by male and remove NaN values\n",
    "bmi_male = np.array([male_group[\"BMI\"]])\n",
    "mean_bmi_male = np.around(np.mean(bmi_male), decimals=1)\n",
    "std_bmi_male = np.around(np.std(bmi_male), decimals=1)\n",
    "underweight_male = np.count_nonzero(bmi_male<18.5)\n",
    "non_overweight_male = np.count_nonzero(np.logical_and(18.5<=bmi_male, bmi_male<25))\n",
    "overweight_male = np.count_nonzero(np.logical_and(25<=bmi_male, bmi_male<30))\n",
    "obese_male = np.count_nonzero(bmi_male>=30)\n",
    "print(f'- MALES ({male_group.shape[0]}): \\n     BMI = {np.around(mean_bmi_male, 1)} +- {np.around(std_bmi_male, 1)} kg/m² \\\n",
    "Underweight: {underweight_male}; Non-overweight: {non_overweight_male}; Overweight: {overweight_male}; Obese: {obese_male}')\n",
    "\n",
    "# Female group\n",
    "female_group = sex_group.get_group(\"F\").dropna() # group by female and remove NaN values (there is one that has no height)\n",
    "bmi_female = np.array([female_group[\"BMI\"]])\n",
    "mean_bmi_female = np.around(np.mean(bmi_female), decimals=1)\n",
    "std_bmi_female = np.around(np.std(bmi_female), decimals=1)\n",
    "underweight_female = np.count_nonzero(bmi_female<18.5)\n",
    "non_overweight_female = np.count_nonzero(np.logical_and(18.5<=bmi_female, bmi_female<25))\n",
    "overweight_female = np.count_nonzero(np.logical_and(25<=bmi_female, bmi_female<30))\n",
    "obese_female = np.count_nonzero(bmi_female>=30)\n",
    "print(f'- FEMALES ({female_group.shape[0]}): \\n     BMI = {np.around(mean_bmi_female, 1)} +- {np.around(std_bmi_female, 1)} kg/m² \\\n",
    "Underweight: {underweight_female}; Non-overweight: {non_overweight_female}; Overweight: {overweight_female}; Obese: {obese_female}')\n",
    "\n",
    "# Total\n",
    "print(f'- TOTAL ({male_group.shape[0] + female_group.shape[0]}): \\n     Underweight: {underweight_female + underweight_male}; \\\n",
    "Non-overweight: {non_overweight_female + non_overweight_male}; Overweight: {overweight_female + overweight_male}; \\\n",
    "Obese: {obese_female + obese_male}')\n",
    "\n",
    "\n",
    "# PLOT #\n",
    "\n",
    "# Sex\n",
    "fig1 = plt.figure(figsize=(5,5))\n",
    "fig1.patch.set_facecolor('white')\n",
    "plt.bar(('Males', 'Females'), (num_males, num_females))\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Number of subjects')\n",
    "plt.title(f'Number of subjects grouped by sex ({num_males+num_females} subjects)')\n",
    "plt.show()\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/sex_bargraph.png')\n",
    "\n",
    "# Age\n",
    "age_counts = pd_csv[\"Age\"].value_counts()\n",
    "fig2 = px.bar(age_counts, title=f'Distribution of age ({num_males+num_females} subjects)')\n",
    "fig2.update_layout(\n",
    "    xaxis_title = 'Age',\n",
    "    yaxis_title = 'Frequency',\n",
    "    title_x = 0.5,\n",
    "    showlegend = False\n",
    ")\n",
    "fig2.show()\n",
    "fig2.write_image('/mnt/sda1/Repos/a-eye/Output/age_bargraph.png')\n",
    "\n",
    "# BMI\n",
    "bmi_labels = ('Underweight', 'Non-overweight', 'Overweight', 'Obese')\n",
    "bmi_percentages_male = np.array([underweight_male, non_overweight_male, overweight_male, obese_male]) / male_group.shape[0]\n",
    "bmi_percentages_female = np.array([underweight_female, non_overweight_female, overweight_female, obese_female]) / female_group.shape[0]\n",
    "bmi_colors = ('tab:red','tab:blue','tab:orange','tab:green')\n",
    "fig3, axs3 = plt.subplots(1, 2, figsize=(10, 5))\n",
    "fig3.patch.set_facecolor('white')\n",
    "fig3.suptitle(f'BMI classification ({num_males+num_females} subjects)')\n",
    "axs3[0].pie(bmi_percentages_male, labels=bmi_labels, startangle=45, colors=bmi_colors, autopct='%1.1f%%')\n",
    "axs3[0].axis('equal'), axs3[0].set_title(f'Males ({male_group.shape[0]})')\n",
    "axs3[1].pie(bmi_percentages_female, labels=bmi_labels, startangle=45, colors=bmi_colors, autopct='%1.1f%%')\n",
    "axs3[1].axis('equal'), axs3[1].set_title(f'Females ({female_group.shape[0]})')\n",
    "plt.show()\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/bmi_piechart.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint metadata (labeled and non-labeled datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "md1 = '/mnt/sda1/Repos/a-eye/Output/metadata/sub_metadata_labeled_dataset.csv'\n",
    "md2 = '/mnt/sda1/Repos/a-eye/Output/metadata/sub_metadata_non_labeled_dataset.csv'\n",
    "\n",
    "# Read the CSV files into DataFrames with the first column as strings\n",
    "df_md1 = pd.read_csv(md1, dtype={'Subject': str})\n",
    "df_md2 = pd.read_csv(md2, dtype={'Subject': str})\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df_md_all = pd.concat([df_md1, df_md2], ignore_index=True)\n",
    "\n",
    "# Write the combined DataFrame to a new CSV file\n",
    "df_md_all.to_csv('/mnt/sda1/Repos/a-eye/Output/metadata/sub_metadata_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volumetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import pi\n",
    "\n",
    "# Measures\n",
    "# GLOBE\n",
    "# The means for the horizontal and vertical diameters are 24.26 ± 0.96 mm (n = 518) and 24.16 ± 0.97 mm (n = 510), respectively.\n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3432692/#:~:text=In%20the%20adult%2C%20the%20spherical,11.8%20and%2011.2%20mm%2C%20respectively\n",
    "globe_avg_diameter = 24.2 # mm\n",
    "globe_avg_volume = 4/3*pi*((globe_avg_diameter/2)**3) # mm³\n",
    "print(globe_avg_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "\n",
    "METHOD = 'dl'\n",
    "\n",
    "# Paths - segmentation results\n",
    "if METHOD=='atlas':\n",
    "    main_path = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/'\n",
    "    input_path = main_path + 'non_labeled_dataset_nifti_reg_2/'\n",
    "elif METHOD=='dl':\n",
    "    main_path = '/mnt/sda1/Repos/a-eye/a-eye_segmentation/deep_learning/nnUNet/nnUNet/nnUNet_inference/'\n",
    "    input_path = main_path + 'no_postprocessing/'\n",
    "\n",
    "# List of volumes for each individual label and subject\n",
    "len_path = len([elem for elem in glob.glob(f'{input_path}*.nii.gz')])\n",
    "name_subject = ['' for _ in range(len_path)]\n",
    "vol_lens = np.zeros(len_path)\n",
    "vol_globe = np.zeros(len_path)\n",
    "vol_nerve = np.zeros(len_path)\n",
    "vol_int_fat = np.zeros(len_path)\n",
    "vol_ext_fat = np.zeros(len_path)\n",
    "vol_lat_mus = np.zeros(len_path)\n",
    "vol_med_mus = np.zeros(len_path)\n",
    "vol_inf_mus = np.zeros(len_path)\n",
    "vol_sup_mus = np.zeros(len_path)\n",
    "vol_total = np.zeros(len_path)\n",
    "\n",
    "i=0\n",
    "# for folder1 in sorted(os.listdir(input_path)):\n",
    "for file in sorted(glob.glob(f'{input_path}*.nii.gz')):\n",
    "    \n",
    "    # Subject's name\n",
    "    basename = os.path.basename(file)\n",
    "    if METHOD=='atlas': name_subject[i] = basename\n",
    "    elif METHOD=='dl': name_subject[i] = basename.split('_')[1].split('.')[0]\n",
    "    print(f'subject: {name_subject[i]}')\n",
    "\n",
    "    # Load image in array format\n",
    "    if METHOD=='atlas': \n",
    "        lab_arr = nb.load(file).get_fdata()\n",
    "    elif METHOD=='dl': \n",
    "        lab_arr = nb.load(file).get_fdata()\n",
    "        lab_arr = lab_arr[int(np.around(lab_arr.shape[0]/2)):lab_arr.shape[0], int(np.around(lab_arr.shape[1]/2)):lab_arr.shape[1], 0:lab_arr.shape[2]] # quadrant right eye\n",
    "\n",
    "    # # plot lab_arr in 3D -  to check we are in the right quadrant, for nnUNet case\n",
    "    # from matplotlib import pyplot as plt\n",
    "    # from mpl_toolkits.mplot3d import Axes3D\n",
    "    # fig = plt.figure(figsize=(10,10))\n",
    "    # ax = fig.add_subplot(111, projection='3d')\n",
    "    # ax.voxels(lab_arr, edgecolor='k')\n",
    "    # plt.show()\n",
    "\n",
    "    # Total volumetry of the subject's eye\n",
    "    total_vol = np.count_nonzero(lab_arr)\n",
    "    vol_total[i] = total_vol # / total_vol\n",
    "    print(f'Total volume of the eye: {total_vol} mm³')\n",
    "\n",
    "    # Lens\n",
    "    vol_lens[i] = np.count_nonzero(lab_arr==1) # / total_vol\n",
    "    print(f'lens {vol_lens[i]}')\n",
    "\n",
    "    # Globe\n",
    "    vol_globe[i] = np.count_nonzero(lab_arr==2) # / total_vol\n",
    "    print(f'globe {vol_globe[i]}')\n",
    "\n",
    "    # Nerve\n",
    "    vol_nerve[i] = np.count_nonzero(lab_arr==3) # / total_vol\n",
    "    print(f'nerve {vol_nerve[i]}')\n",
    "\n",
    "    # Intraconal fat\n",
    "    vol_int_fat[i] = np.count_nonzero(lab_arr==4) # / total_vol\n",
    "    print(f'intraconal fat {vol_int_fat[i]}')\n",
    "\n",
    "    # Extraconal fat\n",
    "    vol_ext_fat[i] = np.count_nonzero(lab_arr==5) # / total_vol\n",
    "    print(f'extraconal fat {vol_ext_fat[i]}')\n",
    "\n",
    "    # Lateral rectus muscle\n",
    "    vol_lat_mus[i] = np.count_nonzero(lab_arr==6) # / total_vol\n",
    "    print(f'lateral rectus muscle {vol_lat_mus[i]}')\n",
    "\n",
    "    # Medial rectus muscle\n",
    "    vol_med_mus[i] = np.count_nonzero(lab_arr==7) # / total_vol\n",
    "    print(f'medial rectus muscle {vol_med_mus[i]}')\n",
    "\n",
    "    # Inferior rectus muscle\n",
    "    vol_inf_mus[i] = np.count_nonzero(lab_arr==8) # / total_vol\n",
    "    print(f'medial rectus muscle {vol_inf_mus[i]}')\n",
    "\n",
    "    # Superior rectus muscle\n",
    "    vol_sup_mus[i] = int(np.count_nonzero(lab_arr==9)) # / total_vol\n",
    "    print(f'superior rectus muscle {vol_sup_mus[i]}\\n')\n",
    "\n",
    "    i+=1\n",
    "    # if i==1:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save values into .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "if METHOD=='atlas': filename = 'volumes_reg_total.csv'\n",
    "elif METHOD=='dl': filename = 'volumes_nnunet_right_eye.csv'\n",
    "\n",
    "column_names = ['Subject','vol_lens','vol_globe','vol_nerve','vol_int_fat','vol_ext_fat','vol_lat_mus','vol_med_mus','vol_inf_mus','vol_sup_mus','vol_total']\n",
    "vals = np.array([name_subject, vol_lens, vol_globe, vol_nerve, vol_int_fat, vol_ext_fat, vol_lat_mus, vol_med_mus, vol_inf_mus, vol_sup_mus, vol_total])\n",
    "vals = vals.T\n",
    "with open('/mnt/sda1/Repos/a-eye/Output/volumetry/nnunet/' + filename, 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(column_names)\n",
    "    writer.writerows(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read values from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from turtle import color\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "METHOD = 'dl'\n",
    "\n",
    "if METHOD=='atlas':\n",
    "    main_path = '/mnt/sda1/Repos/a-eye/Output/volumetry/atlas/'\n",
    "    filename = 'volumes_reg_total.csv'\n",
    "elif METHOD=='dl':\n",
    "    main_path = '/mnt/sda1/Repos/a-eye/Output/volumetry/nnunet/'\n",
    "    filename = 'volumes_nnunet_right_eye.csv'\n",
    "\n",
    "df_vol = pd.read_csv(main_path + filename)\n",
    "\n",
    "# lens\n",
    "vol_lens = np.array([df_vol[\"vol_lens\"]])\n",
    "vol_lens = vol_lens[vol_lens != 0] # drop 0 values\n",
    "print(f'lens - mean: {np.mean(vol_lens)}, std: {np.std(vol_lens)}')\n",
    "\n",
    "# globe\n",
    "vol_globe = np.array([df_vol[\"vol_globe\"]])\n",
    "vol_globe = vol_globe[vol_globe != 0] # drop 0 values\n",
    "print(f'globe - mean: {np.mean(vol_globe)}, std: {np.std(vol_globe)}')\n",
    "\n",
    "# nerve\n",
    "vol_nerve = np.array([df_vol[\"vol_nerve\"]])\n",
    "vol_nerve = vol_nerve[vol_nerve != 0] # drop 0 values\n",
    "print(f'nerve - mean: {np.mean(vol_nerve)}, std: {np.std(vol_nerve)}')\n",
    "\n",
    "# intraconal fat\n",
    "vol_int_fat = np.array([df_vol[\"vol_int_fat\"]])\n",
    "vol_int_fat = vol_int_fat[vol_int_fat != 0] # drop 0 values\n",
    "print(f'intraconal fat - mean: {np.mean(vol_int_fat)}, std: {np.std(vol_int_fat)}')\n",
    "\n",
    "# extraconal fat\n",
    "vol_ext_fat = np.array([df_vol[\"vol_ext_fat\"]])\n",
    "vol_ext_fat = vol_ext_fat[vol_ext_fat != 0] # drop 0 values\n",
    "print(f'extraconal fat - mean: {np.mean(vol_ext_fat)}, std: {np.std(vol_ext_fat)}')\n",
    "\n",
    "# lateral rectus muscle\n",
    "vol_lat_mus = np.array([df_vol[\"vol_lat_mus\"]])\n",
    "vol_lat_mus = vol_lat_mus[vol_lat_mus != 0] # drop 0 values\n",
    "print(f'lateral rectus muscle - mean: {np.mean(vol_lat_mus)}, std: {np.std(vol_lat_mus)}')\n",
    "\n",
    "# medial rectus muscle\n",
    "vol_med_mus= np.array([df_vol[\"vol_med_mus\"]])\n",
    "vol_med_mus = vol_med_mus[vol_med_mus != 0] # drop 0 values\n",
    "print(f'medial rectus muscle - mean: {np.mean(vol_med_mus)}, std: {np.std(vol_med_mus)}')\n",
    "\n",
    "# inferior rectus muscle\n",
    "vol_inf_mus = np.array([df_vol[\"vol_inf_mus\"]])\n",
    "vol_inf_mus = vol_inf_mus[vol_inf_mus != 0] # drop 0 values\n",
    "print(f'inferior rectus muscle - mean: {np.mean(vol_inf_mus)}, std: {np.std(vol_inf_mus)}')\n",
    "\n",
    "# superior rectus muscle\n",
    "vol_sup_mus = np.array([df_vol[\"vol_sup_mus\"]])\n",
    "vol_sup_mus = vol_sup_mus[vol_sup_mus != 0] # drop 0 values\n",
    "print(f'superior rectus muscle - mean: {np.mean(vol_sup_mus)}, std: {np.std(vol_sup_mus)}')\n",
    "\n",
    "# Subplots\n",
    "k = 1.5 # Figure size to preserve ratio 16:9\n",
    "fig, ax = plt.subplots(2, 5, figsize=(16*k, 9*k))\n",
    "fig.suptitle('Volume per label (mm³) - nnUNet')\n",
    "fig.patch.set_facecolor('white')\n",
    "fix_axis = False\n",
    "# x_axis = [-2, 2]\n",
    "# y_axis = [-2.5, 3.5]\n",
    "\n",
    "# lens\n",
    "ax[0][0].set_title(f'lens - mean: {np.round(np.mean(vol_lens))}, std: {np.round(np.std(vol_lens), 2)}')\n",
    "graph_lens = sns.boxplot(df_vol['vol_lens'], ax=ax[0][0])\n",
    "# graph_lens.axhline(np.round(np.mean(vol_lens)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][0].set_xlim(x_axis)\n",
    "    ax[0][0].set_ylim([0, 160])\n",
    "\n",
    "# globe\n",
    "ax[0][1].set_title(f'globe - mean: {np.round(np.mean(vol_globe))}, std: {np.round(np.std(vol_globe), 2)}')\n",
    "graph_globe = sns.boxplot(df_vol['vol_globe'], ax=ax[0][1])\n",
    "# graph_globe.axhline(np.round(np.mean(vol_globe)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][1].set_xlim(x_axis)\n",
    "    ax[0][1].set_ylim([2500, 9000])\n",
    "\n",
    "# nerve\n",
    "ax[0][2].set_title(f'nerve - mean: {np.round(np.mean(vol_nerve))}, std: {np.round(np.std(vol_nerve), 2)}')\n",
    "graph_nerve = sns.boxplot(df_vol['vol_nerve'], ax=ax[0][2])\n",
    "# graph_nerve.axhline(np.round(np.mean(vol_nerve)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][2].set_xlim(x_axis)\n",
    "    ax[0][2].set_ylim([300, 1100])\n",
    "\n",
    "# intraconal fat\n",
    "ax[0][3].set_title(f'int fat - mean: {np.round(np.mean(vol_int_fat))}, std: {np.round(np.std(vol_int_fat), 2)}')\n",
    "graph_int_fat = sns.boxplot(df_vol['vol_int_fat'], ax=ax[0][3])\n",
    "# graph_int_fat.axhline(np.round(np.mean(vol_int_fat)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][3].set_xlim(x_axis)\n",
    "    ax[0][3].set_ylim([2000, 7000])\n",
    "\n",
    "# extraconal fat\n",
    "ax[0][4].set_title(f'ext fat - mean: {np.round(np.mean(vol_ext_fat))}, std: {np.round(np.std(vol_ext_fat), 2)}')\n",
    "graph_ext_fat = sns.boxplot(df_vol['vol_ext_fat'], ax=ax[0][4])\n",
    "# graph_ext_fat.axhline(np.round(np.mean(vol_ext_fat)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][4].set_xlim(x_axis)\n",
    "    ax[0][4].set_ylim([1000, 7000])\n",
    "\n",
    "# lateral rectus muscle\n",
    "ax[1][0].set_title(f'lat mus - mean: {np.round(np.mean(vol_lat_mus))}, std: {np.round(np.std(vol_lat_mus), 2)}')\n",
    "graph_lat_mus = sns.boxplot(df_vol['vol_ext_fat'], ax=ax[1][0])\n",
    "# graph_lat_mus.axhline(np.round(np.mean(vol_ext_fat)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[1][0].set_xlim(x_axis)\n",
    "    ax[1][0].set_ylim([1000, 8000])    \n",
    "\n",
    "# medial rectus muscle\n",
    "ax[1][1].set_title(f'med mus - mean: {np.round(np.mean(vol_med_mus))}, std: {np.round(np.std(vol_med_mus), 2)}')\n",
    "graph_med_mus = sns.boxplot(df_vol['vol_med_mus'], ax=ax[1][1])\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_med_mus)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[1][1].set_xlim(x_axis)\n",
    "    ax[1][1].set_ylim([400, 1500])\n",
    "\n",
    "# inferior rectus muscle\n",
    "ax[1][2].set_title(f'inf mus - mean: {np.round(np.mean(vol_inf_mus))}, std: {np.round(np.std(vol_inf_mus), 2)}')\n",
    "graph_med_mus = sns.boxplot(df_vol['vol_inf_mus'], ax=ax[1][2])\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_inf_mus)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[1][2].set_xlim(x_axis)\n",
    "    ax[1][2].set_ylim([400, 1300])\n",
    "\n",
    "# superior rectus muscle\n",
    "ax[1][3].set_title(f'sup mus - mean: {np.round(np.mean(vol_sup_mus))}, std: {np.round(np.std(vol_sup_mus), 2)}')\n",
    "graph_med_mus = sns.boxplot(df_vol['vol_sup_mus'], ax=ax[1][3])\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_sup_mus)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[1][3].set_xlim(x_axis)\n",
    "    ax[1][3].set_ylim([300, 2000])     \n",
    "\n",
    "plt.show\n",
    "\n",
    "# plt.savefig(main_path + filename.split('.')[0] + '_boxplot.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate csv and group by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "\n",
    "# Concat csv in one dataframe (metadata + volumes per label)\n",
    "METHOD = 'dl'\n",
    "\n",
    "# Paths\n",
    "csv_metadata = '/mnt/sda1/Repos/a-eye/Output/metadata/sub_metadata.csv'\n",
    "if METHOD=='atlas':\n",
    "    csv_volumes = '/mnt/sda1/Repos/a-eye/Output/volumetry/atlas/volumes_reg_total.csv'\n",
    "elif METHOD=='dl':\n",
    "    csv_volumes = '/mnt/sda1/Repos/a-eye/Output/volumetry/nnunet/volumes_nnunet.csv'\n",
    "\n",
    "# Pandas read csv\n",
    "pd_metadata = pd.read_csv(csv_metadata)\n",
    "pd_volumes= pd.read_csv(csv_volumes)\n",
    "\n",
    "# Dataframe\n",
    "df = pd.concat([pd_metadata, pd_volumes.iloc[:, 1:]], axis=1, verify_integrity=True)\n",
    "\n",
    "# Group by sex (males and females)\n",
    "sex_group = df.groupby([\"Sex\"], dropna=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Male group\n",
    "male_group = sex_group.get_group(\"M\").dropna() \n",
    "\n",
    "# lens\n",
    "vol_lens = np.array([male_group[\"vol_lens\"]])\n",
    "print(f'lens - mean: {np.mean(vol_lens)}, std: {np.std(vol_lens)}')\n",
    "\n",
    "# globe\n",
    "vol_globe = np.array([male_group[\"vol_globe\"]])\n",
    "print(f'globe - mean: {np.mean(vol_globe)}, std: {np.std(vol_globe)}')\n",
    "\n",
    "# nerve\n",
    "vol_nerve = np.array([male_group[\"vol_nerve\"]])\n",
    "print(f'nerve - mean: {np.mean(vol_nerve)}, std: {np.std(vol_nerve)}')\n",
    "\n",
    "# intraconal fat\n",
    "vol_int_fat = np.array([male_group[\"vol_int_fat\"]])\n",
    "print(f'intraconal fat - mean: {np.mean(vol_int_fat)}, std: {np.std(vol_int_fat)}')\n",
    "\n",
    "# extraconal fat\n",
    "vol_ext_fat = np.array([male_group[\"vol_ext_fat\"]])\n",
    "print(f'extraconal fat - mean: {np.mean(vol_ext_fat)}, std: {np.std(vol_ext_fat)}')\n",
    "\n",
    "# lateral rectus muscle\n",
    "vol_lat_mus = np.array([male_group[\"vol_lat_mus\"]])\n",
    "print(f'lateral rectus muscle - mean: {np.mean(vol_lat_mus)}, std: {np.std(vol_lat_mus)}')\n",
    "\n",
    "# medial rectus muscle\n",
    "vol_med_mus= np.array([male_group[\"vol_med_mus\"]])\n",
    "print(f'medial rectus muscle - mean: {np.mean(vol_med_mus)}, std: {np.std(vol_med_mus)}')\n",
    "\n",
    "# inferior rectus muscle\n",
    "vol_inf_mus = np.array([male_group[\"vol_inf_mus\"]])\n",
    "print(f'inferior rectus muscle - mean: {np.mean(vol_inf_mus)}, std: {np.std(vol_inf_mus)}')\n",
    "\n",
    "# superior rectus muscle\n",
    "vol_sup_mus = np.array([male_group[\"vol_sup_mus\"]])\n",
    "print(f'superior rectus muscle - mean: {np.mean(vol_sup_mus)}, std: {np.std(vol_sup_mus)}')\n",
    "\n",
    "# total\n",
    "vol_total = np.array([male_group[\"vol_total\"]])\n",
    "print(f'total - mean: {np.mean(vol_total)}, std: {np.std(vol_total)}')\n",
    "\n",
    "# Subplots\n",
    "k = 1.5 # Figure size to preserve ratio 16:9\n",
    "fig, ax = plt.subplots(2, 5, figsize=(16*k, 9*k))\n",
    "fig.suptitle('Volume per label (mm³) in MALES')\n",
    "fig.patch.set_facecolor('white')\n",
    "fix_axis = False\n",
    "# x_axis = [-2, 2]\n",
    "# y_axis = [-2.5, 3.5]\n",
    "\n",
    "# lens\n",
    "ax[0][0].set_title(f'lens - mean: {np.round(np.mean(vol_lens))}, std: {np.round(np.std(vol_lens), 2)}')\n",
    "graph_lens = sns.boxplot(data=vol_lens, ax=ax[0][0])\n",
    "# graph_lens.axhline(np.round(np.mean(vol_lens)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][0].set_xlim(x_axis)\n",
    "    ax[0][0].set_ylim([0, 160])\n",
    "\n",
    "# globe\n",
    "ax[0][1].set_title(f'globe - mean: {np.round(np.mean(vol_globe))}, std: {np.round(np.std(vol_globe), 2)}')\n",
    "graph_globe = sns.boxplot(vol_globe, ax=ax[0][1])\n",
    "# graph_globe.axhline(np.round(np.mean(vol_globe)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][1].set_xlim(x_axis)\n",
    "    ax[0][1].set_ylim([2500, 9000])\n",
    "\n",
    "# nerve\n",
    "ax[0][2].set_title(f'nerve - mean: {np.round(np.mean(vol_nerve))}, std: {np.round(np.std(vol_nerve), 2)}')\n",
    "graph_nerve = sns.boxplot(vol_nerve, ax=ax[0][2])\n",
    "# graph_nerve.axhline(np.round(np.mean(vol_nerve)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][2].set_xlim(x_axis)\n",
    "    ax[0][2].set_ylim([300, 1100])\n",
    "\n",
    "# intraconal fat\n",
    "ax[0][3].set_title(f'int fat - mean: {np.round(np.mean(vol_int_fat))}, std: {np.round(np.std(vol_int_fat), 2)}')\n",
    "graph_int_fat = sns.boxplot(vol_int_fat, ax=ax[0][3])\n",
    "# graph_int_fat.axhline(np.round(np.mean(vol_int_fat)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][3].set_xlim(x_axis)\n",
    "    ax[0][3].set_ylim([2000, 7000])\n",
    "\n",
    "# extraconal fat\n",
    "ax[0][4].set_title(f'ext fat - mean: {np.round(np.mean(vol_ext_fat))}, std: {np.round(np.std(vol_ext_fat), 2)}')\n",
    "graph_ext_fat = sns.boxplot(vol_ext_fat, ax=ax[0][4])\n",
    "# graph_ext_fat.axhline(np.round(np.mean(vol_ext_fat)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][4].set_xlim(x_axis)\n",
    "    ax[0][4].set_ylim([1000, 7000])\n",
    "\n",
    "# lateral rectus muscle\n",
    "ax[1][0].set_title(f'lat mus - mean: {np.round(np.mean(vol_lat_mus))}, std: {np.round(np.std(vol_lat_mus), 2)}')\n",
    "graph_lat_mus = sns.boxplot(vol_lat_mus, ax=ax[1][0])\n",
    "# graph_lat_mus.axhline(np.round(np.mean(vol_ext_fat)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[1][0].set_xlim(x_axis)\n",
    "    ax[1][0].set_ylim([1000, 8000])    \n",
    "\n",
    "# medial rectus muscle\n",
    "ax[1][1].set_title(f'med mus - mean: {np.round(np.mean(vol_med_mus))}, std: {np.round(np.std(vol_med_mus), 2)}')\n",
    "graph_med_mus = sns.boxplot(vol_med_mus, ax=ax[1][1])\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_med_mus)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[1][1].set_xlim(x_axis)\n",
    "    ax[1][1].set_ylim([400, 1500])\n",
    "\n",
    "# inferior rectus muscle\n",
    "ax[1][2].set_title(f'inf mus - mean: {np.round(np.mean(vol_inf_mus))}, std: {np.round(np.std(vol_inf_mus), 2)}')\n",
    "graph_med_mus = sns.boxplot(vol_inf_mus, ax=ax[1][2])\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_inf_mus)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[1][2].set_xlim(x_axis)\n",
    "    ax[1][2].set_ylim([400, 1300])\n",
    "\n",
    "# superior rectus muscle\n",
    "ax[1][3].set_title(f'sup mus - mean: {np.round(np.mean(vol_sup_mus))}, std: {np.round(np.std(vol_sup_mus), 2)}')\n",
    "graph_med_mus = sns.boxplot(vol_sup_mus, ax=ax[1][3])\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_sup_mus)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[1][3].set_xlim(x_axis)\n",
    "    ax[1][3].set_ylim([300, 2000])    \n",
    "\n",
    "# total\n",
    "ax[1][4].set_title(f'total - mean: {np.round(np.mean(vol_total))}, std: {np.round(np.std(vol_total), 2)}')\n",
    "graph_total = sns.boxplot(vol_total, ax=ax[1][4])\n",
    "if fix_axis:\n",
    "    # ax[1][3].set_xlim(x_axis)\n",
    "    ax[1][4].set_ylim([300, 2000])  \n",
    "\n",
    "plt.show\n",
    "\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/volumes/volumes_reg_males.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Female group\n",
    "female_group = sex_group.get_group(\"F\").dropna() \n",
    "\n",
    "# lens\n",
    "vol_lens = np.array([female_group[\"vol_lens\"]])\n",
    "print(f'lens - mean: {np.mean(vol_lens)}, std: {np.std(vol_lens)}')\n",
    "\n",
    "# globe\n",
    "vol_globe = np.array([female_group[\"vol_globe\"]])\n",
    "print(f'globe - mean: {np.mean(vol_globe)}, std: {np.std(vol_globe)}')\n",
    "\n",
    "# nerve\n",
    "vol_nerve = np.array([female_group[\"vol_nerve\"]])\n",
    "print(f'nerve - mean: {np.mean(vol_nerve)}, std: {np.std(vol_nerve)}')\n",
    "\n",
    "# intraconal fat\n",
    "vol_int_fat = np.array([female_group[\"vol_int_fat\"]])\n",
    "print(f'intraconal fat - mean: {np.mean(vol_int_fat)}, std: {np.std(vol_int_fat)}')\n",
    "\n",
    "# extraconal fat\n",
    "vol_ext_fat = np.array([female_group[\"vol_ext_fat\"]])\n",
    "print(f'extraconal fat - mean: {np.mean(vol_ext_fat)}, std: {np.std(vol_ext_fat)}')\n",
    "\n",
    "# lateral rectus muscle\n",
    "vol_lat_mus = np.array([female_group[\"vol_lat_mus\"]])\n",
    "print(f'lateral rectus muscle - mean: {np.mean(vol_lat_mus)}, std: {np.std(vol_lat_mus)}')\n",
    "\n",
    "# medial rectus muscle\n",
    "vol_med_mus= np.array([female_group[\"vol_med_mus\"]])\n",
    "print(f'medial rectus muscle - mean: {np.mean(vol_med_mus)}, std: {np.std(vol_med_mus)}')\n",
    "\n",
    "# inferior rectus muscle\n",
    "vol_inf_mus = np.array([female_group[\"vol_inf_mus\"]])\n",
    "print(f'inferior rectus muscle - mean: {np.mean(vol_inf_mus)}, std: {np.std(vol_inf_mus)}')\n",
    "\n",
    "# superior rectus muscle\n",
    "vol_sup_mus = np.array([female_group[\"vol_sup_mus\"]])\n",
    "print(f'superior rectus muscle - mean: {np.mean(vol_sup_mus)}, std: {np.std(vol_sup_mus)}')\n",
    "\n",
    "# total\n",
    "vol_total = np.array([female_group[\"vol_total\"]])\n",
    "print(f'total - mean: {np.mean(vol_total)}, std: {np.std(vol_total)}')\n",
    "\n",
    "# Subplots\n",
    "k = 1.5 # Figure size to preserve ratio 16:9\n",
    "fig, ax = plt.subplots(2, 5, figsize=(16*k, 9*k))\n",
    "fig.suptitle('Volume per label (mm³) in FEMALES')\n",
    "fig.patch.set_facecolor('white')\n",
    "fix_axis = False\n",
    "# x_axis = [-2, 2]\n",
    "# y_axis = [-2.5, 3.5]\n",
    "\n",
    "# lens\n",
    "ax[0][0].set_title(f'lens - mean: {np.round(np.mean(vol_lens))}, std: {np.round(np.std(vol_lens), 2)}')\n",
    "graph_lens = sns.boxplot(vol_lens, ax=ax[0][0])\n",
    "# graph_lens.axhline(np.round(np.mean(vol_lens)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][0].set_xlim(x_axis)\n",
    "    ax[0][0].set_ylim([0, 160])\n",
    "\n",
    "# globe\n",
    "ax[0][1].set_title(f'globe - mean: {np.round(np.mean(vol_globe))}, std: {np.round(np.std(vol_globe), 2)}')\n",
    "graph_globe = sns.boxplot(vol_globe, ax=ax[0][1])\n",
    "# graph_globe.axhline(np.round(np.mean(vol_globe)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][1].set_xlim(x_axis)\n",
    "    ax[0][1].set_ylim([2500, 9000])\n",
    "\n",
    "# nerve\n",
    "ax[0][2].set_title(f'nerve - mean: {np.round(np.mean(vol_nerve))}, std: {np.round(np.std(vol_nerve), 2)}')\n",
    "graph_nerve = sns.boxplot(vol_nerve, ax=ax[0][2])\n",
    "# graph_nerve.axhline(np.round(np.mean(vol_nerve)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][2].set_xlim(x_axis)\n",
    "    ax[0][2].set_ylim([300, 1100])\n",
    "\n",
    "# intraconal fat\n",
    "ax[0][3].set_title(f'int fat - mean: {np.round(np.mean(vol_int_fat))}, std: {np.round(np.std(vol_int_fat), 2)}')\n",
    "graph_int_fat = sns.boxplot(vol_int_fat, ax=ax[0][3])\n",
    "# graph_int_fat.axhline(np.round(np.mean(vol_int_fat)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][3].set_xlim(x_axis)\n",
    "    ax[0][3].set_ylim([2000, 7000])\n",
    "\n",
    "# extraconal fat\n",
    "ax[0][4].set_title(f'ext fat - mean: {np.round(np.mean(vol_ext_fat))}, std: {np.round(np.std(vol_ext_fat), 2)}')\n",
    "graph_ext_fat = sns.boxplot(vol_ext_fat, ax=ax[0][4])\n",
    "# graph_ext_fat.axhline(np.round(np.mean(vol_ext_fat)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[0][4].set_xlim(x_axis)\n",
    "    ax[0][4].set_ylim([1000, 7000])\n",
    "\n",
    "# lateral rectus muscle\n",
    "ax[1][0].set_title(f'lat mus - mean: {np.round(np.mean(vol_lat_mus))}, std: {np.round(np.std(vol_lat_mus), 2)}')\n",
    "graph_lat_mus = sns.boxplot(vol_lat_mus, ax=ax[1][0])\n",
    "# graph_lat_mus.axhline(np.round(np.mean(vol_ext_fat)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[1][0].set_xlim(x_axis)\n",
    "    ax[1][0].set_ylim([1000, 8000])    \n",
    "\n",
    "# medial rectus muscle\n",
    "ax[1][1].set_title(f'med mus - mean: {np.round(np.mean(vol_med_mus))}, std: {np.round(np.std(vol_med_mus), 2)}')\n",
    "graph_med_mus = sns.boxplot(vol_med_mus, ax=ax[1][1])\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_med_mus)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[1][1].set_xlim(x_axis)\n",
    "    ax[1][1].set_ylim([400, 1500])\n",
    "\n",
    "# inferior rectus muscle\n",
    "ax[1][2].set_title(f'inf mus - mean: {np.round(np.mean(vol_inf_mus))}, std: {np.round(np.std(vol_inf_mus), 2)}')\n",
    "graph_med_mus = sns.boxplot(vol_inf_mus, ax=ax[1][2])\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_inf_mus)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[1][2].set_xlim(x_axis)\n",
    "    ax[1][2].set_ylim([400, 1300])\n",
    "\n",
    "# superior rectus muscle\n",
    "ax[1][3].set_title(f'sup mus - mean: {np.round(np.mean(vol_sup_mus))}, std: {np.round(np.std(vol_sup_mus), 2)}')\n",
    "graph_med_mus = sns.boxplot(vol_sup_mus, ax=ax[1][3])\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_sup_mus)), color='red')\n",
    "if fix_axis:\n",
    "    # ax[1][3].set_xlim(x_axis)\n",
    "    ax[1][3].set_ylim([300, 2000])\n",
    "\n",
    "# total\n",
    "ax[1][4].set_title(f'total - mean: {np.round(np.mean(vol_total))}, std: {np.round(np.std(vol_total), 2)}')\n",
    "graph_total = sns.boxplot(vol_total, ax=ax[1][4])\n",
    "if fix_axis:\n",
    "    # ax[1][3].set_xlim(x_axis)\n",
    "    ax[1][4].set_ylim([300, 2000])  \n",
    "\n",
    "plt.show\n",
    "\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/volumes/volumes_reg_females.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Males and females together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "METHOD = 'dl'\n",
    "\n",
    "# Male group\n",
    "male_group = sex_group.get_group(\"M\").dropna()\n",
    "\n",
    "# Female group\n",
    "female_group = sex_group.get_group(\"F\").dropna()\n",
    "\n",
    "# lens\n",
    "vol_lens_male = np.array([male_group[\"vol_lens\"]])\n",
    "vol_lens_female = np.array([female_group[\"vol_lens\"]])\n",
    "\n",
    "# globe\n",
    "vol_globe_male = np.array([male_group[\"vol_globe\"]])\n",
    "vol_globe_female = np.array([female_group[\"vol_globe\"]])\n",
    "\n",
    "# nerve\n",
    "vol_nerve_male = np.array([male_group[\"vol_nerve\"]])\n",
    "vol_nerve_female = np.array([female_group[\"vol_nerve\"]])\n",
    "\n",
    "# intraconal fat\n",
    "vol_int_fat_male = np.array([male_group[\"vol_int_fat\"]])\n",
    "vol_int_fat_female = np.array([female_group[\"vol_int_fat\"]])\n",
    "\n",
    "# extraconal fat\n",
    "vol_ext_fat_male = np.array([male_group[\"vol_ext_fat\"]])\n",
    "vol_ext_fat_female = np.array([female_group[\"vol_ext_fat\"]])\n",
    "\n",
    "# lateral rectus muscle\n",
    "vol_lat_mus_male = np.array([male_group[\"vol_lat_mus\"]])\n",
    "vol_lat_mus_female = np.array([female_group[\"vol_lat_mus\"]])\n",
    "\n",
    "# medial rectus muscle\n",
    "vol_med_mus_male = np.array([male_group[\"vol_med_mus\"]])\n",
    "vol_med_mus_female = np.array([female_group[\"vol_med_mus\"]])\n",
    "\n",
    "# inferior rectus muscle\n",
    "vol_inf_mus_male = np.array([male_group[\"vol_inf_mus\"]])\n",
    "vol_inf_mus_female = np.array([female_group[\"vol_inf_mus\"]])\n",
    "\n",
    "# superior rectus muscle\n",
    "vol_sup_mus_male = np.array([male_group[\"vol_sup_mus\"]])\n",
    "vol_sup_mus_female = np.array([female_group[\"vol_sup_mus\"]])\n",
    "\n",
    "# total\n",
    "vol_total_male = np.array([male_group[\"vol_total\"]])\n",
    "vol_total_female = np.array([female_group[\"vol_total\"]])\n",
    "\n",
    "# Subplots\n",
    "k = 1.5 # Figure size to preserve ratio 16:9\n",
    "fig, ax = plt.subplots(2, 10, figsize=(16*k, 9*k))\n",
    "# plt.subplots_adjust(wspace=0.8, hspace=0.2)\n",
    "if METHOD == 'atlas':\n",
    "    fig.suptitle('Volume per label (mm³) per sex - ATLAS')\n",
    "elif METHOD == 'dl':\n",
    "    fig.suptitle('Volume per label (mm³) per sex - nnUNet')\n",
    "fig.patch.set_facecolor('white')\n",
    "fix_axis = False\n",
    "# x_axis = [-2, 2]\n",
    "# y_axis = [-2.5, 3.5]\n",
    "\n",
    "# Legend\n",
    "# legend_elements = [Line2D([0], [0], color='c', lw=2, label='Males'),\n",
    "#     Line2D([0], [0], color='orange', lw=2, label='Females')]\n",
    "# fig.legend(handles=legend_elements, loc='upper right')\n",
    "fig.tight_layout(pad = 3)\n",
    "\n",
    "# lens male\n",
    "ax[0][0].set_title(f'M {np.round(np.mean(vol_lens_male))} +/- {np.round(np.std(vol_lens_male), 2)}')\n",
    "graph_lens = sns.boxplot(data=vol_lens_male, ax=ax[0][0], color='tab:red')\n",
    "# graph_lens.axhline(np.round(np.mean(vol_lens)), color='red')\n",
    "ax[0][0].set_xlabel('lens')\n",
    "ax[0][0].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis and METHOD == 'atlas':\n",
    "    # ax[0][0].set_xlim(x_axis)\n",
    "    ax[0][0].set_ylim([30, 130])\n",
    "\n",
    "# lens female\n",
    "ax[0][1].set_title(f'F {np.round(np.mean(vol_lens_female))} +/- {np.round(np.std(vol_lens_female), 2)}')\n",
    "graph_lens = sns.boxplot(data=vol_lens_female, ax=ax[0][1], color='tab:red')\n",
    "# graph_lens.axhline(np.round(np.mean(vol_lens)), color='red')\n",
    "ax[0][1].set_xlabel('lens')\n",
    "ax[0][1].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[0][0].set_xlim(x_axis)\n",
    "    ax[0][1].set_ylim([30, 130])\n",
    "\n",
    "# globe male\n",
    "ax[0][2].set_title(f'M {np.round(np.mean(vol_globe_male))} +/- {np.round(np.std(vol_globe_male), 2)}')\n",
    "graph_globe = sns.boxplot(data=vol_globe_male, ax=ax[0][2], color='lime')\n",
    "# graph_globe.axhline(np.round(np.mean(vol_globe)), color='red')\n",
    "ax[0][2].set_xlabel('globe')\n",
    "ax[0][2].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[0][1].set_xlim(x_axis)\n",
    "    ax[0][2].set_ylim([2500, 9000])\n",
    "\n",
    "# globe female\n",
    "ax[0][3].set_title(f'F {np.round(np.mean(vol_globe_female))} +/- {np.round(np.std(vol_globe_female), 2)}')\n",
    "graph_globe = sns.boxplot(data=vol_globe_female, ax=ax[0][3], color='lime')\n",
    "# graph_globe.axhline(np.round(np.mean(vol_globe)), color='red')\n",
    "ax[0][3].set_xlabel('globe')\n",
    "ax[0][3].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[0][1].set_xlim(x_axis)\n",
    "    ax[0][3].set_ylim([2500, 9000])\n",
    "\n",
    "# nerve male \n",
    "ax[0][4].set_title(f'M {np.round(np.mean(vol_nerve_male))} +/- {np.round(np.std(vol_nerve_male), 2)}')\n",
    "graph_nerve = sns.boxplot(data=vol_nerve_male, ax=ax[0][4], color='tab:blue')\n",
    "# graph_nerve.axhline(np.round(np.mean(vol_nerve)), color='red')\n",
    "ax[0][4].set_xlabel('nerve')\n",
    "ax[0][4].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[0][2].set_xlim(x_axis)\n",
    "    ax[0][4].set_ylim([300, 1100])\n",
    "\n",
    "# nerve female \n",
    "ax[0][5].set_title(f'F {np.round(np.mean(vol_nerve_female))} +/- {np.round(np.std(vol_nerve_female), 2)}')\n",
    "graph_nerve = sns.boxplot(data=vol_nerve_female, ax=ax[0][5], color='tab:blue')\n",
    "# graph_nerve.axhline(np.round(np.mean(vol_nerve)), color='red')\n",
    "ax[0][5].set_xlabel('nerve')\n",
    "ax[0][5].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[0][2].set_xlim(x_axis)\n",
    "    ax[0][5].set_ylim([300, 1100])\n",
    "\n",
    "# intraconal fat male\n",
    "ax[0][6].set_title(f'M {np.round(np.mean(vol_int_fat_male))} +/- {np.round(np.std(vol_int_fat_male), 2)}')\n",
    "graph_int_fat = sns.boxplot(data=vol_int_fat_male, ax=ax[0][6], color='yellow')\n",
    "# graph_int_fat.axhline(np.round(np.mean(vol_int_fat)), color='red')\n",
    "ax[0][6].set_xlabel('int fat')\n",
    "ax[0][6].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[0][3].set_xlim(x_axis)\n",
    "    ax[0][6].set_ylim([2000, 7000])\n",
    "\n",
    "# intraconal fat female\n",
    "ax[0][7].set_title(f'F {np.round(np.mean(vol_int_fat_female))} +/- {np.round(np.std(vol_int_fat_female), 2)}')\n",
    "graph_int_fat = sns.boxplot(data=vol_int_fat_female, ax=ax[0][7], color='yellow')\n",
    "# graph_int_fat.axhline(np.round(np.mean(vol_int_fat)), color='red')\n",
    "ax[0][7].set_xlabel('int fat')\n",
    "ax[0][7].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[0][3].set_xlim(x_axis)\n",
    "    ax[0][7].set_ylim([2000, 7000])\n",
    "\n",
    "# extraconal fat male\n",
    "ax[0][8].set_title(f'M {np.round(np.mean(vol_ext_fat_male))} +/- {np.round(np.std(vol_ext_fat_male), 2)}')\n",
    "graph_ext_fat = sns.boxplot(data=vol_ext_fat_male, ax=ax[0][8], color='cyan')\n",
    "# graph_ext_fat.axhline(np.round(np.mean(vol_ext_fat)), color='red')\n",
    "ax[0][8].set_xlabel('ext fat')\n",
    "ax[0][8].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[0][4].set_xlim(x_axis)\n",
    "    ax[0][8].set_ylim([1000, 8000])\n",
    "\n",
    "# extraconal fat female\n",
    "ax[0][9].set_title(f'F {np.round(np.mean(vol_ext_fat_female))} +/- {np.round(np.std(vol_ext_fat_female), 2)}')\n",
    "graph_ext_fat = sns.boxplot(data=vol_ext_fat_female, ax=ax[0][9], color='cyan')\n",
    "# graph_ext_fat.axhline(np.round(np.mean(vol_ext_fat)), color='red')\n",
    "ax[0][9].set_xlabel('ext fat')\n",
    "ax[0][9].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[0][4].set_xlim(x_axis)\n",
    "    ax[0][9].set_ylim([1000, 8000])\n",
    "\n",
    "# lateral rectus muscle male\n",
    "ax[1][0].set_title(f'M {np.round(np.mean(vol_lat_mus_male))} +/- {np.round(np.std(vol_lat_mus_male), 2)}')\n",
    "graph_lat_mus = sns.boxplot(data=vol_lat_mus_male, ax=ax[1][0], color='magenta')\n",
    "# graph_lat_mus.axhline(np.round(np.mean(vol_ext_fat)), color='red')\n",
    "ax[1][0].set_xlabel('lat mus')\n",
    "ax[1][0].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[1][0].set_xlim(x_axis)\n",
    "    ax[1][0].set_ylim([300, 1100])\n",
    "\n",
    "# lateral rectus muscle female\n",
    "ax[1][1].set_title(f'F {np.round(np.mean(vol_lat_mus_female))} +/- {np.round(np.std(vol_lat_mus_female), 2)}')\n",
    "graph_lat_mus = sns.boxplot(data=vol_lat_mus_female, ax=ax[1][1], color='magenta')\n",
    "# graph_lat_mus.axhline(np.round(np.mean(vol_ext_fat)), color='red')\n",
    "ax[1][1].set_xlabel('lat mus') \n",
    "ax[1][1].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[1][0].set_xlim(x_axis)\n",
    "    ax[1][1].set_ylim([300, 1100]) \n",
    "\n",
    "# medial rectus muscle male\n",
    "ax[1][2].set_title(f'M {np.round(np.mean(vol_med_mus_male))} +/- {np.round(np.std(vol_med_mus_male), 2)}')\n",
    "graph_med_mus = sns.boxplot(data=vol_med_mus_male, ax=ax[1][2], color='ivory')\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_med_mus)), color='red')\n",
    "ax[1][2].set_xlabel('med mus')\n",
    "ax[1][2].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[1][1].set_xlim(x_axis)\n",
    "    ax[1][2].set_ylim([400, 1700])\n",
    "\n",
    "# medial rectus muscle female\n",
    "ax[1][3].set_title(f'F {np.round(np.mean(vol_med_mus_female))} +/- {np.round(np.std(vol_med_mus_female), 2)}')\n",
    "graph_med_mus = sns.boxplot(data=vol_med_mus_female, ax=ax[1][3], color='ivory')\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_med_mus)), color='red')\n",
    "ax[1][3].set_xlabel('med mus')\n",
    "ax[1][3].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[1][1].set_xlim(x_axis)\n",
    "    ax[1][3].set_ylim([400, 1700])\n",
    "\n",
    "# inferior rectus muscle male\n",
    "ax[1][4].set_title(f'M {np.round(np.mean(vol_inf_mus_male))} +/- {np.round(np.std(vol_inf_mus_male), 2)}')\n",
    "graph_med_mus = sns.boxplot(data=vol_inf_mus_male, ax=ax[1][4], color='tab:purple')\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_inf_mus)), color='red')\n",
    "ax[1][4].set_xlabel('inf mus')\n",
    "ax[1][4].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[1][2].set_xlim(x_axis)\n",
    "    ax[1][4].set_ylim([400, 1300])\n",
    "\n",
    "# inferior rectus muscle female\n",
    "ax[1][5].set_title(f'F {np.round(np.mean(vol_inf_mus_female))} +/- {np.round(np.std(vol_inf_mus_female), 2)}')\n",
    "graph_med_mus = sns.boxplot(data=vol_inf_mus_female, ax=ax[1][5], color='tab:purple')\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_inf_mus)), color='red')\n",
    "ax[1][5].set_xlabel('inf mus')\n",
    "ax[1][5].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[1][2].set_xlim(x_axis)\n",
    "    ax[1][5].set_ylim([400, 1300])\n",
    "\n",
    "# superior rectus muscle male\n",
    "ax[1][6].set_title(f'M {np.round(np.mean(vol_sup_mus_male))} +/- {np.round(np.std(vol_sup_mus_male), 2)}')\n",
    "graph_med_mus = sns.boxplot(data=vol_sup_mus_male, ax=ax[1][6], color='chocolate')\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_sup_mus)), color='red')\n",
    "ax[1][6].set_xlabel('sup mus')\n",
    "ax[1][6].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[1][3].set_xlim(x_axis)\n",
    "    ax[1][6].set_ylim([500, 2600])\n",
    "\n",
    "# superior rectus muscle female\n",
    "ax[1][7].set_title(f'F {np.round(np.mean(vol_sup_mus_female))} +/- {np.round(np.std(vol_sup_mus_female), 2)}')\n",
    "graph_med_mus = sns.boxplot(data=vol_sup_mus_female, ax=ax[1][7], color='chocolate')\n",
    "# graph_med_mus.axhline(np.round(np.mean(vol_sup_mus)), color='red')\n",
    "ax[1][7].set_xlabel('sup mus')\n",
    "ax[1][7].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[1][3].set_xlim(x_axis)\n",
    "    ax[1][7].set_ylim([500, 2600])\n",
    "\n",
    "# total male\n",
    "ax[1][8].set_title(f'M {np.round(np.mean(vol_total_male))} +/- {np.round(np.std(vol_total_male), 2)}')\n",
    "graph_total = sns.boxplot(data=vol_total_male, ax=ax[1][8], color='lightseagreen')\n",
    "ax[1][8].set_xlabel('Total')\n",
    "ax[1][8].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[1][3].set_xlim(x_axis)\n",
    "    ax[1][8].set_ylim([10000, 28000])  \n",
    "\n",
    "# total female\n",
    "ax[1][9].set_title(f'F {np.round(np.mean(vol_total_female))} +/-{np.round(np.std(vol_total_female), 2)}')\n",
    "graph_total = sns.boxplot(data=vol_total_female, ax=ax[1][9], color='lightseagreen')\n",
    "ax[1][9].set_xlabel('Total')\n",
    "ax[1][9].tick_params(labelbottom=False, bottom=False)\n",
    "if fix_axis:\n",
    "    # ax[1][3].set_xlim(x_axis)\n",
    "    ax[1][9].set_ylim([10000, 28000])\n",
    "\n",
    "plt.show\n",
    "\n",
    "# if METHOD=='atlas':\n",
    "    # plt.savefig('/mnt/sda1/Repos/a-eye/Output/volumetry/atlas/volumes_reg_males_females.png')\n",
    "# elif METHOD=='dl':\n",
    "    # plt.savefig('/mnt/sda1/Repos/a-eye/Output/volumetry/nnunet/volumes_nnunet_males_females-AXIS.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATLAS vs nnUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "\n",
    "# Paths\n",
    "csv_metadata = '/mnt/sda1/Repos/a-eye/Output/metadata/sub_metadata.csv'\n",
    "csv_volumes_reg = '/mnt/sda1/Repos/a-eye/Output/volumetry/atlas/volumes_reg_total.csv'\n",
    "csv_volumes_nnunet = '/mnt/sda1/Repos/a-eye/Output/volumetry/nnunet/volumes_nnunet_right_eye.csv'\n",
    "\n",
    "# Pandas read csv\n",
    "pd_metadata = pd.read_csv(csv_metadata)\n",
    "pd_volumes_reg = pd.read_csv(csv_volumes_reg)\n",
    "pd_volumes_nnunet = pd.read_csv(csv_volumes_nnunet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove excluded subjects qc1, qc2, qc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc1 = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc1.csv\")\n",
    "qc2 = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc2_atlas_nnunet.csv\")\n",
    "qc3_vol = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc3_vol.csv\")\n",
    "qc3_al = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc3_al.csv\")\n",
    "\n",
    "# concat qc1, qc2 and qc3\n",
    "qc_list = pd.concat([qc1, qc2, qc3_vol, qc3_al], ignore_index=True)\n",
    "\n",
    "# subdataframe of pd_volumes_reg and pd_volumes_nnunet removing the subjects that are in qc1 and qc2\n",
    "pd_metadata = pd_metadata[~pd_metadata['Subject'].isin(qc_list['subject'])]\n",
    "pd_volumes_reg = pd_volumes_reg[~pd_volumes_reg['Subject'].isin(qc_list['subject'])]\n",
    "pd_volumes_nnunet = pd_volumes_nnunet[~pd_volumes_nnunet['Subject'].isin(qc_list['subject'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "# pd_volumes_reg.to_csv('/mnt/sda1/Repos/a-eye/Output/volumetry/atlas/volumes_reg_total_qc1_qc2_qc3.csv', index=False)\n",
    "# pd_volumes_nnunet.to_csv('/mnt/sda1/Repos/a-eye/Output/volumetry/nnunet/volumes_nnunet_right_eye_qc1_qc2_qc3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horizontal dataframe (for data extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe horizontal\n",
    "df_vols_horizontal = pd.concat([pd_metadata, pd_volumes_reg.iloc[:, 1:], pd_volumes_nnunet.iloc[:, 1:]], axis=1, ignore_index=False, verify_integrity=False)\n",
    "# change columns names\n",
    "df_vols_horizontal.columns.values[6:16] = df_vols_horizontal.columns.values[6:16] + '_atlas'\n",
    "df_vols_horizontal.columns.values[16:26] = df_vols_horizontal.columns.values[16:26] + '_nnunet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vertical dataframe (for plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlas and nnunet dataframes\n",
    "df_vols1 = pd.concat([pd_metadata, pd_volumes_reg.iloc[:, 1:]], axis=1, ignore_index=False, verify_integrity=False)\n",
    "df_vols2 = pd.concat([pd_metadata, pd_volumes_nnunet.iloc[:, 1:]], axis=1, ignore_index=False, verify_integrity=False)\n",
    "# add 'method' column in each dataframe as the last column with 'atlas' or 'nnunet' as value\n",
    "df_vols1.insert(16, 'method', 'atlas')\n",
    "df_vols2.insert(16, 'method', 'nnunet')\n",
    "# concatenate both dataframes vertically\n",
    "df_vols_vertical = pd.concat([df_vols1, df_vols2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data extraction (arrays - mean and std by sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by sex (males and females)\n",
    "sex_group = df_vols_horizontal.groupby([\"Sex\"], dropna=True)\n",
    "# Male group\n",
    "male_group = sex_group.get_group(\"M\").dropna()\n",
    "# Female group\n",
    "female_group = sex_group.get_group(\"F\").dropna()\n",
    "\n",
    "REMOVE_ZEROS = 0\n",
    "REMOVE_OUTLIERS = 0\n",
    "if REMOVE_ZEROS:\n",
    "    print('Removing zeros \\n')\n",
    "elif REMOVE_OUTLIERS:\n",
    "    print('Removing outliers \\n')\n",
    "else:\n",
    "    print('No removal \\n')\n",
    "\n",
    "# lens\n",
    "print('Lens')\n",
    "df_vol_lens_atlas = df_vols_horizontal\n",
    "vol_lens_atlas = df_vols_horizontal[\"vol_lens_atlas\"]\n",
    "vol_lens_male_atlas = np.array([male_group[\"vol_lens_atlas\"]])\n",
    "vol_lens_female_atlas = np.array([female_group[\"vol_lens_atlas\"]])\n",
    "df_vol_lens_nnunet = df_vols_horizontal\n",
    "vol_lens_nnunet = df_vols_horizontal[\"vol_lens_nnunet\"]\n",
    "vol_lens_male_nnunet = np.array([male_group[\"vol_lens_nnunet\"]])\n",
    "vol_lens_female_nnunet = np.array([female_group[\"vol_lens_nnunet\"]])\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_lens_atlas = df_vols_horizontal[vol_lens_atlas != 0]\n",
    "    sex_group = df_vol_lens_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_lens_male_atlas = np.array([male_group[\"vol_lens_atlas\"]])\n",
    "    vol_lens_female_atlas = np.array([female_group[\"vol_lens_atlas\"]])\n",
    "\n",
    "    df_vol_lens_nnunet = df_vols_horizontal[vol_lens_nnunet != 0]\n",
    "    sex_group = df_vol_lens_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_lens_male_nnunet = np.array([male_group[\"vol_lens_nnunet\"]])\n",
    "    vol_lens_female_nnunet = np.array([female_group[\"vol_lens_nnunet\"]])\n",
    "if REMOVE_OUTLIERS:\n",
    "    lower_bound = np.percentile(vol_lens_atlas, 5)\n",
    "    upper_bound = np.percentile(vol_lens_atlas, 95)\n",
    "    df_vol_lens_atlas = df_vol_lens_atlas[(df_vol_lens_atlas[\"vol_lens_atlas\"] > lower_bound) & (df_vol_lens_atlas[\"vol_lens_atlas\"] < upper_bound)]\n",
    "    sex_group = df_vol_lens_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_lens_male_atlas = np.array([male_group[\"vol_lens_atlas\"]])\n",
    "    vol_lens_female_atlas = np.array([female_group[\"vol_lens_atlas\"]])\n",
    "\n",
    "    lower_bound = np.percentile(vol_lens_nnunet, 5)\n",
    "    upper_bound = np.percentile(vol_lens_nnunet, 95)\n",
    "    df_vol_lens_nnunet = df_vol_lens_nnunet[(df_vol_lens_nnunet[\"vol_lens_nnunet\"] > lower_bound) & (df_vol_lens_nnunet[\"vol_lens_nnunet\"] < upper_bound)]\n",
    "    sex_group = df_vol_lens_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_lens_male_nnunet = np.array([male_group[\"vol_lens_nnunet\"]])\n",
    "    vol_lens_female_nnunet = np.array([female_group[\"vol_lens_nnunet\"]])\n",
    "\n",
    "print(f'Lens | Atlas  | Male --- median: {np.round(np.median(vol_lens_male_atlas))}, std: {np.round(np.std(vol_lens_male_atlas))} mm3')\n",
    "print(f'Lens | Atlas  | Female - median: {np.round(np.median(vol_lens_female_atlas))}, std: {np.round(np.std(vol_lens_female_atlas))} mm3')\n",
    "print(f'Lens | nnUNet | Male --- median: {np.round(np.median(vol_lens_male_nnunet))}, std: {np.round(np.std(vol_lens_male_nnunet))} mm3')\n",
    "print(f'Lens | nnUNet | Female - median: {np.round(np.median(vol_lens_female_nnunet))}, std: {np.round(np.std(vol_lens_female_nnunet))} mm3 \\n')\n",
    "\n",
    "# globe\n",
    "print('Globe')\n",
    "df_vol_globe_atlas = df_vols_horizontal\n",
    "vol_globe_atlas = df_vols_horizontal[\"vol_globe_atlas\"]\n",
    "vol_globe_male_atlas = np.array([male_group[\"vol_globe_atlas\"]])\n",
    "vol_globe_female_atlas = np.array([female_group[\"vol_globe_atlas\"]])\n",
    "df_vol_globe_nnunet = df_vols_horizontal\n",
    "vol_globe_nnunet = df_vols_horizontal[\"vol_globe_nnunet\"]\n",
    "vol_globe_male_nnunet = np.array([male_group[\"vol_globe_nnunet\"]])\n",
    "vol_globe_female_nnunet = np.array([female_group[\"vol_globe_nnunet\"]])\n",
    "\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_globe_atlas = df_vols_horizontal[vol_globe_atlas != 0]\n",
    "    sex_group = df_vol_globe_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_globe_male_atlas = np.array([male_group[\"vol_globe_atlas\"]])\n",
    "    vol_globe_female_atlas = np.array([female_group[\"vol_globe_atlas\"]])\n",
    "    \n",
    "    df_vol_globe_nnunet = df_vols_horizontal[vol_globe_nnunet != 0]\n",
    "    sex_group = df_vol_globe_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_globe_male_nnunet = np.array([male_group[\"vol_globe_nnunet\"]])\n",
    "    vol_globe_female_nnunet = np.array([female_group[\"vol_globe_nnunet\"]])    \n",
    "\n",
    "if REMOVE_OUTLIERS:\n",
    "    lower_bound = np.percentile(vol_globe_atlas, 5)\n",
    "    upper_bound = np.percentile(vol_globe_atlas, 95)\n",
    "    df_vol_globe_atlas = df_vol_globe_atlas[(df_vol_globe_atlas[\"vol_globe_atlas\"] > lower_bound) & (df_vol_globe_atlas[\"vol_globe_atlas\"] < upper_bound)]\n",
    "    sex_group = df_vol_globe_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_globe_male_atlas = np.array([male_group[\"vol_globe_atlas\"]])\n",
    "    vol_globe_female_atlas = np.array([female_group[\"vol_globe_atlas\"]])\n",
    "    \n",
    "    lower_bound = np.percentile(vol_globe_nnunet, 5)\n",
    "    upper_bound = np.percentile(vol_globe_nnunet, 95)\n",
    "    df_vol_globe_nnunet = df_vol_globe_nnunet[(df_vol_globe_nnunet[\"vol_globe_nnunet\"] > lower_bound) & (df_vol_globe_nnunet[\"vol_globe_nnunet\"] < upper_bound)]\n",
    "    sex_group = df_vol_globe_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_globe_male_nnunet = np.array([male_group[\"vol_globe_nnunet\"]])\n",
    "    vol_globe_female_nnunet = np.array([female_group[\"vol_globe_nnunet\"]])\n",
    "\n",
    "print(f'Globe | Atlas  | Male --- median: {np.round(np.median(vol_globe_male_atlas))}, std: {np.round(np.std(vol_globe_male_atlas))} mm3')\n",
    "print(f'Globe | Atlas  | Female - median: {np.round(np.median(vol_globe_female_atlas))}, std: {np.round(np.std(vol_globe_female_atlas))} mm3')\n",
    "print(f'Globe | nnUNet | Male --- median: {np.round(np.median(vol_globe_male_nnunet))}, std: {np.round(np.std(vol_globe_male_nnunet))} mm3')\n",
    "print(f'Globe | nnUNet | Female - median: {np.round(np.median(vol_globe_female_nnunet))}, std: {np.round(np.std(vol_globe_female_nnunet))} mm3 \\n')\n",
    "\n",
    "# nerve\n",
    "print('Nerve')\n",
    "df_vol_nerve_atlas = df_vols_horizontal\n",
    "vol_nerve_atlas = df_vols_horizontal[\"vol_nerve_atlas\"]\n",
    "vol_nerve_male_atlas = np.array([male_group[\"vol_nerve_atlas\"]])\n",
    "vol_nerve_female_atlas = np.array([female_group[\"vol_nerve_atlas\"]])\n",
    "df_vol_nerve_nnunet = df_vols_horizontal\n",
    "vol_nerve_nnunet = df_vols_horizontal[\"vol_nerve_nnunet\"]\n",
    "vol_nerve_male_nnunet = np.array([male_group[\"vol_nerve_nnunet\"]])\n",
    "vol_nerve_female_nnunet = np.array([female_group[\"vol_nerve_nnunet\"]])\n",
    "\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_nerve_atlas = df_vols_horizontal[vol_nerve_atlas != 0]\n",
    "    sex_group = df_vol_nerve_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_nerve_male_atlas = np.array([male_group[\"vol_nerve_atlas\"]])\n",
    "    vol_nerve_female_atlas = np.array([female_group[\"vol_nerve_atlas\"]])\n",
    "    \n",
    "    df_vol_nerve_nnunet = df_vols_horizontal[vol_nerve_nnunet != 0]\n",
    "    sex_group = df_vol_nerve_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_nerve_male_nnunet = np.array([male_group[\"vol_nerve_nnunet\"]])\n",
    "    vol_nerve_female_nnunet = np.array([female_group[\"vol_nerve_nnunet\"]])    \n",
    "\n",
    "if REMOVE_OUTLIERS:\n",
    "    lower_bound = np.percentile(vol_nerve_atlas, 5)\n",
    "    upper_bound = np.percentile(vol_nerve_atlas, 95)\n",
    "    df_vol_nerve_atlas = df_vol_nerve_atlas[(df_vol_nerve_atlas[\"vol_nerve_atlas\"] > lower_bound) & (df_vol_nerve_atlas[\"vol_nerve_atlas\"] < upper_bound)]\n",
    "    sex_group = df_vol_nerve_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_nerve_male_atlas = np.array([male_group[\"vol_nerve_atlas\"]])\n",
    "    vol_nerve_female_atlas = np.array([female_group[\"vol_nerve_atlas\"]])\n",
    "    \n",
    "    lower_bound = np.percentile(vol_nerve_nnunet, 5)\n",
    "    upper_bound = np.percentile(vol_nerve_nnunet, 95)\n",
    "    df_vol_nerve_nnunet = df_vol_nerve_nnunet[(df_vol_nerve_nnunet[\"vol_nerve_nnunet\"] > lower_bound) & (df_vol_nerve_nnunet[\"vol_nerve_nnunet\"] < upper_bound)]\n",
    "    sex_group = df_vol_nerve_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_nerve_male_nnunet = np.array([male_group[\"vol_nerve_nnunet\"]])\n",
    "    vol_nerve_female_nnunet = np.array([female_group[\"vol_nerve_nnunet\"]])\n",
    "\n",
    "print(f'Nerve | Atlas  | Male --- median: {np.round(np.median(vol_nerve_male_atlas))}, std: {np.round(np.std(vol_nerve_male_atlas))} mm3')\n",
    "print(f'Nerve | Atlas  | Female - median: {np.round(np.median(vol_nerve_female_atlas))}, std: {np.round(np.std(vol_nerve_female_atlas))} mm3')\n",
    "print(f'Nerve | nnUNet | Male --- median: {np.round(np.median(vol_nerve_male_nnunet))}, std: {np.round(np.std(vol_nerve_male_nnunet))} mm3')\n",
    "print(f'Nerve | nnUNet | Female - median: {np.round(np.median(vol_nerve_female_nnunet))}, std: {np.round(np.std(vol_nerve_female_nnunet))} mm3 \\n')\n",
    "\n",
    "# int_fat\n",
    "print('Int_Fat')\n",
    "df_vol_int_fat_atlas = df_vols_horizontal\n",
    "vol_int_fat_atlas = df_vols_horizontal[\"vol_int_fat_atlas\"]\n",
    "vol_int_fat_male_atlas = np.array([male_group[\"vol_int_fat_atlas\"]])\n",
    "vol_int_fat_female_atlas = np.array([female_group[\"vol_int_fat_atlas\"]])\n",
    "df_vol_int_fat_nnunet = df_vols_horizontal\n",
    "vol_int_fat_nnunet = df_vols_horizontal[\"vol_int_fat_nnunet\"]\n",
    "vol_int_fat_male_nnunet = np.array([male_group[\"vol_int_fat_nnunet\"]])\n",
    "vol_int_fat_female_nnunet = np.array([female_group[\"vol_int_fat_nnunet\"]])\n",
    "\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_int_fat_atlas = df_vols_horizontal[vol_int_fat_atlas != 0]\n",
    "    sex_group = df_vol_int_fat_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_int_fat_male_atlas = np.array([male_group[\"vol_int_fat_atlas\"]])\n",
    "    vol_int_fat_female_atlas = np.array([female_group[\"vol_int_fat_atlas\"]])\n",
    "    \n",
    "    df_vol_int_fat_nnunet = df_vols_horizontal[vol_int_fat_nnunet != 0]\n",
    "    sex_group = df_vol_int_fat_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_int_fat_male_nnunet = np.array([male_group[\"vol_int_fat_nnunet\"]])\n",
    "    vol_int_fat_female_nnunet = np.array([female_group[\"vol_int_fat_nnunet\"]])    \n",
    "\n",
    "if REMOVE_OUTLIERS:\n",
    "    lower_bound = np.percentile(vol_int_fat_atlas, 5)\n",
    "    upper_bound = np.percentile(vol_int_fat_atlas, 95)\n",
    "    df_vol_int_fat_atlas = df_vol_int_fat_atlas[(df_vol_int_fat_atlas[\"vol_int_fat_atlas\"] > lower_bound) & (df_vol_int_fat_atlas[\"vol_int_fat_atlas\"] < upper_bound)]\n",
    "    sex_group = df_vol_int_fat_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_int_fat_male_atlas = np.array([male_group[\"vol_int_fat_atlas\"]])\n",
    "    vol_int_fat_female_atlas = np.array([female_group[\"vol_int_fat_atlas\"]])\n",
    "    \n",
    "    lower_bound = np.percentile(vol_int_fat_nnunet, 5)\n",
    "    upper_bound = np.percentile(vol_int_fat_nnunet, 95)\n",
    "    df_vol_int_fat_nnunet = df_vol_int_fat_nnunet[(df_vol_int_fat_nnunet[\"vol_int_fat_nnunet\"] > lower_bound) & (df_vol_int_fat_nnunet[\"vol_int_fat_nnunet\"] < upper_bound)]\n",
    "    sex_group = df_vol_int_fat_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_int_fat_male_nnunet = np.array([male_group[\"vol_int_fat_nnunet\"]])\n",
    "    vol_int_fat_female_nnunet = np.array([female_group[\"vol_int_fat_nnunet\"]])\n",
    "\n",
    "print(f'Int_Fat | Atlas  | Male --- median: {np.round(np.median(vol_int_fat_male_atlas))}, std: {np.round(np.std(vol_int_fat_male_atlas))} mm3')\n",
    "print(f'Int_Fat | Atlas  | Female - median: {np.round(np.median(vol_int_fat_female_atlas))}, std: {np.round(np.std(vol_int_fat_female_atlas))} mm3')\n",
    "print(f'Int_Fat | nnUNet | Male --- median: {np.round(np.median(vol_int_fat_male_nnunet))}, std: {np.round(np.std(vol_int_fat_male_nnunet))} mm3')\n",
    "print(f'Int_Fat | nnUNet | Female - median: {np.round(np.median(vol_int_fat_female_nnunet))}, std: {np.round(np.std(vol_int_fat_female_nnunet))} mm3 \\n')\n",
    "\n",
    "# ext_fat\n",
    "print('Ext_Fat')\n",
    "df_vol_ext_fat_atlas = df_vols_horizontal\n",
    "vol_ext_fat_atlas = df_vols_horizontal[\"vol_ext_fat_atlas\"]\n",
    "vol_ext_fat_male_atlas = np.array([male_group[\"vol_ext_fat_atlas\"]])\n",
    "vol_ext_fat_female_atlas = np.array([female_group[\"vol_ext_fat_atlas\"]])\n",
    "df_vol_ext_fat_nnunet = df_vols_horizontal\n",
    "vol_ext_fat_nnunet = df_vols_horizontal[\"vol_ext_fat_nnunet\"]\n",
    "vol_ext_fat_male_nnunet = np.array([male_group[\"vol_ext_fat_nnunet\"]])\n",
    "vol_ext_fat_female_nnunet = np.array([female_group[\"vol_ext_fat_nnunet\"]])\n",
    "\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_ext_fat_atlas = df_vols_horizontal[vol_ext_fat_atlas != 0]\n",
    "    sex_group = df_vol_ext_fat_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_ext_fat_male_atlas = np.array([male_group[\"vol_ext_fat_atlas\"]])\n",
    "    vol_ext_fat_female_atlas = np.array([female_group[\"vol_ext_fat_atlas\"]])\n",
    "    \n",
    "    df_vol_ext_fat_nnunet = df_vols_horizontal[vol_ext_fat_nnunet != 0]\n",
    "    sex_group = df_vol_ext_fat_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_ext_fat_male_nnunet = np.array([male_group[\"vol_ext_fat_nnunet\"]])\n",
    "    vol_ext_fat_female_nnunet = np.array([female_group[\"vol_ext_fat_nnunet\"]])    \n",
    "\n",
    "if REMOVE_OUTLIERS:\n",
    "    lower_bound = np.percentile(vol_ext_fat_atlas, 5)\n",
    "    upper_bound = np.percentile(vol_ext_fat_atlas, 95)\n",
    "    df_vol_ext_fat_atlas = df_vol_ext_fat_atlas[(df_vol_ext_fat_atlas[\"vol_ext_fat_atlas\"] > lower_bound) & (df_vol_ext_fat_atlas[\"vol_ext_fat_atlas\"] < upper_bound)]\n",
    "    sex_group = df_vol_ext_fat_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_ext_fat_male_atlas = np.array([male_group[\"vol_ext_fat_atlas\"]])\n",
    "    vol_ext_fat_female_atlas = np.array([female_group[\"vol_ext_fat_atlas\"]])\n",
    "    \n",
    "    lower_bound = np.percentile(vol_ext_fat_nnunet, 5)\n",
    "    upper_bound = np.percentile(vol_ext_fat_nnunet, 95)\n",
    "    df_vol_ext_fat_nnunet = df_vol_ext_fat_nnunet[(df_vol_ext_fat_nnunet[\"vol_ext_fat_nnunet\"] > lower_bound) & (df_vol_ext_fat_nnunet[\"vol_ext_fat_nnunet\"] < upper_bound)]\n",
    "    sex_group = df_vol_ext_fat_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_ext_fat_male_nnunet = np.array([male_group[\"vol_ext_fat_nnunet\"]])\n",
    "    vol_ext_fat_female_nnunet = np.array([female_group[\"vol_ext_fat_nnunet\"]])\n",
    "\n",
    "print(f'Ext_Fat | Atlas  | Male --- median: {np.round(np.median(vol_ext_fat_male_atlas))}, std: {np.round(np.std(vol_ext_fat_male_atlas))} mm3')\n",
    "print(f'Ext_Fat | Atlas  | Female - median: {np.round(np.median(vol_ext_fat_female_atlas))}, std: {np.round(np.std(vol_ext_fat_female_atlas))} mm3')\n",
    "print(f'Ext_Fat | nnUNet | Male --- median: {np.round(np.median(vol_ext_fat_male_nnunet))}, std: {np.round(np.std(vol_ext_fat_male_nnunet))} mm3')\n",
    "print(f'Ext_Fat | nnUNet | Female - median: {np.round(np.median(vol_ext_fat_female_nnunet))}, std: {np.round(np.std(vol_ext_fat_female_nnunet))} mm3 \\n')\n",
    "\n",
    "# lat_mus\n",
    "print('Lat_Mus')\n",
    "df_vol_lat_mus_atlas = df_vols_horizontal\n",
    "vol_lat_mus_atlas = df_vols_horizontal[\"vol_lat_mus_atlas\"]\n",
    "vol_lat_mus_male_atlas = np.array([male_group[\"vol_lat_mus_atlas\"]])\n",
    "vol_lat_mus_female_atlas = np.array([female_group[\"vol_lat_mus_atlas\"]])\n",
    "df_vol_lat_mus_nnunet = df_vols_horizontal\n",
    "vol_lat_mus_nnunet = df_vols_horizontal[\"vol_lat_mus_nnunet\"]\n",
    "vol_lat_mus_male_nnunet = np.array([male_group[\"vol_lat_mus_nnunet\"]])\n",
    "vol_lat_mus_female_nnunet = np.array([female_group[\"vol_lat_mus_nnunet\"]])\n",
    "\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_lat_mus_atlas = df_vols_horizontal[vol_lat_mus_atlas != 0]\n",
    "    sex_group = df_vol_lat_mus_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_lat_mus_male_atlas = np.array([male_group[\"vol_lat_mus_atlas\"]])\n",
    "    vol_lat_mus_female_atlas = np.array([female_group[\"vol_lat_mus_atlas\"]])\n",
    "    \n",
    "    df_vol_lat_mus_nnunet = df_vols_horizontal[vol_lat_mus_nnunet != 0]\n",
    "    sex_group = df_vol_lat_mus_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_lat_mus_male_nnunet = np.array([male_group[\"vol_lat_mus_nnunet\"]])\n",
    "    vol_lat_mus_female_nnunet = np.array([female_group[\"vol_lat_mus_nnunet\"]])    \n",
    "\n",
    "if REMOVE_OUTLIERS:\n",
    "    lower_bound = np.percentile(vol_lat_mus_atlas, 5)\n",
    "    upper_bound = np.percentile(vol_lat_mus_atlas, 95)\n",
    "    df_vol_lat_mus_atlas = df_vol_lat_mus_atlas[(df_vol_lat_mus_atlas[\"vol_lat_mus_atlas\"] > lower_bound) & (df_vol_lat_mus_atlas[\"vol_lat_mus_atlas\"] < upper_bound)]\n",
    "    sex_group = df_vol_lat_mus_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_lat_mus_male_atlas = np.array([male_group[\"vol_lat_mus_atlas\"]])\n",
    "    vol_lat_mus_female_atlas = np.array([female_group[\"vol_lat_mus_atlas\"]])\n",
    "    \n",
    "    lower_bound = np.percentile(vol_lat_mus_nnunet, 5)\n",
    "    upper_bound = np.percentile(vol_lat_mus_nnunet, 95)\n",
    "    df_vol_lat_mus_nnunet = df_vol_lat_mus_nnunet[(df_vol_lat_mus_nnunet[\"vol_lat_mus_nnunet\"] > lower_bound) & (df_vol_lat_mus_nnunet[\"vol_lat_mus_nnunet\"] < upper_bound)]\n",
    "    sex_group = df_vol_lat_mus_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_lat_mus_male_nnunet = np.array([male_group[\"vol_lat_mus_nnunet\"]])\n",
    "    vol_lat_mus_female_nnunet = np.array([female_group[\"vol_lat_mus_nnunet\"]])\n",
    "\n",
    "print(f'Lat_Mus | Atlas  | Male --- median: {np.round(np.median(vol_lat_mus_male_atlas))}, std: {np.round(np.std(vol_lat_mus_male_atlas))} mm3')\n",
    "print(f'Lat_Mus | Atlas  | Female - median: {np.round(np.median(vol_lat_mus_female_atlas))}, std: {np.round(np.std(vol_lat_mus_female_atlas))} mm3')\n",
    "print(f'Lat_Mus | nnUNet | Male --- median: {np.round(np.median(vol_lat_mus_male_nnunet))}, std: {np.round(np.std(vol_lat_mus_male_nnunet))} mm3')\n",
    "print(f'Lat_Mus | nnUNet | Female - median: {np.round(np.median(vol_lat_mus_female_nnunet))}, std: {np.round(np.std(vol_lat_mus_female_nnunet))} mm3 \\n')\n",
    "\n",
    "# med_mus\n",
    "print('Med_Mus')\n",
    "df_vol_med_mus_atlas = df_vols_horizontal\n",
    "vol_med_mus_atlas = df_vols_horizontal[\"vol_med_mus_atlas\"]\n",
    "vol_med_mus_male_atlas = np.array([male_group[\"vol_med_mus_atlas\"]])\n",
    "vol_med_mus_female_atlas = np.array([female_group[\"vol_med_mus_atlas\"]])\n",
    "df_vol_med_mus_nnunet = df_vols_horizontal\n",
    "vol_med_mus_nnunet = df_vols_horizontal[\"vol_med_mus_nnunet\"]\n",
    "vol_med_mus_male_nnunet = np.array([male_group[\"vol_med_mus_nnunet\"]])\n",
    "vol_med_mus_female_nnunet = np.array([female_group[\"vol_med_mus_nnunet\"]])\n",
    "\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_med_mus_atlas = df_vols_horizontal[vol_med_mus_atlas != 0]\n",
    "    sex_group = df_vol_med_mus_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_med_mus_male_atlas = np.array([male_group[\"vol_med_mus_atlas\"]])\n",
    "    vol_med_mus_female_atlas = np.array([female_group[\"vol_med_mus_atlas\"]])\n",
    "    \n",
    "    df_vol_med_mus_nnunet = df_vols_horizontal[vol_med_mus_nnunet != 0]\n",
    "    sex_group = df_vol_med_mus_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_med_mus_male_nnunet = np.array([male_group[\"vol_med_mus_nnunet\"]])\n",
    "    vol_med_mus_female_nnunet = np.array([female_group[\"vol_med_mus_nnunet\"]])    \n",
    "\n",
    "if REMOVE_OUTLIERS:\n",
    "    lower_bound = np.percentile(vol_med_mus_atlas, 5)\n",
    "    upper_bound = np.percentile(vol_med_mus_atlas, 95)\n",
    "    df_vol_med_mus_atlas = df_vol_med_mus_atlas[(df_vol_med_mus_atlas[\"vol_med_mus_atlas\"] > lower_bound) & (df_vol_med_mus_atlas[\"vol_med_mus_atlas\"] < upper_bound)]\n",
    "    sex_group = df_vol_med_mus_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_med_mus_male_atlas = np.array([male_group[\"vol_med_mus_atlas\"]])\n",
    "    vol_med_mus_female_atlas = np.array([female_group[\"vol_med_mus_atlas\"]])\n",
    "    \n",
    "    lower_bound = np.percentile(vol_med_mus_nnunet, 5)\n",
    "    upper_bound = np.percentile(vol_med_mus_nnunet, 95)\n",
    "    df_vol_med_mus_nnunet = df_vol_med_mus_nnunet[(df_vol_med_mus_nnunet[\"vol_med_mus_nnunet\"] > lower_bound) & (df_vol_med_mus_nnunet[\"vol_med_mus_nnunet\"] < upper_bound)]\n",
    "    sex_group = df_vol_med_mus_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_med_mus_male_nnunet = np.array([male_group[\"vol_med_mus_nnunet\"]])\n",
    "    vol_med_mus_female_nnunet = np.array([female_group[\"vol_med_mus_nnunet\"]])\n",
    "\n",
    "print(f'Med_Mus | Atlas  | Male --- median: {np.round(np.median(vol_med_mus_male_atlas))}, std: {np.round(np.std(vol_med_mus_male_atlas))} mm3')\n",
    "print(f'Med_Mus | Atlas  | Female - median: {np.round(np.median(vol_med_mus_female_atlas))}, std: {np.round(np.std(vol_med_mus_female_atlas))} mm3')\n",
    "print(f'Med_Mus | nnUNet | Male --- median: {np.round(np.median(vol_med_mus_male_nnunet))}, std: {np.round(np.std(vol_med_mus_male_nnunet))} mm3')\n",
    "print(f'Med_Mus | nnUNet | Female - median: {np.round(np.median(vol_med_mus_female_nnunet))}, std: {np.round(np.std(vol_med_mus_female_nnunet))} mm3 \\n')\n",
    "\n",
    "# inf_mus\n",
    "print('Inf_Mus')\n",
    "df_vol_inf_mus_atlas = df_vols_horizontal\n",
    "vol_inf_mus_atlas = df_vols_horizontal[\"vol_inf_mus_atlas\"]\n",
    "vol_inf_mus_male_atlas = np.array([male_group[\"vol_inf_mus_atlas\"]])\n",
    "vol_inf_mus_female_atlas = np.array([female_group[\"vol_inf_mus_atlas\"]])\n",
    "df_vol_inf_mus_nnunet = df_vols_horizontal\n",
    "vol_inf_mus_nnunet = df_vols_horizontal[\"vol_inf_mus_nnunet\"]\n",
    "vol_inf_mus_male_nnunet = np.array([male_group[\"vol_inf_mus_nnunet\"]])\n",
    "vol_inf_mus_female_nnunet = np.array([female_group[\"vol_inf_mus_nnunet\"]])\n",
    "\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_inf_mus_atlas = df_vols_horizontal[vol_inf_mus_atlas != 0]\n",
    "    sex_group = df_vol_inf_mus_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_inf_mus_male_atlas = np.array([male_group[\"vol_inf_mus_atlas\"]])\n",
    "    vol_inf_mus_female_atlas = np.array([female_group[\"vol_inf_mus_atlas\"]])\n",
    "    \n",
    "    df_vol_inf_mus_nnunet = df_vols_horizontal[vol_inf_mus_nnunet != 0]\n",
    "    sex_group = df_vol_inf_mus_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_inf_mus_male_nnunet = np.array([male_group[\"vol_inf_mus_nnunet\"]])\n",
    "    vol_inf_mus_female_nnunet = np.array([female_group[\"vol_inf_mus_nnunet\"]])    \n",
    "\n",
    "if REMOVE_OUTLIERS:\n",
    "    lower_bound = np.percentile(vol_inf_mus_atlas, 5)\n",
    "    upper_bound = np.percentile(vol_inf_mus_atlas, 95)\n",
    "    df_vol_inf_mus_atlas = df_vol_inf_mus_atlas[(df_vol_inf_mus_atlas[\"vol_inf_mus_atlas\"] > lower_bound) & (df_vol_inf_mus_atlas[\"vol_inf_mus_atlas\"] < upper_bound)]\n",
    "    sex_group = df_vol_inf_mus_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_inf_mus_male_atlas = np.array([male_group[\"vol_inf_mus_atlas\"]])\n",
    "    vol_inf_mus_female_atlas = np.array([female_group[\"vol_inf_mus_atlas\"]])\n",
    "    \n",
    "    lower_bound = np.percentile(vol_inf_mus_nnunet, 5)\n",
    "    upper_bound = np.percentile(vol_inf_mus_nnunet, 95)\n",
    "    df_vol_inf_mus_nnunet = df_vol_inf_mus_nnunet[(df_vol_inf_mus_nnunet[\"vol_inf_mus_nnunet\"] > lower_bound) & (df_vol_inf_mus_nnunet[\"vol_inf_mus_nnunet\"] < upper_bound)]\n",
    "    sex_group = df_vol_inf_mus_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_inf_mus_male_nnunet = np.array([male_group[\"vol_inf_mus_nnunet\"]])\n",
    "    vol_inf_mus_female_nnunet = np.array([female_group[\"vol_inf_mus_nnunet\"]])\n",
    "\n",
    "print(f'Inf_Mus | Atlas  | Male --- median: {np.round(np.median(vol_inf_mus_male_atlas))}, std: {np.round(np.std(vol_inf_mus_male_atlas))} mm3')\n",
    "print(f'Inf_Mus | Atlas  | Female - median: {np.round(np.median(vol_inf_mus_female_atlas))}, std: {np.round(np.std(vol_inf_mus_female_atlas))} mm3')\n",
    "print(f'Inf_Mus | nnUNet | Male --- median: {np.round(np.median(vol_inf_mus_male_nnunet))}, std: {np.round(np.std(vol_inf_mus_male_nnunet))} mm3')\n",
    "print(f'Inf_Mus | nnUNet | Female - median: {np.round(np.median(vol_inf_mus_female_nnunet))}, std: {np.round(np.std(vol_inf_mus_female_nnunet))} mm3 \\n')\n",
    "\n",
    "# sup_mus\n",
    "print('Sup_Mus')\n",
    "df_vol_sup_mus_atlas = df_vols_horizontal\n",
    "vol_sup_mus_atlas = df_vols_horizontal[\"vol_sup_mus_atlas\"]\n",
    "vol_sup_mus_male_atlas = np.array([male_group[\"vol_sup_mus_atlas\"]])\n",
    "vol_sup_mus_female_atlas = np.array([female_group[\"vol_sup_mus_atlas\"]])\n",
    "df_vol_sup_mus_nnunet = df_vols_horizontal\n",
    "vol_sup_mus_nnunet = df_vols_horizontal[\"vol_sup_mus_nnunet\"]\n",
    "vol_sup_mus_male_nnunet = np.array([male_group[\"vol_sup_mus_nnunet\"]])\n",
    "vol_sup_mus_female_nnunet = np.array([female_group[\"vol_sup_mus_nnunet\"]])\n",
    "\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_sup_mus_atlas = df_vols_horizontal[vol_sup_mus_atlas != 0]\n",
    "    sex_group = df_vol_sup_mus_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_sup_mus_male_atlas = np.array([male_group[\"vol_sup_mus_atlas\"]])\n",
    "    vol_sup_mus_female_atlas = np.array([female_group[\"vol_sup_mus_atlas\"]])\n",
    "    \n",
    "    df_vol_sup_mus_nnunet = df_vols_horizontal[vol_sup_mus_nnunet != 0]\n",
    "    sex_group = df_vol_sup_mus_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_sup_mus_male_nnunet = np.array([male_group[\"vol_sup_mus_nnunet\"]])\n",
    "    vol_sup_mus_female_nnunet = np.array([female_group[\"vol_sup_mus_nnunet\"]])    \n",
    "\n",
    "if REMOVE_OUTLIERS:\n",
    "    lower_bound = np.percentile(vol_sup_mus_atlas, 5)\n",
    "    upper_bound = np.percentile(vol_sup_mus_atlas, 95)\n",
    "    df_vol_sup_mus_atlas = df_vol_sup_mus_atlas[(df_vol_sup_mus_atlas[\"vol_sup_mus_atlas\"] > lower_bound) & (df_vol_sup_mus_atlas[\"vol_sup_mus_atlas\"] < upper_bound)]\n",
    "    sex_group = df_vol_sup_mus_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_sup_mus_male_atlas = np.array([male_group[\"vol_sup_mus_atlas\"]])\n",
    "    vol_sup_mus_female_atlas = np.array([female_group[\"vol_sup_mus_atlas\"]])\n",
    "    \n",
    "    lower_bound = np.percentile(vol_sup_mus_nnunet, 5)\n",
    "    upper_bound = np.percentile(vol_sup_mus_nnunet, 95)\n",
    "    df_vol_sup_mus_nnunet = df_vol_sup_mus_nnunet[(df_vol_sup_mus_nnunet[\"vol_sup_mus_nnunet\"] > lower_bound) & (df_vol_sup_mus_nnunet[\"vol_sup_mus_nnunet\"] < upper_bound)]\n",
    "    sex_group = df_vol_sup_mus_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_sup_mus_male_nnunet = np.array([male_group[\"vol_sup_mus_nnunet\"]])\n",
    "    vol_sup_mus_female_nnunet = np.array([female_group[\"vol_sup_mus_nnunet\"]])\n",
    "\n",
    "print(f'Sup_Mus | Atlas  | Male --- median: {np.round(np.median(vol_sup_mus_male_atlas))}, std: {np.round(np.std(vol_sup_mus_male_atlas))} mm3')\n",
    "print(f'Sup_Mus | Atlas  | Female - median: {np.round(np.median(vol_sup_mus_female_atlas))}, std: {np.round(np.std(vol_sup_mus_female_atlas))} mm3')\n",
    "print(f'Sup_Mus | nnUNet | Male --- median: {np.round(np.median(vol_sup_mus_male_nnunet))}, std: {np.round(np.std(vol_sup_mus_male_nnunet))} mm3')\n",
    "print(f'Sup_Mus | nnUNet | Female - median: {np.round(np.median(vol_sup_mus_female_nnunet))}, std: {np.round(np.std(vol_sup_mus_female_nnunet))} mm3 \\n')\n",
    "\n",
    "# total\n",
    "print('Total')\n",
    "df_vol_total_atlas = df_vols_horizontal\n",
    "vol_total_atlas = df_vols_horizontal[\"vol_total_atlas\"]\n",
    "vol_total_male_atlas = np.array([male_group[\"vol_total_atlas\"]])\n",
    "vol_total_female_atlas = np.array([female_group[\"vol_total_atlas\"]])\n",
    "df_vol_total_nnunet = df_vols_horizontal\n",
    "vol_total_nnunet = df_vols_horizontal[\"vol_total_nnunet\"]\n",
    "vol_total_male_nnunet = np.array([male_group[\"vol_total_nnunet\"]])\n",
    "vol_total_female_nnunet = np.array([female_group[\"vol_total_nnunet\"]])\n",
    "\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_total_atlas = df_vols_horizontal[vol_total_atlas != 0]\n",
    "    sex_group = df_vol_total_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_total_male_atlas = np.array([male_group[\"vol_total_atlas\"]])\n",
    "    vol_total_female_atlas = np.array([female_group[\"vol_total_atlas\"]])\n",
    "    \n",
    "    df_vol_total_nnunet = df_vols_horizontal[vol_total_nnunet != 0]\n",
    "    sex_group = df_vol_total_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_total_male_nnunet = np.array([male_group[\"vol_total_nnunet\"]])\n",
    "    vol_total_female_nnunet = np.array([female_group[\"vol_total_nnunet\"]])    \n",
    "\n",
    "if REMOVE_OUTLIERS:\n",
    "    lower_bound = np.percentile(vol_total_atlas, 5)\n",
    "    upper_bound = np.percentile(vol_total_atlas, 95)\n",
    "    df_vol_total_atlas = df_vol_total_atlas[(df_vol_total_atlas[\"vol_total_atlas\"] > lower_bound) & (df_vol_total_atlas[\"vol_total_atlas\"] < upper_bound)]\n",
    "    sex_group = df_vol_total_atlas.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_total_male_atlas = np.array([male_group[\"vol_total_atlas\"]])\n",
    "    vol_total_female_atlas = np.array([female_group[\"vol_total_atlas\"]])\n",
    "    \n",
    "    lower_bound = np.percentile(vol_total_nnunet, 5)\n",
    "    upper_bound = np.percentile(vol_total_nnunet, 95)\n",
    "    df_vol_total_nnunet = df_vol_total_nnunet[(df_vol_total_nnunet[\"vol_total_nnunet\"] > lower_bound) & (df_vol_total_nnunet[\"vol_total_nnunet\"] < upper_bound)]\n",
    "    sex_group = df_vol_total_nnunet.groupby([\"Sex\"], dropna=True)\n",
    "    male_group = sex_group.get_group(\"M\").dropna()\n",
    "    female_group = sex_group.get_group(\"F\").dropna()\n",
    "    vol_total_male_nnunet = np.array([male_group[\"vol_total_nnunet\"]])\n",
    "    vol_total_female_nnunet = np.array([female_group[\"vol_total_nnunet\"]])\n",
    "\n",
    "print(f'Total | Atlas  | Male --- median: {np.round(np.median(vol_total_male_atlas))}, std: {np.round(np.std(vol_total_male_atlas))} mm3')\n",
    "print(f'Total | Atlas  | Female - median: {np.round(np.median(vol_total_female_atlas))}, std: {np.round(np.std(vol_total_female_atlas))} mm3')\n",
    "print(f'Total | nnUNet | Male --- median: {np.round(np.median(vol_total_male_nnunet))}, std: {np.round(np.std(vol_total_male_nnunet))} mm3')\n",
    "print(f'Total | nnUNet | Female - median: {np.round(np.median(vol_total_female_nnunet))}, std: {np.round(np.std(vol_total_female_nnunet))} mm3 \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data plotting (dataframes - per eye structure removing zeros or outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens\n",
    "df_vol_lens = df_vols_vertical\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_lens = df_vols_vertical[df_vols_vertical[\"vol_lens\"] != 0]\n",
    "if REMOVE_OUTLIERS:\n",
    "    df_vol_lens_atlas_v = df_vol_lens_atlas.iloc[:, 0:16].copy()\n",
    "    df_vol_lens_atlas_v.insert(16, 'method', 'atlas')\n",
    "    rename_dict = {col: col.replace('_atlas', '') for col in df_vol_lens_atlas_v.columns[6:16]}\n",
    "    df_vol_lens_atlas_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_lens_nnunet_v = df_vol_lens_nnunet.iloc[:, list(range(0, 6)) + list(range(16, 26))].copy()\n",
    "    df_vol_lens_nnunet_v.insert(16, 'method', 'nnunet')\n",
    "    rename_dict = {col: col.replace('_nnunet', '') for col in df_vol_lens_nnunet_v.columns[6:16]}\n",
    "    df_vol_lens_nnunet_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_lens = pd.concat([df_vol_lens_atlas_v, df_vol_lens_nnunet_v], ignore_index=True)\n",
    "\n",
    "# globe\n",
    "df_vol_globe = df_vols_vertical\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_globe = df_vols_vertical[df_vols_vertical[\"vol_globe\"] != 0]\n",
    "if REMOVE_OUTLIERS:\n",
    "    df_vol_globe_atlas_v = df_vol_globe_atlas.iloc[:, 0:16].copy()\n",
    "    df_vol_globe_atlas_v.insert(16, 'method', 'atlas')\n",
    "    rename_dict = {col: col.replace('_atlas', '') for col in df_vol_globe_atlas_v.columns[6:16]}\n",
    "    df_vol_globe_atlas_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_globe_nnunet_v = df_vol_globe_nnunet.iloc[:, list(range(0, 6)) + list(range(16, 26))].copy()\n",
    "    df_vol_globe_nnunet_v.insert(16, 'method', 'nnunet')\n",
    "    rename_dict = {col: col.replace('_nnunet', '') for col in df_vol_globe_nnunet_v.columns[6:16]}\n",
    "    df_vol_globe_nnunet_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_globe = pd.concat([df_vol_globe_atlas_v, df_vol_globe_nnunet_v], ignore_index=True)\n",
    "\n",
    "# nerve\n",
    "df_vol_nerve = df_vols_vertical\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_nerve = df_vols_vertical[df_vols_vertical[\"vol_nerve\"] != 0]\n",
    "if REMOVE_OUTLIERS:\n",
    "    df_vol_nerve_atlas_v = df_vol_nerve_atlas.iloc[:, 0:16].copy()\n",
    "    df_vol_nerve_atlas_v.insert(16, 'method', 'atlas')\n",
    "    rename_dict = {col: col.replace('_atlas', '') for col in df_vol_nerve_atlas_v.columns[6:16]}\n",
    "    df_vol_nerve_atlas_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_nerve_nnunet_v = df_vol_nerve_nnunet.iloc[:, list(range(0, 6)) + list(range(16, 26))].copy()\n",
    "    df_vol_nerve_nnunet_v.insert(16, 'method', 'nnunet')\n",
    "    rename_dict = {col: col.replace('_nnunet', '') for col in df_vol_nerve_nnunet_v.columns[6:16]}\n",
    "    df_vol_nerve_nnunet_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_nerve = pd.concat([df_vol_nerve_atlas_v, df_vol_nerve_nnunet_v], ignore_index=True)\n",
    "\n",
    "# int_fat\n",
    "df_vol_int_fat = df_vols_vertical\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_int_fat = df_vols_vertical[df_vols_vertical[\"vol_int_fat\"] != 0]\n",
    "if REMOVE_OUTLIERS:\n",
    "    df_vol_int_fat_atlas_v = df_vol_int_fat_atlas.iloc[:, 0:16].copy()\n",
    "    df_vol_int_fat_atlas_v.insert(16, 'method', 'atlas')\n",
    "    rename_dict = {col: col.replace('_atlas', '') for col in df_vol_int_fat_atlas_v.columns[6:16]}\n",
    "    df_vol_int_fat_atlas_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_int_fat_nnunet_v = df_vol_int_fat_nnunet.iloc[:, list(range(0, 6)) + list(range(16, 26))].copy()\n",
    "    df_vol_int_fat_nnunet_v.insert(16, 'method', 'nnunet')\n",
    "    rename_dict = {col: col.replace('_nnunet', '') for col in df_vol_int_fat_nnunet_v.columns[6:16]}\n",
    "    df_vol_int_fat_nnunet_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_int_fat = pd.concat([df_vol_int_fat_atlas_v, df_vol_int_fat_nnunet_v], ignore_index=True)\n",
    "\n",
    "# ext_fat\n",
    "df_vol_ext_fat = df_vols_vertical\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_ext_fat = df_vols_vertical[df_vols_vertical[\"vol_ext_fat\"] != 0]\n",
    "if REMOVE_OUTLIERS:\n",
    "    df_vol_ext_fat_atlas_v = df_vol_ext_fat_atlas.iloc[:, 0:16].copy()\n",
    "    df_vol_ext_fat_atlas_v.insert(16, 'method', 'atlas')\n",
    "    rename_dict = {col: col.replace('_atlas', '') for col in df_vol_ext_fat_atlas_v.columns[6:16]}\n",
    "    df_vol_ext_fat_atlas_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_ext_fat_nnunet_v = df_vol_ext_fat_nnunet.iloc[:, list(range(0, 6)) + list(range(16, 26))].copy()\n",
    "    df_vol_ext_fat_nnunet_v.insert(16, 'method', 'nnunet')\n",
    "    rename_dict = {col: col.replace('_nnunet', '') for col in df_vol_ext_fat_nnunet_v.columns[6:16]}\n",
    "    df_vol_ext_fat_nnunet_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_ext_fat = pd.concat([df_vol_ext_fat_atlas_v, df_vol_ext_fat_nnunet_v], ignore_index=True)\n",
    "\n",
    "# lat_mus\n",
    "df_vol_lat_mus = df_vols_vertical\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_lat_mus = df_vols_vertical[df_vols_vertical[\"vol_lat_mus\"] != 0]\n",
    "if REMOVE_OUTLIERS:\n",
    "    df_vol_lat_mus_atlas_v = df_vol_lat_mus_atlas.iloc[:, 0:16].copy()\n",
    "    df_vol_lat_mus_atlas_v.insert(16, 'method', 'atlas')\n",
    "    rename_dict = {col: col.replace('_atlas', '') for col in df_vol_lat_mus_atlas_v.columns[6:16]}\n",
    "    df_vol_lat_mus_atlas_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_lat_mus_nnunet_v = df_vol_lat_mus_nnunet.iloc[:, list(range(0, 6)) + list(range(16, 26))].copy()\n",
    "    df_vol_lat_mus_nnunet_v.insert(16, 'method', 'nnunet')\n",
    "    rename_dict = {col: col.replace('_nnunet', '') for col in df_vol_lat_mus_nnunet_v.columns[6:16]}\n",
    "    df_vol_lat_mus_nnunet_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_lat_mus = pd.concat([df_vol_lat_mus_atlas_v, df_vol_lat_mus_nnunet_v], ignore_index=True)\n",
    "\n",
    "# med_mus\n",
    "df_vol_med_mus = df_vols_vertical\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_med_mus = df_vols_vertical[df_vols_vertical[\"vol_med_mus\"] != 0]\n",
    "if REMOVE_OUTLIERS:\n",
    "    df_vol_med_mus_atlas_v = df_vol_med_mus_atlas.iloc[:, 0:16].copy()\n",
    "    df_vol_med_mus_atlas_v.insert(16, 'method', 'atlas')\n",
    "    rename_dict = {col: col.replace('_atlas', '') for col in df_vol_med_mus_atlas_v.columns[6:16]}\n",
    "    df_vol_med_mus_atlas_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_med_mus_nnunet_v = df_vol_med_mus_nnunet.iloc[:, list(range(0, 6)) + list(range(16, 26))].copy()\n",
    "    df_vol_med_mus_nnunet_v.insert(16, 'method', 'nnunet')\n",
    "    rename_dict = {col: col.replace('_nnunet', '') for col in df_vol_med_mus_nnunet_v.columns[6:16]}\n",
    "    df_vol_med_mus_nnunet_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_med_mus = pd.concat([df_vol_med_mus_atlas_v, df_vol_med_mus_nnunet_v], ignore_index=True)\n",
    "\n",
    "# inf_mus\n",
    "df_vol_inf_mus = df_vols_vertical\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_inf_mus = df_vols_vertical[df_vols_vertical[\"vol_inf_mus\"] != 0]\n",
    "if REMOVE_OUTLIERS:\n",
    "    df_vol_inf_mus_atlas_v = df_vol_inf_mus_atlas.iloc[:, 0:16].copy()\n",
    "    df_vol_inf_mus_atlas_v.insert(16, 'method', 'atlas')\n",
    "    rename_dict = {col: col.replace('_atlas', '') for col in df_vol_inf_mus_atlas_v.columns[6:16]}\n",
    "    df_vol_inf_mus_atlas_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_inf_mus_nnunet_v = df_vol_inf_mus_nnunet.iloc[:, list(range(0, 6)) + list(range(16, 26))].copy()\n",
    "    df_vol_inf_mus_nnunet_v.insert(16, 'method', 'nnunet')\n",
    "    rename_dict = {col: col.replace('_nnunet', '') for col in df_vol_inf_mus_nnunet_v.columns[6:16]}\n",
    "    df_vol_inf_mus_nnunet_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_inf_mus = pd.concat([df_vol_inf_mus_atlas_v, df_vol_inf_mus_nnunet_v], ignore_index=True)\n",
    "\n",
    "# sup_mus\n",
    "df_vol_sup_mus = df_vols_vertical\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_sup_mus = df_vols_vertical[df_vols_vertical[\"vol_sup_mus\"] != 0]\n",
    "if REMOVE_OUTLIERS:\n",
    "    df_vol_sup_mus_atlas_v = df_vol_sup_mus_atlas.iloc[:, 0:16].copy()\n",
    "    df_vol_sup_mus_atlas_v.insert(16, 'method', 'atlas')\n",
    "    rename_dict = {col: col.replace('_atlas', '') for col in df_vol_sup_mus_atlas_v.columns[6:16]}\n",
    "    df_vol_sup_mus_atlas_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_sup_mus_nnunet_v = df_vol_sup_mus_nnunet.iloc[:, list(range(0, 6)) + list(range(16, 26))].copy()\n",
    "    df_vol_sup_mus_nnunet_v.insert(16, 'method', 'nnunet')\n",
    "    rename_dict = {col: col.replace('_nnunet', '') for col in df_vol_sup_mus_nnunet_v.columns[6:16]}\n",
    "    df_vol_sup_mus_nnunet_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_sup_mus = pd.concat([df_vol_sup_mus_atlas_v, df_vol_sup_mus_nnunet_v], ignore_index=True)\n",
    "\n",
    "# total\n",
    "df_vol_total = df_vols_vertical\n",
    "if REMOVE_ZEROS:\n",
    "    df_vol_total = df_vols_vertical[df_vols_vertical[\"vol_total\"] != 0]\n",
    "if REMOVE_OUTLIERS:\n",
    "    df_vol_total_atlas_v = df_vol_total_atlas.iloc[:, 0:16].copy()\n",
    "    df_vol_total_atlas_v.insert(16, 'method', 'atlas')\n",
    "    rename_dict = {col: col.replace('_atlas', '') for col in df_vol_total_atlas_v.columns[6:16]}\n",
    "    df_vol_total_atlas_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_total_nnunet_v = df_vol_total_nnunet.iloc[:, list(range(0, 6)) + list(range(16, 26))].copy()\n",
    "    df_vol_total_nnunet_v.insert(16, 'method', 'nnunet')\n",
    "    rename_dict = {col: col.replace('_nnunet', '') for col in df_vol_total_nnunet_v.columns[6:16]}\n",
    "    df_vol_total_nnunet_v.rename(columns=rename_dict, inplace=True)\n",
    "    df_vol_total = pd.concat([df_vol_total_atlas_v, df_vol_total_nnunet_v], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot with seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Subplots\n",
    "fig, ax = plt.subplots(3, 3, figsize=(20, 20))\n",
    "fig.suptitle(f'Volumetry per Structure in mm³ per Method by Sex. Total = {len(pd_volumes_nnunet)} subjects')\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Legend\n",
    "# legend_elements = [Line2D([0], [0], color='lightskyblue', lw=2, label='ATLAS'),\n",
    "#     Line2D([0], [0], color='steelblue', lw=2, label='nnUNet')]\n",
    "# fig.legend(handles=legend_elements, loc='upper right')\n",
    "fig.tight_layout(pad=3)\n",
    "\n",
    "# Color\n",
    "# palette with 'lightskyblue' and 'steelblue'\n",
    "palette = sns.color_palette(\"Blues\", 2)\n",
    "\n",
    "# lens\n",
    "ax[0][0].set_title(\"LENS\")\n",
    "graph = sns.violinplot(data=df_vol_lens, x=\"method\", y=\"vol_lens\", ax=ax[0][0], hue='Sex' , split=True, inner='quart', palette=palette)\n",
    "graph.set_ylabel('Volume (mm³)')\n",
    "graph.text(0, df_vol_lens['vol_lens'].min(), f'Male: {len(vol_lens_male_atlas[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, df_vol_lens['vol_lens'].min(), f' Female: {len(vol_lens_female_atlas[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_lens['vol_lens'].min(), f'Male: {len(vol_lens_male_nnunet[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_lens['vol_lens'].min(), f' Female: {len(vol_lens_female_nnunet[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_lens_male_atlas)), f'{int(np.median(vol_lens_male_atlas))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_lens_female_atlas)), f'{int(np.median(vol_lens_female_atlas))}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_lens_male_nnunet)), f'{int(np.median(vol_lens_male_nnunet))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_lens_female_nnunet)), f'{int(np.median(vol_lens_female_nnunet))}', ha='left', va='bottom', fontsize=10)\n",
    "\n",
    "# globe\n",
    "ax[0][1].set_title(\"GLOBE\")\n",
    "graph = sns.violinplot(data=df_vol_globe, x=\"method\", y=\"vol_globe\", ax=ax[0][1], hue='Sex' , split=True, inner='quart', palette=palette)\n",
    "graph.set_ylabel('Volume (mm³)')\n",
    "graph.text(0, df_vol_globe['vol_globe'].min(), f'Male: {len(vol_globe_male_atlas[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, df_vol_globe['vol_globe'].min(), f' Female: {len(vol_globe_female_atlas[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_globe['vol_globe'].min(), f'Male: {len(vol_globe_male_nnunet[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_globe['vol_globe'].min(), f' Female: {len(vol_globe_female_nnunet[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_globe_male_atlas)), f'{int(np.median(vol_globe_male_atlas))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_globe_female_atlas)), f'{int(np.median(vol_globe_female_atlas))}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_globe_male_nnunet)), f'{int(np.median(vol_globe_male_nnunet))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_globe_female_nnunet)), f'{int(np.median(vol_globe_female_nnunet))}', ha='left', va='bottom', fontsize=10)\n",
    "\n",
    "# nerve\n",
    "ax[0][2].set_title(\"OPTIC NERVE\")\n",
    "graph = sns.violinplot(data=df_vol_nerve, x=\"method\", y=\"vol_nerve\", ax=ax[0][2], hue='Sex' , split=True, inner='quart', palette=palette)\n",
    "graph.set_ylabel('Volume (mm³)')\n",
    "graph.text(0, df_vol_nerve['vol_nerve'].min(), f'Male: {len(vol_nerve_male_atlas[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, df_vol_nerve['vol_nerve'].min(), f' Female: {len(vol_nerve_female_atlas[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_nerve['vol_nerve'].min(), f'Male: {len(vol_nerve_male_nnunet[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_nerve['vol_nerve'].min(), f' Female: {len(vol_nerve_female_nnunet[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_nerve_male_atlas)), f'{int(np.median(vol_nerve_male_atlas))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_nerve_female_atlas)), f'{int(np.median(vol_nerve_female_atlas))}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_nerve_male_nnunet)), f'{int(np.median(vol_nerve_male_nnunet))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_nerve_female_nnunet)), f'{int(np.median(vol_nerve_female_nnunet))}', ha='left', va='bottom', fontsize=10)\n",
    "\n",
    "# int_fat\n",
    "ax[1][0].set_title(\"INTRACONAL FAT\")\n",
    "graph = sns.violinplot(data=df_vol_int_fat, x=\"method\", y=\"vol_int_fat\", ax=ax[1][0], hue='Sex' , split=True, inner='quart', palette=palette)\n",
    "graph.set_ylabel('Volume (mm³)')\n",
    "graph.text(0, df_vol_int_fat['vol_int_fat'].min(), f'Male: {len(vol_lens_male_atlas[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, df_vol_int_fat['vol_int_fat'].min(), f' Female: {len(vol_lens_female_atlas[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_int_fat['vol_int_fat'].min(), f'Male: {len(vol_lens_male_nnunet[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_int_fat['vol_int_fat'].min(), f' Female: {len(vol_lens_female_nnunet[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_int_fat_male_atlas)), f'{int(np.median(vol_int_fat_male_atlas))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_int_fat_female_atlas)), f'{int(np.median(vol_int_fat_female_atlas))}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_int_fat_male_nnunet)), f'{int(np.median(vol_int_fat_male_nnunet))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_int_fat_female_nnunet)), f'{int(np.median(vol_int_fat_female_nnunet))}', ha='left', va='bottom', fontsize=10)\n",
    "\n",
    "# ext_fat\n",
    "ax[1][1].set_title(\"EXTRACONAL FAT\")\n",
    "graph = sns.violinplot(data=df_vol_ext_fat, x=\"method\", y=\"vol_ext_fat\", ax=ax[1][1], hue='Sex' , split=True, inner='quart', palette=palette)\n",
    "graph.set_ylabel('Volume (mm³)')\n",
    "graph.text(0, df_vol_ext_fat['vol_ext_fat'].min(), f'Male: {len(vol_lens_male_atlas[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, df_vol_ext_fat['vol_ext_fat'].min(), f' Female: {len(vol_lens_female_atlas[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_ext_fat['vol_ext_fat'].min(), f'Male: {len(vol_lens_male_nnunet[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_ext_fat['vol_ext_fat'].min(), f' Female: {len(vol_lens_female_nnunet[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_ext_fat_male_atlas)), f'{int(np.median(vol_ext_fat_male_atlas))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_ext_fat_female_atlas)), f'{int(np.median(vol_ext_fat_female_atlas))}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_ext_fat_male_nnunet)), f'{int(np.median(vol_ext_fat_male_nnunet))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_ext_fat_female_nnunet)), f'{int(np.median(vol_ext_fat_female_nnunet))}', ha='left', va='bottom', fontsize=10)\n",
    "\n",
    "# lat_mus\n",
    "ax[1][2].set_title(\"LATERAL RECTUS MUSCLE\")\n",
    "graph = sns.violinplot(data=df_vol_lat_mus, x=\"method\", y=\"vol_lat_mus\", ax=ax[1][2], hue='Sex' , split=True, inner='quart', palette=palette)\n",
    "graph.set_ylabel('Volume (mm³)')\n",
    "graph.text(0, df_vol_lat_mus['vol_lat_mus'].min(), f'Male: {len(vol_lens_male_atlas[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, df_vol_lat_mus['vol_lat_mus'].min(), f' Female: {len(vol_lens_female_atlas[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_lat_mus['vol_lat_mus'].min(), f'Male: {len(vol_lens_male_nnunet[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_lat_mus['vol_lat_mus'].min(), f' Female: {len(vol_lens_female_nnunet[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_lat_mus_male_atlas)), f'{int(np.median(vol_lat_mus_male_atlas))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_lat_mus_female_atlas)), f'{int(np.median(vol_lat_mus_female_atlas))}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_lat_mus_male_nnunet)), f'{int(np.median(vol_lat_mus_male_nnunet))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_lat_mus_female_nnunet)), f'{int(np.median(vol_lat_mus_female_nnunet))}', ha='left', va='bottom', fontsize=10)\n",
    "\n",
    "# med_mus\n",
    "ax[2][0].set_title(\"MEDIAL RECTUS MUSCLE\")\n",
    "graph = sns.violinplot(data=df_vol_med_mus, x=\"method\", y=\"vol_med_mus\", ax=ax[2][0], hue='Sex' , split=True, inner='quart', palette=palette)\n",
    "graph.set_ylabel('Volume (mm³)')\n",
    "graph.text(0, df_vol_med_mus['vol_med_mus'].min(), f'Male: {len(vol_lens_male_atlas[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, df_vol_med_mus['vol_med_mus'].min(), f' Female: {len(vol_lens_female_atlas[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_med_mus['vol_med_mus'].min(), f'Male: {len(vol_lens_male_nnunet[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_med_mus['vol_med_mus'].min(), f' Female: {len(vol_lens_female_nnunet[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_med_mus_male_atlas)), f'{int(np.median(vol_med_mus_male_atlas))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_med_mus_female_atlas)), f'{int(np.median(vol_med_mus_female_atlas))}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_med_mus_male_nnunet)), f'{int(np.median(vol_med_mus_male_nnunet))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_med_mus_female_nnunet)), f'{int(np.median(vol_med_mus_female_nnunet))}', ha='left', va='bottom', fontsize=10)\n",
    "\n",
    "# inf_mus\n",
    "ax[2][1].set_title(\"INFERIOR RECTUS MUSCLE\")\n",
    "graph = sns.violinplot(data=df_vol_inf_mus, x=\"method\", y=\"vol_inf_mus\", ax=ax[2][1], hue='Sex' , split=True, inner='quart', palette=palette)\n",
    "graph.set_ylabel('Volume (mm³)')\n",
    "graph.text(0, df_vol_inf_mus['vol_inf_mus'].min(), f'Male: {len(vol_lens_male_atlas[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, df_vol_inf_mus['vol_inf_mus'].min(), f' Female: {len(vol_lens_female_atlas[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_inf_mus['vol_inf_mus'].min(), f'Male: {len(vol_lens_male_nnunet[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_inf_mus['vol_inf_mus'].min(), f' Female: {len(vol_lens_female_nnunet[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_inf_mus_male_atlas)), f'{int(np.median(vol_inf_mus_male_atlas))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_inf_mus_female_atlas)), f'{int(np.median(vol_inf_mus_female_atlas))}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_inf_mus_male_nnunet)), f'{int(np.median(vol_inf_mus_male_nnunet))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_inf_mus_female_nnunet)), f'{int(np.median(vol_inf_mus_female_nnunet))}', ha='left', va='bottom', fontsize=10)\n",
    "\n",
    "# sup_mus\n",
    "ax[2][2].set_title(\"SUPERIOR RECTUS MUSCLE\")\n",
    "graph = sns.violinplot(data=df_vol_sup_mus, x=\"method\", y=\"vol_sup_mus\", ax=ax[2][2], hue='Sex' , split=True, inner='quart', palette=palette)\n",
    "graph.set_ylabel('Volume (mm³)')\n",
    "graph.text(0, df_vol_sup_mus['vol_sup_mus'].min(), f'Male: {len(vol_lens_male_atlas[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, df_vol_sup_mus['vol_sup_mus'].min(), f' Female: {len(vol_lens_female_atlas[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_sup_mus['vol_sup_mus'].min(), f'Male: {len(vol_lens_male_nnunet[0])} ', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, df_vol_sup_mus['vol_sup_mus'].min(), f' Female: {len(vol_lens_female_nnunet[0])}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_sup_mus_male_atlas)), f'{int(np.median(vol_sup_mus_male_atlas))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(0, int(np.median(vol_sup_mus_female_atlas)), f'{int(np.median(vol_sup_mus_female_atlas))}', ha='left', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_sup_mus_male_nnunet)), f'{int(np.median(vol_sup_mus_male_nnunet))}', ha='right', va='bottom', fontsize=10)\n",
    "graph.text(1, int(np.median(vol_sup_mus_female_nnunet)), f'{int(np.median(vol_sup_mus_female_nnunet))}', ha='left', va='bottom', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "methods separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Create a list of the structures to loop through\n",
    "structures = [\n",
    "    ('LENS', df_vol_lens, 'vol_lens'),\n",
    "    ('GLOBE', df_vol_globe, 'vol_globe'),\n",
    "    ('OPTIC NERVE', df_vol_nerve, 'vol_nerve'),\n",
    "    ('INTRACONAL FAT', df_vol_int_fat, 'vol_int_fat'),\n",
    "    ('EXTRACONAL FAT', df_vol_ext_fat, 'vol_ext_fat'),\n",
    "    ('LATERAL RECTUS MUSCLE', df_vol_lat_mus, 'vol_lat_mus'),\n",
    "    ('MEDIAL RECTUS MUSCLE', df_vol_med_mus, 'vol_med_mus'),\n",
    "    ('INFERIOR RECTUS MUSCLE', df_vol_inf_mus, 'vol_inf_mus'),\n",
    "    ('SUPERIOR RECTUS MUSCLE', df_vol_sup_mus, 'vol_sup_mus')\n",
    "]\n",
    "\n",
    "# Subplots configuration\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 20))\n",
    "fig.suptitle(f'Volumetry per Structure in mm³ per Sex. Total = {len(df_vol_lens[df_vol_lens[\"method\"] == \"nnunet\"])} subjects')\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.tight_layout(pad=3)\n",
    "\n",
    "# Color palette\n",
    "palette = sns.color_palette(\"Blues\", 2)\n",
    "\n",
    "# Plot each structure in a separate subplot\n",
    "for ax, (title, df, vol_col) in zip(axes.flatten(), structures):\n",
    "    # Filter the dataframe to include only the 'nnunet' method\n",
    "    df_nnunet = df[df['method'] == 'nnunet']\n",
    "    \n",
    "    # Plot the violin plot\n",
    "    sns.violinplot(data=df_nnunet, x=\"method\", y=vol_col, ax=ax, hue='Sex', split=True, inner='quart', palette=palette)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Volume (mm³)')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Add median values as text\n",
    "    median_val = df_nnunet[df_nnunet['Sex'] == \"M\"][vol_col].median()\n",
    "    ax.text(-0.1, median_val, f'{int(median_val)}', ha='left', va='bottom', fontsize=10, color='black')\n",
    "    median_val = df_nnunet[df_nnunet['Sex'] == \"F\"][vol_col].median()\n",
    "    ax.text(0.1, median_val, f'{int(median_val)}', ha='right', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save figure as .png\n",
    "fig.savefig('/mnt/sda1/Repos/a-eye/Output/volumetry/nnunet/nnunet_sex_raw_text_right_eye_qc1_qc2_qc3.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# csv_file = pd.read_csv('/mnt/sda1/Repos/a-eye/Output/volumetry/atlas/volumes_reg_total_qc1_qc2.csv')\n",
    "csv_file = pd.read_csv('/mnt/sda1/Repos/a-eye/Output/volumetry/nnunet/volumes_nnunet_right_eye_qc1_qc2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk test for normality for each column of csv_file\n",
    "from scipy.stats import shapiro\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for i in range(1, len(csv_file.columns)):\n",
    "    stat, p = shapiro(csv_file.iloc[:,i])\n",
    "    print(f'{csv_file.columns[i]}: Statistics={stat}, p={p}')\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('Sample does not look Gaussian (reject H0)')\n",
    "    # histogram plot\n",
    "    plt.hist(csv_file.iloc[:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_df1 = pd.DataFrame(columns=['Column', 'Outlier Subject'])\n",
    "bounds_df = pd.DataFrame(columns=['Column', 'Lower Bound', 'Upper Bound']) # dataFrame for bounds\n",
    "\n",
    "# Calculate the IQR for each column\n",
    "Q1 = csv_file.quantile(0.25)\n",
    "Q3 = csv_file.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Find the outliers for each column\n",
    "for column in csv_file.columns[1:]:\n",
    "    lower_bound = Q1[column] - 1.5 * IQR[column]\n",
    "    upper_bound = Q3[column] + 1.5 * IQR[column]\n",
    "\n",
    "    # Append bounds to the bounds_df DataFrame\n",
    "    new_row = pd.DataFrame({'Column': [column], 'Lower Bound': [lower_bound], 'Upper Bound': [upper_bound]})\n",
    "    bounds_df = pd.concat([bounds_df, new_row], ignore_index=True)\n",
    "\n",
    "    column_outliers = csv_file[(csv_file[column] < lower_bound) | (csv_file[column] > upper_bound)]\n",
    "    new_row = pd.DataFrame({'Column': [column], 'Outlier Subject': [column_outliers['Subject'].values]})\n",
    "    outliers_df1 = pd.concat([outliers_df1, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new DataFrame with the same structure as csv_file but filled with False\n",
    "outliers_df2 = pd.DataFrame(False, index=csv_file.index, columns=csv_file.columns)\n",
    "\n",
    "# Copy the 'Subject' column from csv_file to outliers_df\n",
    "outliers_df2['Subject'] = csv_file['Subject']\n",
    "\n",
    "# Calculate the IQR for each column excluding 'Subject'\n",
    "Q1 = csv_file.drop('Subject', axis=1).quantile(0.25)\n",
    "Q3 = csv_file.drop('Subject', axis=1).quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Find the outliers for each column excluding 'Subject'\n",
    "for column in csv_file.columns:\n",
    "    if column != 'Subject':\n",
    "        lower_bound = Q1[column] - 1.5 * IQR[column]\n",
    "        upper_bound = Q3[column] + 1.5 * IQR[column]\n",
    "        # Update outliers_df with True for outliers\n",
    "        outliers_df2[column] = (csv_file[column] < lower_bound) | (csv_file[column] > upper_bound)\n",
    "\n",
    "# Replace all False values with ''\n",
    "outliers_df2 = outliers_df2.replace(False, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# make a list of 'Outlier Subject' without duplicates in row and column\n",
    "outliers_list = []\n",
    "for i in range(len(outliers_df1)):\n",
    "    for j in range(len(outliers_df1.iloc[i,1])):\n",
    "        outliers_list.append(outliers_df1.iloc[i,1][j])\n",
    "\n",
    "# Count the occurrences of each outlier\n",
    "outliers_counter = Counter(outliers_list)\n",
    "\n",
    "# Keep only the outliers that appear more than once\n",
    "outliers_list = [item for item, count in outliers_counter.items() if count > 1]\n",
    "\n",
    "outliers_list = list(sorted(set(outliers_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reports to look at - removing already analysed subjects from atlas qc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc3_vol_atlas = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_vol_atlas.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_aux = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/df_aux.csv\")\n",
    "\n",
    "# subdataframe of df_aux with the outliers_list\n",
    "outliers_reports_df = df_aux[df_aux['subject'].isin(outliers_list)]\n",
    "# add 'my_rate' column to outliers_reports_df\n",
    "outliers_reports_df.loc[:, 'my_rate'] = 0.0\n",
    "# order outliers_reports_df by 'report'\n",
    "outliers_reports_df = outliers_reports_df.sort_values(by=['report'])\n",
    "# remove subjects from outliers_reports_df that are in qc3_atlas - useful to view the non-repeated reports\n",
    "outliers_reports_df = outliers_reports_df[~outliers_reports_df['subject'].isin(qc3_vol_atlas['subject'])]\n",
    "# add column 'comments' to outliers_reports_df\n",
    "outliers_reports_df.loc[:, 'comments'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy reports that appear in outliers_reports from /home/jaimebarranco/Desktop/MRI-QC/fetal/fetalqc_non-labeled-dataset to /home/jaimebarranco/Downloads/reports \n",
    "import shutil\n",
    "import os\n",
    "\n",
    "reports_folder = '/home/jaimebarranco/Downloads/reports/'\n",
    "# create reports folder if it doesn't exist\n",
    "if not os.path.exists(reports_folder):\n",
    "    os.makedirs(reports_folder)\n",
    "else:\n",
    "    # remove content from reports folder\n",
    "    for filename in os.listdir(reports_folder):\n",
    "        file_path = os.path.join(reports_folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "for report in outliers_reports_df['report']:\n",
    "    src = f'/home/jaimebarranco/Desktop/MRI-QC/fetal/fetalqc_non-labeled-dataset/{report}_report.html'\n",
    "    dst = f'/home/jaimebarranco/Downloads/reports/{report}_report.html'\n",
    "    shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint outliers (atlas + nnunet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc3_atlas = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_vol_atlas.xlsx\")\n",
    "qc3_nnunet = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_vol_nnunet.xlsx\")\n",
    "\n",
    "# joint dataframes\n",
    "qc3 = pd.concat([qc3_atlas, qc3_nnunet], ignore_index=True)\n",
    "# keep only the rows with '0' in my_rate column\n",
    "qc3 = qc3[qc3['my_rate'] == 0]\n",
    "# save it to .csv\n",
    "qc3.to_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_vol.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Axial length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alignment for new manual segmentation issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# Paths\n",
    "main_path = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/'\n",
    "template_path = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/new_manual_annotations/segmentations/manual_74/'\n",
    "input_path = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/new_manual_annotations/segmentations/nnunet/'\n",
    "output_path = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/new_manual_annotations/segmentations/nnunet_aligned/'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Loop over input images\n",
    "for folder1 in sorted(os.listdir(input_path)):\n",
    "    # Load template and input images\n",
    "    template_image = sitk.ReadImage(os.path.join(template_path, folder1))\n",
    "    input_image = sitk.ReadImage(os.path.join(input_path, folder1))\n",
    "\n",
    "    # Debugging: Print image properties\n",
    "    print(f\"Template image size: {template_image.GetSize()}, pixel type: {template_image.GetPixelIDTypeAsString()}\")\n",
    "    print(f\"Input image size: {input_image.GetSize()}, pixel type: {input_image.GetPixelIDTypeAsString()}\")\n",
    "\n",
    "    # Ensure both images are 3D\n",
    "    if len(template_image.GetSize()) == 2:\n",
    "        template_image = sitk.JoinSeries([template_image])\n",
    "    if len(input_image.GetSize()) == 2:\n",
    "        input_image = sitk.JoinSeries([input_image])\n",
    "\n",
    "    # Ensure both images have the same pixel type\n",
    "    template_image = sitk.Cast(template_image, sitk.sitkFloat32)\n",
    "    input_image = sitk.Cast(input_image, sitk.sitkFloat32)\n",
    "\n",
    "    # Perform registration\n",
    "    initial_transform = sitk.CenteredTransformInitializer(\n",
    "        template_image,\n",
    "        input_image,\n",
    "        sitk.Euler3DTransform(),\n",
    "        sitk.CenteredTransformInitializerFilter.GEOMETRY\n",
    "    )\n",
    "\n",
    "    # Resample input image to match the template\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetReferenceImage(template_image)\n",
    "    resampler.SetTransform(initial_transform)\n",
    "\n",
    "    # Use nearest-neighbor interpolation to preserve voxel values\n",
    "    resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    resampled_image = resampler.Execute(input_image)\n",
    "\n",
    "    # Save the aligned image\n",
    "    output_file = os.path.join(output_path, folder1)\n",
    "    sitk.WriteImage(resampled_image, output_file)\n",
    "    print(f\"Aligned image saved to {output_file}\")\n",
    "\n",
    "    # Stop after first image for debugging\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regionprops + line 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from skimage.measure import regionprops, label\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.lines import Line2D\n",
    "import math\n",
    "from skimage import filters\n",
    "\n",
    "METHOD = 'atlas' # atlas, manual, nnunet\n",
    "\n",
    "# Paths - segmentation results\n",
    "if METHOD=='atlas':\n",
    "    img_path = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/new_manual_annotations/images/images_cropped_reoriented/'\n",
    "    lab_path = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/new_manual_annotations/segmentations/atlas_cropped_reoriented/'\n",
    "    output_path = '/mnt/sda1/Repos/a-eye/Output/axial_length/atlas/'\n",
    "elif METHOD=='manual':\n",
    "    img_path = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/new_manual_annotations/images/images/'\n",
    "    lab_path = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/new_manual_annotations/segmentations/manual_74/'\n",
    "    output_path = '/mnt/sda1/Repos/a-eye/Output/axial_length/manual/'\n",
    "elif METHOD=='nnunet':\n",
    "    img_path = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/new_manual_annotations/images/images/'\n",
    "    lab_path = '/mnt/sda1/Repos/a-eye/Data/SHIP_dataset/new_manual_annotations/segmentations/nnunet_aligned/'\n",
    "    output_path = '/mnt/sda1/Repos/a-eye/Output/axial_length/nnunet/'\n",
    "\n",
    "# List of volumes for each individual label and subject\n",
    "len_path = len([elem for elem in os.listdir(lab_path)])\n",
    "name_subject = [\"\"]*len_path\n",
    "axial_length_total = np.zeros(len_path)\n",
    "outliers_list_1 = list() # condition 1\n",
    "outliers_list_2 = list() # condition 2\n",
    "outliers_list_3 = list() # condition 3\n",
    "outliers_list_4 = list() # condition 4\n",
    "outliers_dict_2 = {}\n",
    "outliers_dict_3 = {}\n",
    "outliers_dict_4 = {}\n",
    "list_results = sorted(os.listdir(lab_path))\n",
    "arr_diff = []\n",
    "\n",
    "i=0\n",
    "for folder1 in list_results:\n",
    "    # if folder1 == '2022160100265.nii.gz': # uncomment for concrete subject\n",
    "    # if folder1 == 'AEye_2022160100285_0000.nii.gz': # for nnunet\n",
    "\n",
    "        # Subject's name\n",
    "        if METHOD=='dl': name_subject[i] = folder1.split('_')[0]\n",
    "        # elif METHOD=='nnunet': name_subject[i] = folder1.split('_')[1]\n",
    "        else: name_subject[i] = str(folder1) # atlas, manual, new manual annotations\n",
    "        print(f'subject: {name_subject[i]}')\n",
    "\n",
    "        # Load image in array format\n",
    "        if METHOD=='atlas':\n",
    "            lab = nb.load(f'{lab_path}{folder1}')\n",
    "            lab_arr = lab.get_fdata() # labels matrix\n",
    "            voxel_size = lab.header.get_zooms() # voxel size\n",
    "            ima = nb.load(f'{img_path}{folder1}')\n",
    "            ima_arr = ima.get_fdata() # image matrix\n",
    "        elif METHOD=='manual':\n",
    "            lab = nb.load(f'{lab_path}{folder1}')\n",
    "            lab_arr = lab.get_fdata() # labels matrix\n",
    "            voxel_size = lab.header.get_zooms() # voxel size\n",
    "            ima = nb.load(f'{img_path}{folder1}')\n",
    "            ima_arr = ima.get_fdata() # image matrix\n",
    "        elif METHOD=='nnunet':\n",
    "            # lab = nb.load(f'{lab_path}AEye_{name_subject[i]}.nii.gz')  # for non-labeled dataset\n",
    "            lab = nb.load(f'{lab_path}{folder1}')  # for new manual annotations\n",
    "            lab_arr = lab.get_fdata() # labels matrix\n",
    "            voxel_size = lab.header.get_zooms() # voxel size\n",
    "            ima = nb.load(f'{img_path}{folder1}')\n",
    "            ima_arr = ima.get_fdata() # image matrix\n",
    "\n",
    "        # Label masks\n",
    "        lens = (lab_arr == 1).astype(int)\n",
    "        globe = (lab_arr == 2).astype(int)\n",
    "        eyeball = (np.logical_or(lab_arr == 1, lab_arr == 2)).astype(int)\n",
    "        nerve = (lab_arr == 3).astype(int)\n",
    "        lens_vox = np.count_nonzero(lens)\n",
    "        globe_vox = np.count_nonzero(globe)\n",
    "        eyeball_vox = np.count_nonzero(eyeball)\n",
    "        nerve_vox = np.count_nonzero(nerve)\n",
    "        if METHOD=='nnunet':  # only take one half of the image (to capture the right eye)\n",
    "            # Split along X-axis into two halves\n",
    "            x_mid = lab_arr.shape[0] // 2  # Midpoint of X-axis\n",
    "            y_mid = lab_arr.shape[1] // 2  # Midpoint of Y-axis\n",
    "            # Select the top-left region in the axial view\n",
    "            lens_r = lens[x_mid:, y_mid:, :]  # Retain all Z-axis, select second halves of X and Y axes\n",
    "            globe_r = globe[x_mid:, y_mid:, :]  # Same for globe\n",
    "            eyeball_r = eyeball[x_mid:, y_mid:, :]  # Same for eyeball\n",
    "            nerve_r = nerve[x_mid:, y_mid:, :]  # Same for nerve\n",
    "            # Recalculate voxel counts for the right half\n",
    "            lens_vox = np.count_nonzero(lens_r)\n",
    "            globe_vox = np.count_nonzero(globe_r)\n",
    "            eyeball_vox = np.count_nonzero(eyeball_r)\n",
    "            nerve_vox = np.count_nonzero(nerve_r)\n",
    "\n",
    "        # Condition 1: there must be lens, nerve or globe segmentation voxels\n",
    "        if lens_vox==0 or nerve_vox==0 or globe_vox==0:\n",
    "            axial_length_total[i] = 0\n",
    "            outliers_list_1.append(name_subject[i]) # outliers with no lens segmented\n",
    "            outliers_list1_clean = list(dict.fromkeys(outliers_list_2)) # to remove duplicates from list\n",
    "            print(f'Final axial length: {axial_length_total[i]}mm \\n')\n",
    "        else:\n",
    "            # LENS CENTROID\n",
    "            properties_lens = regionprops(lens) # properties\n",
    "            com_lens = properties_lens[0].centroid # centroid\n",
    "            if METHOD=='nnunet':\n",
    "                properties_lens = regionprops(lens_r) # properties\n",
    "                com_lens = properties_lens[0].centroid # centroid\n",
    "            print(f'com_lens: {np.around(com_lens)}')\n",
    "\n",
    "            # EYEBALL CENTROID\n",
    "            properties_eyeball = regionprops(eyeball) # properties\n",
    "            com_eyeball = (np.rint(properties_eyeball[0].centroid)).astype(int) # centroid\n",
    "            if METHOD=='nnunet':\n",
    "                properties_eyeball = regionprops(eyeball_r)\n",
    "                com_eyeball = properties_eyeball[0].centroid # centroid\n",
    "            print(f'com_eyeball: {np.around(com_eyeball)}')\n",
    "\n",
    "            # OPTIC NERVE CENTROID\n",
    "            properties_nerve = regionprops(nerve) # properties\n",
    "            com_nerve = (np.rint(properties_nerve[0].centroid)).astype(int) # centroid\n",
    "            if METHOD=='nnunet':\n",
    "                properties_nerve = regionprops(nerve_r)\n",
    "                com_nerve = properties_nerve[0].centroid\n",
    "            print(f'com_nerve: {np.around(com_nerve)}')\n",
    "\n",
    "            # Compute best centroid\n",
    "            if com_lens[2] == com_nerve[2]:\n",
    "                slices = np.array([com_lens[2]])\n",
    "            else:\n",
    "                if com_lens[2] < com_nerve[2]:\n",
    "                    slices = np.arange(com_lens[2], com_nerve[2]+1, 1, dtype=int)\n",
    "                else: \n",
    "                    slices = np.arange(com_lens[2], com_nerve[2]-1, -1, dtype=int)\n",
    "            print(f'slices: {slices} \\n')\n",
    "\n",
    "            # Save variables per slice\n",
    "            axial_length_slices = np.zeros(len(slices))\n",
    "            lens_vox = np.zeros(len(slices))\n",
    "            globe_vox = np.zeros(len(slices))\n",
    "            nerve_vox = np.zeros(len(slices))\n",
    "            int_fat_vox = np.zeros(len(slices))\n",
    "\n",
    "            # Compute axial length per slice\n",
    "            p = -1\n",
    "            for s in slices:\n",
    "                p+=1\n",
    "                lens_vox[p] = np.count_nonzero(lab_arr[:, :, s]==1)\n",
    "                globe_vox[p] = np.count_nonzero(lab_arr[:, :, s]==2)\n",
    "                nerve_vox[p] = np.count_nonzero(lab_arr[:, :, s]==3)\n",
    "                int_fat_vox[p] = np.count_nonzero(lab_arr[:, :, s]==4)\n",
    "                print(f'slice {s} -- voxels -- lens: {int(lens_vox[p])} | nerve: {int(nerve_vox[p])} | int fat: {int(int_fat_vox[p])} | globe: {int(globe_vox[p])}')\n",
    "\n",
    "                # Label masks\n",
    "                lens_2d = (lab_arr[:, :, s]==1)*1\n",
    "                globe_2d = (lab_arr[:, :, s]==2)*1\n",
    "                nerve_2d = (lab_arr[:, :, s]==3)*1\n",
    "                int_fat_2d = (lab_arr[:, :, s]==4)*1\n",
    "                lens_vox_2d = np.count_nonzero(lens_2d)\n",
    "                globe_vox_2d = np.count_nonzero(globe_2d)\n",
    "                nerve_vox_2d = np.count_nonzero(nerve_2d)\n",
    "                int_fat_vox_2d = np.count_nonzero(int_fat_2d)\n",
    "                if METHOD=='nnunet':\n",
    "                    lens_2d_q = lens_2d[int(np.around(lens_2d.shape[0]/2)):lens_2d.shape[0], int(np.around(lens_2d.shape[1]/2)):lens_2d.shape[1]] # quadrant right eye\n",
    "                    globe_2d_q = globe_2d[int(np.around(globe_2d.shape[0]/2)):globe_2d.shape[0], int(np.around(globe_2d.shape[1]/2)):globe_2d.shape[1]] # quadrant right eye\n",
    "                    nerve_2d_q = nerve_2d[int(np.around(nerve_2d.shape[0]/2)):nerve_2d.shape[0], int(np.around(nerve_2d.shape[1]/2)):nerve_2d.shape[1]] # quadrant right eye\n",
    "                    int_fat_2d_q = int_fat_2d[int(np.around(int_fat_2d.shape[0]/2)):int_fat_2d.shape[0], int(np.around(int_fat_2d.shape[1]/2)):int_fat_2d.shape[1]] # quadrant right eye\n",
    "                    lens_vox_2d = np.count_nonzero(lens_2d_q)\n",
    "                    globe_vox_2d = np.count_nonzero(globe_2d_q)\n",
    "                    nerve_vox_2d = np.count_nonzero(nerve_2d_q)\n",
    "                    int_fat_vox_2d = np.count_nonzero(int_fat_2d_q)\n",
    "                    print(f'```````````right eye: lens: {lens_vox_2d} | nerve: {nerve_vox_2d} | int fat: {int_fat_vox_2d} | globe: {globe_vox_2d}\\n')\n",
    "\n",
    "                # Centroid of the lens in the 2D slice in axial view\n",
    "                # Condition 2: check first if there are pixels of all the main structures to extract the axial length\n",
    "                if lens_vox_2d > 0 and nerve_vox_2d > 0 and int_fat_vox_2d > 0 and globe_vox_2d > 0:\n",
    "                    properties_lens = regionprops(lens_2d)\n",
    "                    com_lens = properties_lens[0].centroid # centroid\n",
    "                    if METHOD=='nnunet':\n",
    "                        properties_lens = regionprops(lens_2d_q) # upper right quadrant\n",
    "                        com_lens = properties_lens[0].centroid # centroid\n",
    "                        com_lens = [com_lens[0]+lens_2d.shape[0]/2, com_lens[1]+lens_2d.shape[1]/2] # centroid amplified to entire image\n",
    "                    print(f'com_lens: {np.around(com_lens)}')\n",
    "                    axis_minor_lens = properties_lens[0].axis_minor_length # minor axis\n",
    "                    axis_major_lens = properties_lens[0].axis_major_length # major axis\n",
    "                    print(f'axis minor lens = {axis_minor_lens} \\naxis major lens = {axis_major_lens}')\n",
    "\n",
    "                    # Get the 2nd point of the orthogonal in the lens\n",
    "                    x0_lens = com_lens[0]\n",
    "                    y0_lens = com_lens[1]\n",
    "                    x1_lens = x0_lens\n",
    "                    y1_lens = y0_lens - 1 # orthogonal to the globe (following y axis: orientation y=1, z=slice)\n",
    "\n",
    "                    # Parametric equation of the line between (x0, y0) and (x1, y1)\n",
    "                    n_points = int(np.ceil(math.dist([0,0,0], [lab_arr.shape[0], lab_arr.shape[1], lab_arr.shape[2]]))) # max number of points of a line in the image square\n",
    "                    t = np.linspace(-int(n_points), int(n_points), n_points*10) # resolution of the line\n",
    "                    line_x = (x0_lens - x1_lens)*t + x0_lens\n",
    "                    line_y = (y0_lens - y1_lens)*t + y0_lens\n",
    "\n",
    "                    # Line in image space (square)\n",
    "                    line = np.zeros([lab_arr.shape[0], lab_arr.shape[1]])\n",
    "                    for j in range(len(t)):\n",
    "                        if 0<=round(line_x[j])<lab_arr.shape[0] and 0<=round(line_y[j])<lab_arr.shape[1] :\n",
    "                            line[int(np.around(line_x[j])), int(np.around(line_y[j]))] = 1\n",
    "                    print(f'Number of points of the line in the image space: {np.count_nonzero(line)}')\n",
    "\n",
    "                    # Intersections and extreme points\n",
    "                    # Lens\n",
    "                    # inter_lens = np.logical_and(lens[:, :, int(np.around(com_eyeball[2]))], line)*1 # int format, intersection points in lens with line\n",
    "                    inter_lens = np.logical_and(lens_2d, line)*1 # int format, intersection points in lens with line\n",
    "                    print(f'Number of intersection points in lens: {np.count_nonzero(inter_lens)}')\n",
    "\n",
    "                    # Condition 3: there must be intersection points between the line and the lens\n",
    "                    if np.count_nonzero(inter_lens) > 0:\n",
    "                        inter_coord_lens = np.argwhere(inter_lens==1)\n",
    "                        extreme_inter_lens = inter_coord_lens[np.argmax(inter_coord_lens[:,1])]\n",
    "                        print(f'Lens extreme intersection point: {extreme_inter_lens}')\n",
    "                        # Globe\n",
    "                        # inter_globe = np.logical_and(globe[:, :, int(np.around(com_eyeball[2]))], line)*1 # int format, intersection points in globe with line\n",
    "                        inter_globe = np.logical_and(globe_2d, line)*1 # int format, intersection points in globe with line\n",
    "                        print(f'Number of instersection points in globe: {np.count_nonzero(inter_globe)}')\n",
    "                        inter_coord_globe = np.argwhere(inter_globe==1)\n",
    "                        extreme_inter_globe = inter_coord_globe[np.argmin(inter_coord_globe[:,1])]\n",
    "                        print(f'Globe extreme intersection point: {extreme_inter_globe}')\n",
    "\n",
    "                        # Line to compute the intensities gradient\n",
    "                        sobel = True\n",
    "                        if sobel:\n",
    "                            edges = filters.sobel(ima_arr[:, :, s]) # Sobel\n",
    "                            grad_arr = edges[extreme_inter_lens[0], extreme_inter_lens[1]:lab_arr.shape[1]-1] # Sobel\n",
    "                        else:\n",
    "                            grad_arr = ima_arr[extreme_inter_lens[0], extreme_inter_lens[1]:lab_arr.shape[1]-1, s]\n",
    "                        print(f'grad_arr = {grad_arr}')\n",
    "                        vox = 0\n",
    "                        n_drops = 0\n",
    "                        if len(grad_arr) >= 1:\n",
    "                            for v in range(len(grad_arr)):\n",
    "                                next_val = grad_arr[v+1] if v != len(grad_arr)-1 else 3000\n",
    "                                diff = next_val - grad_arr[v]\n",
    "                                if sobel:\n",
    "                                    threshold = 96.17 # np.mean(arr_diff) for 100 cases (95.28 for 1210 cases)\n",
    "                                    if diff < threshold: # Sobel\n",
    "                                        if n_drops > 0: # 2nd drop\n",
    "                                            arr_diff.append(diff)\n",
    "                                            break\n",
    "                                        else:\n",
    "                                            vox+=1\n",
    "                                            n_drops+=1\n",
    "                                    else:\n",
    "                                        vox+=1\n",
    "                                else:\n",
    "                                    threshold = 179.92 # np.mean(arr_diff) for 100 cases\n",
    "                                    if (diff > 0 and next_val >= 100) or (diff <= threshold and diff >= 0):\n",
    "                                        vox += 1\n",
    "                                    else:\n",
    "                                        arr_diff.append(diff)\n",
    "                                        break\n",
    "                        print(f'Number of mm to add to the axial length (due to the cornea) = {vox}')\n",
    "\n",
    "                        # Extra distance 2 (towards globe direction until reaching intraconal fat)\n",
    "                        grad_arr2 = lab_arr[extreme_inter_globe[0], np.arange(extreme_inter_globe[1]-1, 0, -1), s]\n",
    "                        print(f'grad_arr2 = {grad_arr2}')\n",
    "                        vox2 = 0\n",
    "                        if len(grad_arr2) > 0 and np.count_nonzero(grad_arr2 == 4) > 0 :\n",
    "                            for w in range(len(grad_arr2)):\n",
    "                                if grad_arr2[w] != 4:\n",
    "                                    vox2 +=1\n",
    "                                else:\n",
    "                                    break\n",
    "                        print(f'Number of mm to add to the axial length (due to intraconal fat) = {vox2}')\n",
    "\n",
    "                        # Axial length\n",
    "                        axial_length = (extreme_inter_lens[1] + voxel_size[1]/2) - (extreme_inter_globe[1] - voxel_size[1]/2) + vox + vox2 # distance between the center of the two points, we have to add +0.5mm for each point to be the actual extremes\n",
    "                        print(f'Axial length = {axial_length} mm \\n')\n",
    "\n",
    "                        # Condition 4: axial length must be greater than 0\n",
    "                        if axial_length > 0:\n",
    "                            # axial_length_total[i] = axial_length\n",
    "                            axial_length_slices[p] = axial_length # if best slice\n",
    "\n",
    "                            # PLOT\n",
    "                            plot_bool = 1\n",
    "                            if plot_bool:\n",
    "                                k = 1 # aspect ratio\n",
    "                                fig, ax = plt.subplots(1, 3, figsize=(16*k, 9*k))\n",
    "                                fig.patch.set_facecolor('white')\n",
    "                                if METHOD == 'atlas':\n",
    "                                    method = 'ATLAS'\n",
    "                                elif METHOD == 'nnunet':\n",
    "                                    method = 'nnUNet'\n",
    "                                fig.suptitle(f'Automatic axial length extraction. Method: {method}. Subject: {name_subject[i]}. Slice: {s}. Axial length: {axial_length} mm.')\n",
    "\n",
    "                                # Legend\n",
    "                                legend_elements = [Line2D([0], [0], color='y', lw=2, label=f'Axial length'),\n",
    "                                    Line2D([], [], color='y', label='Extreme points', marker='+', markersize=5, linestyle='None'),\n",
    "                                    Line2D([], [], color='b', label='Lens centroid', marker='+', markersize=5, linestyle='None'),\n",
    "                                    Line2D([], [], color='c', label='Added distance', marker='+', markersize=5, linestyle='None')]\n",
    "                                fig.legend(handles=legend_elements, loc='lower right')\n",
    "                                fig.tight_layout()\n",
    "\n",
    "                                # Lens centroid and line\n",
    "                                ax[0].set_title('Original image')\n",
    "                                ax[0].imshow(ima_arr[:, :, s].T, origin='lower', cmap='gist_gray', interpolation='none')\n",
    "                                # Note the inverted coordinates because plt uses (x, y) while NumPy uses (row, column)\n",
    "                                ax[0].plot(int(np.around(com_lens[0])), int(np.around(com_lens[1])), '+b', markersize=10)\n",
    "                                ax[0].plot(extreme_inter_lens[0], extreme_inter_lens[1]+voxel_size[1]/2, '+y', markersize=10)\n",
    "                                ax[0].plot(extreme_inter_globe[0], extreme_inter_globe[1]-voxel_size[1]/2, '+y', markersize=10)\n",
    "                                ax[0].plot((extreme_inter_lens[0], extreme_inter_globe[0]), (extreme_inter_lens[1]+voxel_size[1]/2, extreme_inter_globe[1]-voxel_size[1]/2), '-y', linewidth=1)\n",
    "                                # Extra distance\n",
    "                                ax[0].plot(extreme_inter_lens[0], extreme_inter_lens[1]+voxel_size[1]/2+vox, '+c', markersize=10)\n",
    "                                ax[0].plot((extreme_inter_lens[0], extreme_inter_lens[0]), (extreme_inter_lens[1]+voxel_size[1]/2+vox, extreme_inter_lens[1]), '-c', linewidth=1)\n",
    "                                # Extra distance 2\n",
    "                                ax[0].plot(extreme_inter_globe[0], extreme_inter_globe[1]-voxel_size[1]/2-vox2, '+c', markersize=10)\n",
    "                                ax[0].plot((extreme_inter_globe[0], extreme_inter_globe[0]), (extreme_inter_globe[1]-voxel_size[1]/2-vox2, extreme_inter_globe[1]), '-c', linewidth=1)\n",
    "\n",
    "                                # Eyeball\n",
    "                                ax[1].set_title('Original image + labels')\n",
    "                                ax[1].imshow(ima_arr[:, :, s].T, origin='lower', cmap='gist_gray', interpolation='none')\n",
    "                                lens_mask = np.ma.masked_where(lens[:, :, s] == 0, lens[:, :, s])\n",
    "                                globe_mask = np.ma.masked_where(globe[:, :, s] == 0, globe[:, :, s])\n",
    "                                nerve_mask = np.ma.masked_where(nerve[:, :, s] == 0, nerve[:, :, s])\n",
    "                                int_fat_mask = np.ma.masked_where(int_fat_2d[:, :] == 0, int_fat_2d[:, :])\n",
    "                                palette_lens = colors.ListedColormap(['red'])\n",
    "                                palette_globe = colors.ListedColormap(['lime'])\n",
    "                                palette_nerve = colors.ListedColormap(['blue'])\n",
    "                                palette_int_fat = colors.ListedColormap(['yellow'])\n",
    "                                ax[1].imshow(lens_mask.T, origin='lower', interpolation='none', alpha=0.4, cmap=palette_lens)\n",
    "                                ax[1].imshow(globe_mask.T, origin='lower', interpolation='none', alpha=0.4, cmap=palette_globe)\n",
    "                                ax[1].imshow(nerve_mask.T, origin='lower', interpolation='none', alpha=0.4, cmap=palette_nerve)\n",
    "                                ax[1].imshow(int_fat_mask.T, origin='lower', interpolation='none', alpha=0.4, cmap=palette_int_fat)\n",
    "                                # Note the inverted coordinates because plt uses (x, y) while NumPy uses (row, column)\n",
    "                                ax[1].plot(int(np.around(com_lens[0])), int(np.around(com_lens[1])), '+b', markersize=10)\n",
    "                                ax[1].plot(extreme_inter_lens[0], extreme_inter_lens[1]+voxel_size[1]/2, '+y', markersize=10)\n",
    "                                ax[1].plot(extreme_inter_globe[0], extreme_inter_globe[1]-voxel_size[1]/2, '+y', markersize=10)\n",
    "                                ax[1].plot((extreme_inter_lens[0], extreme_inter_globe[0]), (extreme_inter_lens[1]+voxel_size[1]/2, extreme_inter_globe[1]-voxel_size[1]/2), '-y', linewidth=1)\n",
    "                                # Extra distance\n",
    "                                ax[1].plot(extreme_inter_lens[0], extreme_inter_lens[1]+voxel_size[1]/2+vox, '+c', markersize=10)\n",
    "                                ax[1].plot((extreme_inter_lens[0], extreme_inter_lens[0]), (extreme_inter_lens[1]+voxel_size[1]/2+vox, extreme_inter_lens[1]), '-c', linewidth=1)\n",
    "                                # Extra distance 2\n",
    "                                ax[1].plot(extreme_inter_globe[0], extreme_inter_globe[1]-voxel_size[1]/2-vox2, '+c', markersize=10)\n",
    "                                ax[1].plot((extreme_inter_globe[0], extreme_inter_globe[0]), (extreme_inter_globe[1]-voxel_size[1]/2-vox2, extreme_inter_globe[1]), '-c', linewidth=1)\n",
    "\n",
    "                                # Sobel\n",
    "                                edges = filters.sobel(ima_arr[:, :, s].T)\n",
    "                                ax[2].set_title('Sobel filter')\n",
    "                                ax[2].imshow(edges, origin='lower', cmap='gist_gray', interpolation='none')\n",
    "                                lens_mask = np.ma.masked_where(lens[:, :, s] == 0, lens[:, :, s])\n",
    "                                globe_mask = np.ma.masked_where(globe[:, :, s] == 0, globe[:, :, s])\n",
    "                                nerve_mask = np.ma.masked_where(nerve[:, :, s] == 0, nerve[:, :, s])\n",
    "                                palette_lens = colors.ListedColormap(['red'])\n",
    "                                palette_globe = colors.ListedColormap(['lime'])\n",
    "                                palette_nerve = colors.ListedColormap(['blue'])\n",
    "                                # ax[2].imshow(lens_mask.T, origin='lower', interpolation='none', alpha=0.4, cmap=palette_lens)\n",
    "                                # ax[2].imshow(globe_mask.T, origin='lower', interpolation='none', alpha=0.4, cmap=palette_globe)\n",
    "                                # ax[2].imshow(nerve_mask.T, origin='lower', interpolation='none', alpha=0.4, cmap=palette_nerve)\n",
    "                                # Note the inverted coordinates because plt uses (x, y) while NumPy uses (row, column)\n",
    "                                # ax[2].plot(int(np.around(com_lens[0])), int(np.around(com_lens[1])), '+b', markersize=10)\n",
    "                                # ax[2].plot(extreme_inter_lens[0], extreme_inter_lens[1]+voxel_size[1]/2, '+y', markersize=10)\n",
    "                                # ax[2].plot(extreme_inter_globe[0], extreme_inter_globe[1]-voxel_size[1]/2, '+y', markersize=10)\n",
    "                                ax[2].plot((extreme_inter_lens[0], extreme_inter_globe[0]), (extreme_inter_lens[1]+voxel_size[1]/2, extreme_inter_globe[1]-voxel_size[1]/2), '-y', linewidth=1)\n",
    "                                # Extra distance\n",
    "                                ax[2].plot(extreme_inter_lens[0], extreme_inter_lens[1]+voxel_size[1]/2+vox, '+c', markersize=10)\n",
    "                                ax[2].plot((extreme_inter_lens[0], extreme_inter_lens[0]), (extreme_inter_lens[1]+voxel_size[1]/2+vox, extreme_inter_lens[1]), '-c', linewidth=1)\n",
    "                                # Extra distance 2\n",
    "                                ax[2].plot((extreme_inter_globe[0], extreme_inter_globe[0]), (extreme_inter_globe[1]-voxel_size[1]/2-vox2, extreme_inter_globe[1]), '-c', linewidth=1)\n",
    "                                ax[2].plot(extreme_inter_globe[0], extreme_inter_globe[1]-voxel_size[1]/2-vox2, '+c', markersize=10)\n",
    "\n",
    "                                plt.savefig(f'{output_path}examples/{name_subject[i]}_{s}.png')\n",
    "                                \n",
    "                                plt.show\n",
    "\n",
    "\n",
    "                            # break # comment to extract all the slices in the range lens centroid - optic nerve centroid\n",
    "\n",
    "                        else:\n",
    "                            axial_length_slices[p] = 0\n",
    "                            outliers_list_4.append(name_subject[i])\n",
    "                            outliers_list_4_clean = list(dict.fromkeys(outliers_list_4)) # to remove duplicates from list\n",
    "                            outliers_dict_4[str(name_subject[i])] = s\n",
    "\n",
    "                    else:\n",
    "                        axial_length_slices[p] = 0\n",
    "                        outliers_list_3.append(name_subject[i])\n",
    "                        outliers_list_3_clean = list(dict.fromkeys(outliers_list_3)) # to remove duplicates from list\n",
    "                        outliers_dict_3[str(name_subject[i])] = s\n",
    "                        # break\n",
    "\n",
    "                else:\n",
    "                    axial_length_slices[p] = 0\n",
    "                    outliers_list_2.append(name_subject[i])\n",
    "                    outliers_list2_clean = list(dict.fromkeys(outliers_list_2)) # to remove duplicates from list\n",
    "                    outliers_dict_2[str(name_subject[i])] = s\n",
    "\n",
    "            # Selecting best slice (not really good - better to allow clinician to select by him/herself)\n",
    "            if np.count_nonzero(axial_length_slices) == 0:\n",
    "                axial_length_total[i] = 0\n",
    "            else:\n",
    "                indexes_valid_slices = np.argwhere(axial_length_slices != 0)\n",
    "                valid_slices = slices[indexes_valid_slices]\n",
    "                filtered_lens_vox = lens_vox[axial_length_slices != 0] # from the lens values, the ones with axial length != 0\n",
    "                filtered_nerve_vox = nerve_vox[axial_length_slices != 0] # from the nerve values, the ones with axial length != 0\n",
    "                ratio = np.zeros(len(valid_slices)) # they all have the same length\n",
    "                for k in range(len(valid_slices)): # they all have the same length\n",
    "                    ratio[k] = filtered_lens_vox[k] / filtered_nerve_vox[k] if filtered_lens_vox[k] < filtered_nerve_vox[k] else filtered_nerve_vox[k] / filtered_lens_vox[k]\n",
    "                best_slice_inner = np.argmax(ratio) # best slice is the one with higher ratio lens-nerve\n",
    "                best_slice_outer = valid_slices[best_slice_inner] # the real slice number\n",
    "                index_best_slice = np.argwhere(slices == best_slice_outer)\n",
    "                print(f'--------- BEST SLICE: {best_slice_outer} ---------')\n",
    "                axial_length_total[i] = axial_length_slices[index_best_slice]\n",
    "            print(f'\\nFinal axial length: {axial_length_total[i]}mm')\n",
    "\n",
    "            print(f'\\n')\n",
    "\n",
    "        i+=1\n",
    "        if i==10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(np.mean(arr_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save values into .csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "if METHOD=='atlas': filename = 'axial_length_atlas_cond4_best_slice_N43.csv'\n",
    "elif METHOD=='dl': filename = 'axial_length_dl_outliers.csv'\n",
    "elif METHOD=='manual': filename = 'axial_length_manual_cond4_best_slice.csv'\n",
    "elif METHOD=='nnunet': filename = 'axial_length_nnunet_cond4_best_slice_N43.csv'\n",
    "\n",
    "column_names = ['Subject','axial_length']\n",
    "vals = np.array([name_subject, axial_length_total])\n",
    "vals = vals.T\n",
    "with open(output_path + filename, 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(column_names)\n",
    "    writer.writerows(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read values from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# reference axial length (mean and std)\n",
    "ref_axl_mean = 24.1 # mm. Range: (21.6-27). See https://bmcophthalmol.biomedcentral.com/articles/10.1186/s12886-022-02289-y\n",
    "ref_axl_std = 1.2 # mm\n",
    "\n",
    "# csv's\n",
    "csv_manual = '/mnt/sda1/Repos/a-eye/Output/axial_length/manual/axial_length_manual_cond4_best_slice.csv'\n",
    "csv_reg = '/mnt/sda1/Repos/a-eye/Output/axial_length/atlas/axial_length_atlas_cond4_best_slice_N43.csv'\n",
    "csv_dl = '/mnt/sda1/Repos/a-eye/Output/axial_length/nnunet/axial_length_nnunet_cond4_best_slice_N43.csv' # nnUNet\n",
    "csv_metadata = '/mnt/sda1/Repos/a-eye/Output/metadata/sub_metadata_all.csv' # metadata (for sex, etc.)\n",
    "\n",
    "# dataframes\n",
    "df_axial_manual = pd.read_csv(csv_manual)\n",
    "df_axial_reg = pd.read_csv(csv_reg)\n",
    "df_axial_dl = pd.read_csv(csv_dl)\n",
    "df_md_all = pd.read_csv(csv_metadata, dtype={'Subject': str})\n",
    "\n",
    "# Trim the strings of the first column ('Subject') removing everything after the first '.'\n",
    "df_axial_manual['Subject'] = df_axial_manual['Subject'].str.split('.').str[0]\n",
    "df_axial_reg['Subject'] = df_axial_reg['Subject'].str.split('.').str[0]\n",
    "df_axial_dl['Subject'] = df_axial_dl['Subject'].str.split('.').str[0]\n",
    "\n",
    "# Merge dataframes\n",
    "df_al = df_md_all.merge(df_axial_manual, on='Subject', how='inner', suffixes=('', '_manual'))\n",
    "df_al = df_al.merge(df_axial_reg, on='Subject', how='left', suffixes=('', '_reg'))\n",
    "df_al = df_al.merge(df_axial_dl, on='Subject', how='left', suffixes=('', '_dl'))\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_al.rename(columns={'axial_length': 'al_manual', 'axial_length_reg': 'al_atlas', 'axial_length_dl': 'al_nnunet'}, inplace=True)\n",
    "\n",
    "# Remove rows with no manual, atlas, or nnunet axial_length values\n",
    "df_al.dropna(subset=['al_manual', 'al_atlas', 'al_nnunet'], inplace=True)\n",
    "\n",
    "# Save the dataframe as a CSV file\n",
    "df_al.to_csv('/mnt/sda1/Repos/a-eye/Output/axial_length/combined_axial_lengths.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing excluded subjects from qc1, qc2, qc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc1 = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc1.csv\")\n",
    "qc2 = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc2_atlas_nnunet.csv\")\n",
    "qc3_vol = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc3_vol.csv\")\n",
    "qc3_al = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc3_al.csv\")\n",
    "\n",
    "# concat qc1, qc2 and qc3\n",
    "qc_list = pd.concat([qc1, qc2, qc3_vol, qc3_al], ignore_index=True)\n",
    "\n",
    "# subdataframe of pd_volumes_reg and pd_volumes_nnunet removing the subjects that are in qc1 and qc2\n",
    "df_axial_reg = df_axial_reg[~df_axial_reg['Subject'].isin(qc_list['subject'])]\n",
    "df_axial_reg = df_axial_reg.reset_index(drop=True)\n",
    "df_axial_dl = df_axial_dl[~df_axial_dl['Subject'].isin(qc_list['subject'])]\n",
    "df_axial_dl = df_axial_dl.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from .csv\n",
    "axl_manual = np.array([df_axial_manual[\"axial_length\"]])\n",
    "axl_manual = axl_manual[axl_manual != 0]\n",
    "axl_reg = np.array([df_axial_reg[\"axial_length\"]])\n",
    "axl_reg = axl_reg[axl_reg != 0]\n",
    "axl_dl = np.array([df_axial_dl[\"axial_length\"]])\n",
    "axl_dl = axl_dl[axl_dl != 0]\n",
    "print(f'MANUAL: axial length mean: {np.around(np.mean(axl_manual), 1)}, std: {np.std(axl_manual)}\\n\\\n",
    "ATLAS-BASED: axial length mean: {np.around(np.mean(axl_reg), 1)}, std: {np.std(axl_reg)}\\n\\\n",
    "nnUNet: axial length mean: {np.around(np.mean(axl_dl), 1)}, std: {np.std(axl_dl)}')\n",
    "\n",
    "# Subplots\n",
    "k = 1 # Figure size to preserve ratio 16:9\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "fig.suptitle('Axial length (mm)')\n",
    "fig.patch.set_facecolor('white')\n",
    "fix_axis = 1\n",
    "x_axis = [-2, 2]\n",
    "y_axis = [15, 30]\n",
    "fig.tight_layout(pad=2)\n",
    "\n",
    "# Legend\n",
    "legend_elements = [Line2D([0], [0], color='red', lw=2, label=f'Previous studies \\nmean: {ref_axl_mean} \\nstd: {ref_axl_std}'), Line2D([0], [0], color='limegreen', lw=2, label='Mean')]\n",
    "fig.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "# # Manual\n",
    "# ax[0].set_title(f'MANUAL (35 subs) - mean: {np.around(np.mean(axl_manual), decimals=1)}, std: {np.around(np.std(axl_manual), decimals=1)}')\n",
    "# graph_lens = sns.boxplot(axl_manual, ax=ax[0])\n",
    "# # graph_lens = sns.swarmplot(axl_manual, ax=ax[0])\n",
    "# graph_lens.axhline(ref_axl_mean, color='red')\n",
    "# # ax[0].set_xticklabels()\n",
    "# if fix_axis:\n",
    "#     # ax[0].set_xlim(x_axis)\n",
    "#     ax[0].set_ylim(y_axis)\n",
    "\n",
    "meanlineprops = dict(linestyle=\"-\", linewidth=2, color=\"limegreen\")\n",
    "meanpointprops = {\"marker\":\"x\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\", \"markersize\":\"10\"}\n",
    "\n",
    "# ATLAS-based atlas\n",
    "ax[0].set_title(f'ATLAS ({len(axl_reg)} subs) - mean: {np.around(np.mean(axl_reg), decimals=1)}, std: {np.around(np.std(axl_reg), decimals=1)}')\n",
    "graph_lens = sns.boxplot(data=axl_reg, ax=ax[0], meanprops=meanlineprops, showmeans=True, meanline=True)\n",
    "ax[0].set(xticklabels=[])\n",
    "ax[0].tick_params(bottom=False)\n",
    "graph_lens.axhline(ref_axl_mean, color='red')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax[0].set_ylim(y_axis)\n",
    "\n",
    "# Deep learning --> nnUNet\n",
    "ax[1].set_title(f'nnUNet ({len(axl_dl)} subs) - mean: {np.around(np.mean(axl_dl), decimals=1)}, std: {np.around(np.std(axl_dl), decimals=1)}')\n",
    "graph_lens = sns.boxplot(data=axl_dl, ax=ax[1], meanprops=meanlineprops, showmeans=True, meanline=True)\n",
    "ax[1].set_xticklabels([])\n",
    "ax[1].tick_params(bottom=False)\n",
    "graph_lens.axhline(ref_axl_mean, color='red')\n",
    "if fix_axis:\n",
    "    # ax[2].set_xlim(x_axis)\n",
    "    ax[1].set_ylim(y_axis)\n",
    "\n",
    "plt.show\n",
    "\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/axial_length/axial_length_atlas_vs_nnunet_qc1_qc2_qc3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot new manual annotations' values (GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual\n",
    "axl_manual = np.array([df_al[\"al_manual\"]])\n",
    "axl_manual_clean = axl_manual[axl_manual != 0]\n",
    "ref_acl_mean = np.around(np.mean(axl_manual_clean), 1) # only from non-zero values\n",
    "ref_acl_std = np.std(axl_manual_clean) # only from non-zero values\n",
    "\n",
    "# atlas\n",
    "axl_reg = np.array([df_al[\"al_atlas\"]])\n",
    "# axl_reg = axl_reg[axl_reg != 0]\n",
    "\n",
    "# nnunet\n",
    "axl_dl = np.array([df_al[\"al_nnunet\"]])\n",
    "# axl_dl = axl_dl[axl_dl != 0]\n",
    "\n",
    "print(f'MANUAL: axial length mean: {np.around(np.mean(axl_manual), 1)}, std: {np.std(axl_manual)}\\n\\\n",
    "ATLAS-BASED: axial length mean: {np.around(np.mean(axl_reg), 1)}, std: {np.std(axl_reg)}\\n\\\n",
    "nnUNet: axial length mean: {np.around(np.mean(axl_dl), 1)}, std: {np.std(axl_dl)}')\n",
    "\n",
    "# Subplots\n",
    "k = 1 # Figure size to preserve ratio 16:9\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "fig.suptitle('Axial length (mm)')\n",
    "fig.patch.set_facecolor('white')\n",
    "fix_axis = 1\n",
    "x_axis = [-2, 2]\n",
    "y_axis = [15, 30]\n",
    "fig.tight_layout(pad=2)\n",
    "\n",
    "# Legend\n",
    "legend_elements = [Line2D([0], [0], color='red', lw=2, label=f'Previous studies \\nmean: {ref_axl_mean} \\nstd: {ref_axl_std}'), Line2D([0], [0], color='limegreen', lw=2, label='Mean')]\n",
    "fig.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "# # Manual\n",
    "# ax[0].set_title(f'MANUAL (35 subs) - mean: {np.around(np.mean(axl_manual), decimals=1)}, std: {np.around(np.std(axl_manual), decimals=1)}')\n",
    "# graph_lens = sns.boxplot(axl_manual, ax=ax[0])\n",
    "# # graph_lens = sns.swarmplot(axl_manual, ax=ax[0])\n",
    "# graph_lens.axhline(ref_axl_mean, color='red')\n",
    "# # ax[0].set_xticklabels()\n",
    "# if fix_axis:\n",
    "#     # ax[0].set_xlim(x_axis)\n",
    "#     ax[0].set_ylim(y_axis)\n",
    "\n",
    "meanlineprops = dict(linestyle=\"-\", linewidth=2, color=\"limegreen\")\n",
    "meanpointprops = {\"marker\":\"x\", \"markerfacecolor\":\"black\", \"markeredgecolor\":\"black\", \"markersize\":\"10\"}\n",
    "\n",
    "# ATLAS-based atlas\n",
    "ax[0].set_title(f'ATLAS ({axl_reg.shape[1]} subs) - mean: {np.around(np.mean(axl_reg), decimals=1)}, std: {np.around(np.std(axl_reg), decimals=1)}')\n",
    "graph_lens = sns.boxplot(data=axl_reg, ax=ax[0], meanprops=meanlineprops, showmeans=True, meanline=True)\n",
    "ax[0].set(xticklabels=[])\n",
    "ax[0].tick_params(bottom=False)\n",
    "graph_lens.axhline(ref_axl_mean, color='red')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax[0].set_ylim(y_axis)\n",
    "\n",
    "# Deep learning --> nnUNet\n",
    "ax[1].set_title(f'nnUNet ({axl_dl.shape[1]} subs) - mean: {np.around(np.mean(axl_dl), decimals=1)}, std: {np.around(np.std(axl_dl), decimals=1)}')\n",
    "graph_lens = sns.boxplot(data=axl_dl, ax=ax[1], meanprops=meanlineprops, showmeans=True, meanline=True)\n",
    "ax[1].set_xticklabels([])\n",
    "ax[1].tick_params(bottom=False)\n",
    "graph_lens.axhline(ref_axl_mean, color='red')\n",
    "if fix_axis:\n",
    "    # ax[2].set_xlim(x_axis)\n",
    "    ax[1].set_ylim(y_axis)\n",
    "\n",
    "plt.show\n",
    "\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/axial_length/axial_length_atlas_vs_nnunet_qc1_qc2_qc3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# csv_file = pd.read_csv('/mnt/sda1/Repos/a-eye/Output/axial_length/atlas/axial_length_reg_cond4_best_slice.csv')\n",
    "csv_file = pd.read_csv('/mnt/sda1/Repos/a-eye/Output/axial_length/nnunet/axial_length_nnunet_cond4_best_slice.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove qc1, qc2, qc3_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc1 = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc1.csv\")\n",
    "qc2 = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_atlas_nnunet.csv\")\n",
    "qc3_vol = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_vol.csv\")\n",
    "\n",
    "# concat qc1, qc2 and qc3_vol\n",
    "qc_list = pd.concat([qc1, qc2, qc3_vol], ignore_index=True)\n",
    "\n",
    "# subdataframe of pd_volumes_reg and pd_volumes_nnunet removing the subjects that are in qc1 and qc2\n",
    "csv_file = csv_file[~csv_file['Subject'].isin(qc_list['subject'])]\n",
    "csv_file = csv_file.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk test for normality for each column of csv_file\n",
    "from scipy.stats import shapiro\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for i in range(1, len(csv_file.columns)):\n",
    "    stat, p = shapiro(csv_file.iloc[:,i])\n",
    "    print(f'{csv_file.columns[i]}: Statistics={stat}, p={p}')\n",
    "    alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('Sample does not look Gaussian (reject H0)')\n",
    "    # histogram plot\n",
    "    plt.hist(csv_file.iloc[:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_df1 = pd.DataFrame(columns=['Column', 'Outlier Subject'])\n",
    "bounds_df = pd.DataFrame(columns=['Column', 'Lower Bound', 'Upper Bound']) # dataFrame for bounds\n",
    "\n",
    "# Calculate the IQR for each column\n",
    "Q1 = csv_file.quantile(0.25)\n",
    "Q3 = csv_file.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Find the outliers for each column\n",
    "for column in csv_file.columns[1:]:\n",
    "    lower_bound = Q1[column] - 1.5 * IQR[column]\n",
    "    upper_bound = Q3[column] + 1.5 * IQR[column]\n",
    "\n",
    "    # Append bounds to the bounds_df DataFrame\n",
    "    new_row = pd.DataFrame({'Column': [column], 'Lower Bound': [lower_bound], 'Upper Bound': [upper_bound]})\n",
    "    bounds_df = pd.concat([bounds_df, new_row], ignore_index=True)\n",
    "\n",
    "    column_outliers = csv_file[(csv_file[column] < lower_bound) | (csv_file[column] > upper_bound)]\n",
    "    new_row = pd.DataFrame({'Column': [column], 'Outlier Subject': [column_outliers['Subject'].values]})\n",
    "    outliers_df1 = pd.concat([outliers_df1, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new DataFrame with the same structure as csv_file but filled with False\n",
    "outliers_df2 = pd.DataFrame(False, index=csv_file.index, columns=csv_file.columns)\n",
    "\n",
    "# Copy the 'Subject' column from csv_file to outliers_df\n",
    "outliers_df2['Subject'] = csv_file['Subject']\n",
    "\n",
    "# Calculate the IQR for each column excluding 'Subject'\n",
    "Q1 = csv_file.drop('Subject', axis=1).quantile(0.25)\n",
    "Q3 = csv_file.drop('Subject', axis=1).quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Find the outliers for each column excluding 'Subject'\n",
    "for column in csv_file.columns:\n",
    "    if column != 'Subject':\n",
    "        lower_bound = Q1[column] - 1.5 * IQR[column]\n",
    "        upper_bound = Q3[column] + 1.5 * IQR[column]\n",
    "        # Update outliers_df with True for outliers\n",
    "        outliers_df2[column] = (csv_file[column] < lower_bound) | (csv_file[column] > upper_bound)\n",
    "\n",
    "# Replace all False values with ''\n",
    "outliers_df2 = outliers_df2.replace(False, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# make a list of 'Outlier Subject' without duplicates in row and column\n",
    "outliers_list = []\n",
    "for i in range(len(outliers_df1)):\n",
    "    for j in range(len(outliers_df1.iloc[i,1])):\n",
    "        outliers_list.append(outliers_df1.iloc[i,1][j])\n",
    "\n",
    "# Count the occurrences of each outlier\n",
    "outliers_counter = Counter(outliers_list)\n",
    "\n",
    "# Keep only the outliers that appear more than once\n",
    "outliers_list = [item for item, count in outliers_counter.items() if count > 0] # there's only one column\n",
    "\n",
    "outliers_list = list(sorted(set(outliers_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reports to look at - removing subjects already analysed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_aux = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/df_aux.csv\")\n",
    "\n",
    "qc2_atlas = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_atlas.xlsx\")\n",
    "qc2_nnunet = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_nnunet.xlsx\")\n",
    "qc2_atlas_nnunet = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_atlas_nnunet.xlsx\")\n",
    "qc3_vol_atlas = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_vol_atlas.xlsx\")\n",
    "qc3_vol_nnunet = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_vol_nnunet.xlsx\")\n",
    "qc3_al_atlas = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_al_atlas.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat qc2_atlas, qc2_nnunet, qc2_atlas_nnunet, qc3_vol_atlas and qc3_vol_nnunet\n",
    "analysed_subjects = pd.concat([qc2_atlas, qc2_nnunet, qc2_atlas_nnunet, qc3_vol_atlas, qc3_vol_nnunet, qc3_al_atlas], ignore_index=True)\n",
    "# remove duplicates\n",
    "analysed_subjects = analysed_subjects.drop_duplicates(subset=['subject'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdataframe of df_aux with the outliers_list\n",
    "outliers_reports_df = df_aux[df_aux['subject'].isin(outliers_list)]\n",
    "# add 'my_rate' column to outliers_reports_df\n",
    "outliers_reports_df.loc[:, 'my_rate'] = 0.0\n",
    "# order outliers_reports_df by 'report'\n",
    "outliers_reports_df = outliers_reports_df.sort_values(by=['report'])\n",
    "# add column 'comments' to outliers_reports_df\n",
    "outliers_reports_df.loc[:, 'comments'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge outliers_reports_df and analysed_subjects keeping 'report', 'bids', 'subject' from outliers_reports_df and 'my_rate' and 'comments' from analysed_subjects\n",
    "outliers_reports_df = pd.merge(outliers_reports_df, analysed_subjects, on=['report', 'bids', 'subject'], how='left')\n",
    "# remove duplicates\n",
    "outliers_reports_df = outliers_reports_df.drop_duplicates(subset=['report'], keep='first')\n",
    "# remove columns 'my_rate_x' and 'comments_x'\n",
    "outliers_reports_df = outliers_reports_df.drop(columns=['my_rate_x', 'comments_x'])\n",
    "# rename columns 'my_rate_y' and 'comments_y'\n",
    "outliers_reports_df = outliers_reports_df.rename(columns={'my_rate_y': 'my_rate', 'comments_y': 'comments'})\n",
    "# save to excel\n",
    "# outliers_reports_df.to_excel('/home/jaimebarranco/Desktop/MRI-QC/qc3_al_nnunet.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy reports that appear in outliers_reports from /home/jaimebarranco/Desktop/MRI-QC/fetal/fetalqc_non-labeled-dataset to /home/jaimebarranco/Downloads/reports \n",
    "import shutil\n",
    "import os\n",
    "\n",
    "reports_folder = '/home/jaimebarranco/Downloads/reports/'\n",
    "# create reports folder if it doesn't exist\n",
    "if not os.path.exists(reports_folder):\n",
    "    os.makedirs(reports_folder)\n",
    "else:\n",
    "    # remove content from reports folder\n",
    "    for filename in os.listdir(reports_folder):\n",
    "        file_path = os.path.join(reports_folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "filtered_reports_df = outliers_reports_df[outliers_reports_df['my_rate'] != 1]\n",
    "\n",
    "for report in filtered_reports_df['report']:\n",
    "    src = f'/home/jaimebarranco/Desktop/MRI-QC/fetal/fetalqc_non-labeled-dataset/{report}_report.html'\n",
    "    dst = f'/home/jaimebarranco/Downloads/reports/{report}_report.html'\n",
    "    shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge filtered_reports_df (subject) and csv_file (Subject)\n",
    "filtered_reports_df = pd.merge(filtered_reports_df, csv_file, left_on=['subject'], right_on=['Subject'], how='left')\n",
    "# remove 'Subject' column\n",
    "filtered_reports_df = filtered_reports_df.drop(columns=['Subject'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint outliers (atlas + nnunet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc3_al_atlas = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_al_atlas.xlsx\")\n",
    "qc3_al_nnunet = pd.read_excel(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_al_nnunet.xlsx\")\n",
    "\n",
    "# joint dataframes\n",
    "qc3 = pd.concat([qc3_al_atlas, qc3_al_nnunet], ignore_index=True)\n",
    "# keep only the rows with '0' in my_rate column\n",
    "qc3 = qc3[qc3['my_rate'] == 0]\n",
    "# save it to .csv\n",
    "qc3.to_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_al.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axial length grouped by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "csv_metadata = '/mnt/sda1/Repos/a-eye/Output/metadata/sub_metadata.csv'\n",
    "METHOD = 'nnunet' # atlas, dl, manual, nnunet\n",
    "if METHOD == 'atlas':\n",
    "    csv_axial_length = '/mnt/sda1/Repos/a-eye/Output/axial_length/atlas/axial_length_reg_cond4_best_slice.csv'\n",
    "elif METHOD == 'nnunet':\n",
    "    csv_axial_length = '/mnt/sda1/Repos/a-eye/Output/axial_length/nnunet/axial_length_nnunet_cond4_best_slice.csv'\n",
    "\n",
    "# Pandas read csv\n",
    "pd_metadata = pd.read_csv(csv_metadata)\n",
    "pd_axial_length = pd.read_csv(csv_axial_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove subjects from qc1, qc2, qc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc1 = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc1.csv\")\n",
    "qc2 = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc2_atlas_nnunet.csv\")\n",
    "qc3_vol = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc3_vol.csv\")\n",
    "qc3_al = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc3_al.csv\")\n",
    "\n",
    "# concat qc1, qc2 and qc3\n",
    "qc_list = pd.concat([qc1, qc2, qc3_vol, qc3_al], ignore_index=True)\n",
    "\n",
    "# subdataframe of pd_volumes_reg and pd_volumes_nnunet removing the subjects that are in qc1 and qc2\n",
    "pd_axial_length = pd_axial_length[~pd_axial_length['Subject'].isin(qc_list['subject'])]\n",
    "pd_axial_length = pd_axial_length.reset_index(drop=True)\n",
    "pd_metadata = pd_metadata[~pd_metadata['Subject'].isin(qc_list['subject'])]\n",
    "pd_metadata = pd_metadata.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "df = pd.concat([pd_metadata, pd_axial_length['axial_length']], axis=1, verify_integrity=True)\n",
    "\n",
    "# Group by sex\n",
    "sex_group = df.groupby([\"Sex\"])\n",
    "\n",
    "# Male group\n",
    "male_group = sex_group.get_group(\"M\").dropna()\n",
    "axial_length_male = np.array([male_group[\"axial_length\"]])\n",
    "axial_length_male = axial_length_male[axial_length_male != 0] # remove zeros\n",
    "mean_al_male = np.around(np.mean(axial_length_male), decimals=1)\n",
    "std_al_male = np.around(np.std(axial_length_male), decimals=1)\n",
    "print(f'- MALES: \\n   Axial length: {mean_al_male} +- {std_al_male} mm')\n",
    "\n",
    "# Female group\n",
    "female_group = sex_group.get_group(\"F\").dropna()\n",
    "axial_length_female = np.array([female_group[\"axial_length\"]])\n",
    "axial_length_female = axial_length_female[axial_length_female != 0] # remove zeros\n",
    "mean_al_female = np.around(np.mean(axial_length_female), decimals=1)\n",
    "std_al_female = np.around(np.std(axial_length_female), decimals=1)\n",
    "print(f'- FEMALES: \\n   Axial length: {mean_al_female} +- {std_al_female} mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "# Literature (PlosOne Sönke). See https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6366780/\n",
    "ref_axl_male_mean = 23.4 # mm\n",
    "ref_axl_male_std = 0.8 # mm\n",
    "ref_axl_female_mean = 22.8 # mm\n",
    "ref_axl_female_std = 0.9 # mm\n",
    "\n",
    "# Subplots\n",
    "k = 1 # Figure size to preserve ratio 16:9\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "if METHOD == 'atlas':\n",
    "    method = 'ATLAS'\n",
    "elif METHOD == 'nnunet':\n",
    "    method = 'nnUNet'\n",
    "fig.suptitle(f'Axial length grouped by sex (mm) - {method}')\n",
    "fig.patch.set_facecolor('white')\n",
    "fix_axis = 1\n",
    "x_axis = [-2, 2]\n",
    "y_axis = [15,30]\n",
    "\n",
    "# Legend\n",
    "legend_elements = [Line2D([0], [0], color='red', lw=2, label=f'Previous studies \\n Male: {ref_axl_male_mean} +- {ref_axl_male_std} mm \\\n",
    "    \\n Female: {ref_axl_female_mean} +- {ref_axl_female_std} mm'),\n",
    "    Line2D([0], [0], color='lime', lw=2, label='Mean')]\n",
    "fig.legend(handles=legend_elements, loc='lower right')\n",
    "meanlineprops = dict(linestyle=\"solid\", linewidth=1.5, color=\"lime\")\n",
    "meanpointprops = {\"marker\":\"D\", \"markerfacecolor\":\"lime\", \"markeredgecolor\":\"black\", \"markersize\":\"10\"}\n",
    "\n",
    "# MALES\n",
    "ax[0].set_title(f'MALES ({len(axial_length_male)} subs) - mean: {mean_al_male}, std: {std_al_male}')\n",
    "graph_lens = sns.boxplot(data=axial_length_male, ax=ax[0], meanprops=meanlineprops, meanline=True, showmeans=True)\n",
    "graph_lens.axhline(ref_axl_male_mean, color='red')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax[0].set_ylim(y_axis)\n",
    "\n",
    "# FEMALES\n",
    "ax[1].set_title(f'FEMALES ({len(axial_length_female)} subs) - mean: {mean_al_female}, std: {std_al_female}')\n",
    "graph_lens = sns.boxplot(data=axial_length_female, ax=ax[1], meanprops=meanlineprops, meanline=True, showmeans=True)\n",
    "graph_lens.axhline(ref_axl_female_mean, color='red')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax[1].set_ylim(y_axis)\n",
    "\n",
    "plt.show\n",
    "\n",
    "# plt.savefig(f'/mnt/sda1/Repos/a-eye/Output/axial_length/axial_length_{method}_cond4_best_slice_qc1_qc2_qc3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "csv_metadata = '/mnt/sda1/Repos/a-eye/Output/metadata/sub_metadata_non_labeled_dataset.csv'\n",
    "csv_al_atlas = '/mnt/sda1/Repos/a-eye/Output/axial_length/atlas/axial_length_reg_cond4_best_slice.csv'\n",
    "csv_al_nnunet = '/mnt/sda1/Repos/a-eye/Output/axial_length/nnunet/axial_length_nnunet_cond4_best_slice.csv'\n",
    "csv_al_manual = '/mnt/sda1/Repos/a-eye/Output/axial_length/manual/axial_length_manual_cond4_best_slice.csv'\n",
    "\n",
    "# Pandas read csv\n",
    "pd_metadata = pd.read_csv(csv_metadata)\n",
    "pd_al_atlas = pd.read_csv(csv_al_atlas)\n",
    "pd_al_nnunet = pd.read_csv(csv_al_nnunet)\n",
    "pd_al_manual = pd.read_csv(csv_al_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove subjects from qc1, qc2, qc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc1 = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc1.csv\")\n",
    "qc2 = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc2_atlas_nnunet.csv\")\n",
    "qc3_vol = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc3_vol.csv\")\n",
    "qc3_al = pd.read_csv(\"/mnt/sda1/Repos/a-eye/Output/mri_qc/qc3_al.csv\")\n",
    "\n",
    "# concat qc1, qc2 and qc3\n",
    "qc_list = pd.concat([qc1, qc2, qc3_vol, qc3_al], ignore_index=True)\n",
    "\n",
    "# subdataframe of pd_volumes_reg and pd_volumes_nnunet removing the subjects that are in qc1 and qc2\n",
    "pd_metadata = pd_metadata[~pd_metadata['Subject'].isin(qc_list['subject'])]\n",
    "pd_metadata = pd_metadata.reset_index(drop=True)\n",
    "pd_al_atlas = pd_al_atlas[~pd_al_atlas['Subject'].isin(qc_list['subject'])]\n",
    "pd_al_atlas = pd_al_atlas.reset_index(drop=True)\n",
    "pd_al_nnunet = pd_al_nnunet[~pd_al_nnunet['Subject'].isin(qc_list['subject'])]\n",
    "pd_al_nnunet = pd_al_nnunet.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mixing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat pd_metadata and pd_al_atlas\n",
    "df_atlas = pd.concat([pd_metadata, pd_al_atlas['axial_length']], axis=1, verify_integrity=True)\n",
    "# add column method with values 'atlas'\n",
    "df_atlas['method'] = 'atlas'\n",
    "\n",
    "# concat pd_metadata and pd_al_nnunet\n",
    "df_nnunet = pd.concat([pd_metadata, pd_al_nnunet['axial_length']], axis=1, verify_integrity=True)\n",
    "# add column method with values 'nnunet'\n",
    "df_nnunet['method'] = 'nnunet'\n",
    "\n",
    "# Ensure that if a subject has axial_length 0 in atlas or nnunet, it is removed from both\n",
    "subjects_to_remove_atlas = df_atlas[df_atlas['axial_length'] == 0]['Subject']\n",
    "subjects_to_remove_nnunet = df_nnunet[df_nnunet['axial_length'] == 0]['Subject']\n",
    "subjects_to_remove = pd.concat([subjects_to_remove_atlas, subjects_to_remove_nnunet]).unique()\n",
    "\n",
    "df_atlas = df_atlas[~df_atlas['Subject'].isin(subjects_to_remove)]\n",
    "df_nnunet = df_nnunet[~df_nnunet['Subject'].isin(subjects_to_remove)]\n",
    "\n",
    "# Concat the cleaned dataframes\n",
    "df = pd.concat([df_atlas, df_nnunet], axis=0, ignore_index=True)\n",
    "\n",
    "# Print the number of rows for atlas and nnunet cases\n",
    "num_rows_atlas = df[df['method'] == 'atlas'].shape[0]\n",
    "num_rows_nnunet = df[df['method'] == 'nnunet'].shape[0]\n",
    "\n",
    "print(f'Number of rows for atlas cases: {num_rows_atlas}')\n",
    "print(f'Number of rows for nnunet cases: {num_rows_nnunet}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouped by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Groups by sex\n",
    "atlas_group = df_atlas.groupby([\"Sex\"])\n",
    "nnunet_group = df_nnunet.groupby([\"Sex\"])\n",
    "\n",
    "# atlas male group\n",
    "atlas_male = atlas_group.get_group(\"M\").dropna()\n",
    "al_atlas_male = np.array([atlas_male[\"axial_length\"]])\n",
    "# al_atlas_male = al_atlas_male[al_atlas_male != 0]\n",
    "\n",
    "# atlas female group\n",
    "atlas_female = atlas_group.get_group(\"F\").dropna()\n",
    "al_atlas_female = np.array([atlas_female[\"axial_length\"]])\n",
    "# al_atlas_female = al_atlas_female[al_atlas_female != 0]\n",
    "\n",
    "# nnunet male group\n",
    "nnunet_male = nnunet_group.get_group(\"M\").dropna()\n",
    "al_nnunet_male = np.array([nnunet_male[\"axial_length\"]])\n",
    "# al_nnunet_male = al_nnunet_male[al_nnunet_male != 0]\n",
    "\n",
    "# nnunet female group\n",
    "nnunet_female = nnunet_group.get_group(\"F\").dropna()\n",
    "al_nnunet_female = np.array([nnunet_female[\"axial_length\"]])\n",
    "# al_nnunet_female = al_nnunet_female[al_nnunet_female != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and std for nnunet and atlas for male and female\n",
    "\n",
    "# nnunet male\n",
    "mean_nnunet_male = round(np.mean(al_nnunet_male), 1)\n",
    "std_nnunet_male = round(np.std(al_nnunet_male), 1)\n",
    "\n",
    "# nnunet female\n",
    "mean_nnunet_female = round(nnunet_female['axial_length'].mean(), 1)\n",
    "std_nnunet_female = round(nnunet_female['axial_length'].std(), 1)\n",
    "\n",
    "# atlas male\n",
    "mean_atlas_male = round(atlas_male['axial_length'].mean(), 1)\n",
    "std_atlas_male = round(atlas_male['axial_length'].std(), 1)\n",
    "\n",
    "# atlas female\n",
    "mean_atlas_female = round(atlas_female['axial_length'].mean(), 1)\n",
    "std_atlas_female = round(atlas_female['axial_length'].std(), 1)\n",
    "\n",
    "print(f'nnunet male: mean = {mean_nnunet_male}, std = {std_nnunet_male}')\n",
    "print(f'nnunet female: mean = {mean_nnunet_female}, std = {std_nnunet_female}')\n",
    "print(f'atlas male: mean = {mean_atlas_male}, std = {std_atlas_male}')\n",
    "print(f'atlas female: mean = {mean_atlas_female}, std = {std_atlas_female}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Figure\n",
    "plt.figure(figsize=(10,8), facecolor='white')\n",
    "plt.suptitle(f'Axial Length (in mm) per Method and Sex. Total = {len(df_nnunet)} subjects')\n",
    "# plt.patch.set_facecolor('white')\n",
    "\n",
    "# Legend\n",
    "# legend_elements = [Line2D([0], [0], color='lightskyblue', lw=2, label='ATLAS'),\n",
    "#     Line2D([0], [0], color='steelblue', lw=2, label='nnUNet')]\n",
    "# fig.legend(handles=legend_elements, loc='upper right')\n",
    "plt.tight_layout(pad=3)\n",
    "\n",
    "# Color\n",
    "# palette with 'lightskyblue' and 'steelblue'\n",
    "palette = sns.color_palette(\"Blues\", 2)\n",
    "\n",
    "# violin\n",
    "sns.violinplot(data=df, x=\"method\", y=\"axial_length\", hue='Sex' , split=True, inner='quart', palette=palette)\n",
    "plt.ylabel('Axial length (mm)')\n",
    "plt.yticks(np.arange(-5, 35, 2))\n",
    "# number of males and females\n",
    "plt.text(0.5, df_atlas['axial_length'].min(), f'Male: {len(df_atlas[df_atlas[\"Sex\"] == \"M\"])} ', ha='right', va='bottom', fontsize=10)\n",
    "plt.text(0.5, df_atlas['axial_length'].min(), f' Female: {len(df_atlas[df_atlas[\"Sex\"] == \"F\"])}', ha='left', va='bottom', fontsize=10)\n",
    "# median values\n",
    "# plt.text(0, int(np.median(al_atlas_male)), f'{int(np.median(al_atlas_male))}', ha='right', va='bottom', fontsize=10)\n",
    "# plt.text(0, int(np.median(al_atlas_female)), f'{int(np.median(al_atlas_female))}', ha='left', va='bottom', fontsize=10)\n",
    "# plt.text(1, int(np.median(al_nnunet_male)), f'{int(np.median(al_nnunet_male))}', ha='right', va='bottom', fontsize=10)\n",
    "# plt.text(1, int(np.median(al_nnunet_female)), f'{int(np.median(al_nnunet_female))}', ha='left', va='bottom', fontsize=10)\n",
    "\n",
    "# plt.savefig(f'/mnt/sda1/Repos/a-eye/Output/axial_length/atlas_nnunet_sex_qc1_qc2_qc3.png', dpi=300)#, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count zero values in axial length per method and sex\n",
    "zero_counts = df[df['axial_length'] == 0].groupby(['method', 'Sex']).size().reset_index(name='count')\n",
    "zero_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per method individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Figure\n",
    "plt.figure(figsize=(8,10), facecolor='white')\n",
    "plt.suptitle(f'Axial Length (in mm) per Sex. Total = {len(df_nnunet)} subjects')\n",
    "# plt.patch.set_facecolor('white')\n",
    "\n",
    "# Legend\n",
    "# legend_elements = [Line2D([0], [0], color='lightskyblue', lw=2, label='ATLAS'),\n",
    "#     Line2D([0], [0], color='steelblue', lw=2, label='nnUNet')]\n",
    "# fig.legend(handles=legend_elements, loc='upper right')\n",
    "plt.tight_layout(pad=3)\n",
    "\n",
    "# Color\n",
    "# palette with 'lightskyblue' and 'steelblue'\n",
    "palette = sns.color_palette(\"Blues\", 2)\n",
    "\n",
    "# violin\n",
    "sns.violinplot(data=df_nnunet, x=\"method\", y=\"axial_length\", hue='Sex' , split=True, inner='quart', palette=palette)\n",
    "plt.ylabel('Axial length (mm)')\n",
    "plt.yticks(np.arange(-5, 35, 2))\n",
    "# number of males and females\n",
    "plt.text(0, 9, f'Male: {len(df_atlas[df_atlas[\"Sex\"] == \"M\"])} ', ha='right', va='bottom', fontsize=10)\n",
    "plt.text(0, 9, f' Female: {len(df_atlas[df_atlas[\"Sex\"] == \"F\"])}', ha='left', va='bottom', fontsize=10)\n",
    "# median values\n",
    "# plt.text(0, int(np.median(al_atlas_male)), f'{int(np.median(al_atlas_male))}', ha='right', va='bottom', fontsize=10)\n",
    "# plt.text(0, int(np.median(al_atlas_female)), f'{int(np.median(al_atlas_female))}', ha='left', va='bottom', fontsize=10)\n",
    "plt.text(0, int(np.median(al_nnunet_male)), f'{int(np.median(al_nnunet_male))}', ha='right', va='bottom', fontsize=10)\n",
    "plt.text(0, int(np.median(al_nnunet_female)), f'{int(np.median(al_nnunet_female))}', ha='left', va='bottom', fontsize=10)\n",
    "\n",
    "# plt.savefig(f'/mnt/sda1/Repos/a-eye/Output/axial_length/atlas_nnunet_sex_qc1_qc2_qc3.png', dpi=300)#, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plots per method vs GT -  new manual annotations (N=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load and preprocess the data\n",
    "df_al = pd.read_csv('/mnt/sda1/Repos/a-eye/Output/axial_length/combined_axial_lengths.csv', dtype={'Subject': str})\n",
    "df_al = df_al[(df_al['al_manual'] != 0) & (df_al['al_atlas'] != 0) & (df_al['al_nnunet'] != 0)]  # Remove zero values\n",
    "\n",
    "# Calculate statistics\n",
    "stats_atlas = {\n",
    "    'mean': df_al['al_atlas'].mean(),\n",
    "    'std': df_al['al_atlas'].std(),\n",
    "    'correlation': df_al['al_manual'].corr(df_al['al_atlas'])\n",
    "}\n",
    "\n",
    "stats_nnunet = {\n",
    "    'mean': df_al['al_nnunet'].mean(),\n",
    "    'std': df_al['al_nnunet'].std(),\n",
    "    'correlation': df_al['al_manual'].corr(df_al['al_nnunet'])\n",
    "}\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Subplot for Atlas\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(data=df_al, x='al_manual', y='al_atlas', hue='Sex', palette='Blues', s=80)\n",
    "plt.plot([df_al['al_manual'].min(), df_al['al_manual'].max()],\n",
    "         [df_al['al_manual'].min(), df_al['al_manual'].max()], 'r--', label='Line of Equality')\n",
    "plt.title(f'Manual vs. Atlas (n={len(df_al)})')\n",
    "plt.xlabel('Manual Axial Length (mm)')\n",
    "plt.ylabel('Atlas Axial Length (mm)')\n",
    "plt.legend(loc='upper left')  # Move legend to avoid overlap\n",
    "\n",
    "# Add statistics as text (bottom-right corner)\n",
    "plt.text(0.95, 0.05, \n",
    "         f\"Mean: {stats_atlas['mean']:.2f}\\nStd: {stats_atlas['std']:.2f}\\nPearson Corr: {stats_atlas['correlation']:.2f}\",\n",
    "         transform=plt.gca().transAxes, fontsize=10, verticalalignment='bottom', horizontalalignment='right',\n",
    "         bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "# Subplot for nnUNet\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(data=df_al, x='al_manual', y='al_nnunet', hue='Sex', palette='Greens', s=80)\n",
    "plt.plot([df_al['al_manual'].min(), df_al['al_manual'].max()],\n",
    "         [df_al['al_manual'].min(), df_al['al_manual'].max()], 'r--', label='Line of Equality')\n",
    "plt.title(f'Manual vs. nnUNet (n={len(df_al)})')\n",
    "plt.xlabel('Manual Axial Length (mm)')\n",
    "plt.ylabel('nnUNet Axial Length (mm)')\n",
    "plt.legend(loc='upper left')  # Move legend to avoid overlap\n",
    "\n",
    "# Add statistics as text (bottom-right corner)\n",
    "plt.text(0.95, 0.05, \n",
    "         f\"Mean: {stats_nnunet['mean']:.2f}\\nStd: {stats_nnunet['std']:.2f}\\nPearson Corr: {stats_nnunet['correlation']:.2f}\",\n",
    "         transform=plt.gca().transAxes, fontsize=10, verticalalignment='bottom', horizontalalignment='right',\n",
    "         bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "# Save the figure\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/axial_length/manual_vs_atlas_nnunet_scatter.png', dpi=300)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       al_manual   al_atlas  al_nnunet\n",
      "count  41.000000  41.000000  41.000000\n",
      "mean   22.853659  21.878049  22.926829\n",
      "std     1.824294   1.144446   1.522994\n",
      "min    19.000000  20.000000  20.000000\n",
      "25%    22.000000  21.000000  22.000000\n",
      "50%    23.000000  22.000000  23.000000\n",
      "75%    24.000000  22.000000  24.000000\n",
      "max    28.000000  25.000000  28.000000\n"
     ]
    }
   ],
   "source": [
    "print(df_al[['al_manual', 'al_atlas', 'al_nnunet']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volumetry and BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate csv's and group by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "\n",
    "# Concat csv in one dataframe (metadata + volumes per label)\n",
    "\n",
    "METHOD = 'nnunet' # atlas, nnunet\n",
    "\n",
    "# Paths\n",
    "csv_metadata = '/mnt/sda1/Repos/a-eye/Output/metadata/sub_metadata.csv'\n",
    "if METHOD == 'atlas':\n",
    "    csv_volumes = '/mnt/sda1/Repos/a-eye/Output/volumetry/atlas/volumes_reg.csv'\n",
    "elif METHOD == 'nnunet':\n",
    "    csv_volumes = '/mnt/sda1/Repos/a-eye/Output/volumetry/nnunet/volumes_nnunet_right_eye.csv'\n",
    "\n",
    "# Pandas read csv\n",
    "pd_metadata = pd.read_csv(csv_metadata)\n",
    "pd_volumes= pd.read_csv(csv_volumes)\n",
    "\n",
    "# remove vol_total column (only if nnunet!!)\n",
    "pd_volumes = pd_volumes.drop(columns=['vol_total'])\n",
    "\n",
    "# Dataframe\n",
    "df = pd.concat([pd_metadata, pd_volumes.iloc[:, 1:]], axis=1, verify_integrity=True)\n",
    "\n",
    "# Group by sex (males and females)\n",
    "sex_group = df.groupby([\"Sex\"], dropna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove excluded subjects qc1, qc2, qc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qc1 = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc1.csv\")\n",
    "qc2 = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc2_atlas_nnunet.csv\")\n",
    "qc3_vol = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_vol.csv\")\n",
    "qc3_al = pd.read_csv(\"/home/jaimebarranco/Desktop/MRI-QC/qc3_al.csv\")\n",
    "\n",
    "# concat qc1, qc2 and qc3\n",
    "qc_list = pd.concat([qc1, qc2, qc3_vol, qc3_al], ignore_index=True)\n",
    "\n",
    "# subdataframe of pd_volumes_reg and pd_volumes_nnunet removing the subjects that are in qc1 and qc2\n",
    "df = df[~df['Subject'].isin(qc_list['subject'])]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Group by sex (males and females)\n",
    "sex_group = df.groupby([\"Sex\"], dropna=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male group\n",
    "male_group = sex_group.get_group(\"M\").dropna() \n",
    "\n",
    "# Volumes\n",
    "volume_lens_male = np.array([male_group[\"vol_lens\"]])\n",
    "volume_globe_male = np.array([male_group[\"vol_globe\"]])\n",
    "volume_nerve_male = np.array([male_group[\"vol_nerve\"]])\n",
    "volume_int_fat_male = np.array([male_group[\"vol_int_fat\"]])\n",
    "volume_ext_fat_male = np.array([male_group[\"vol_ext_fat\"]])\n",
    "volume_lat_mus_male = np.array([male_group[\"vol_lat_mus\"]])\n",
    "volume_med_mus_male = np.array([male_group[\"vol_med_mus\"]])\n",
    "volume_inf_mus_male = np.array([male_group[\"vol_inf_mus\"]])\n",
    "volume_sup_mus_male = np.array([male_group[\"vol_sup_mus\"]])\n",
    "\n",
    "# BMI\n",
    "bmi_male = np.array([male_group[\"BMI\"]])\n",
    "\n",
    "# Plot: boxplot (2x5), x_axis=BMI, y_axis=volume per label\n",
    "\n",
    "# Figure\n",
    "k = 1.5 # Figure size to preserve ratio 16:9\n",
    "fig1, ax1 = plt.subplots(2, 5, figsize=(16*k, 9*k))\n",
    "fig1.suptitle(f'BMI vs Volumes ({male_group.shape[0]} males)')\n",
    "fig1.patch.set_facecolor('white')\n",
    "fix_axis = False\n",
    "x_axis = [-2, 2]\n",
    "y_axis = [19,31]\n",
    "\n",
    "# Lens\n",
    "ax1[0][0].set_title(f'Lens')\n",
    "plot1 = sns.scatterplot(x=bmi_male.flatten(), y=volume_lens_male.flatten(), ax=ax1[0][0])\n",
    "ax1[0][0].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][0].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][0].set_ylim(y_axis)\n",
    "\n",
    "# Globe\n",
    "ax1[0][1].set_title(f'Globe')\n",
    "plot2 = sns.scatterplot(x=bmi_male.flatten(), y=volume_globe_male.flatten(), ax=ax1[0][1])\n",
    "ax1[0][1].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][1].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][1].set_ylim(y_axis)\n",
    "\n",
    "# Optic nerve\n",
    "ax1[0][2].set_title(f'Optic nerve')\n",
    "plot3 = sns.scatterplot(x=bmi_male.flatten(), y=volume_nerve_male.flatten(), ax=ax1[0][2])\n",
    "ax1[0][2].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][2].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][2].set_ylim(y_axis)\n",
    "\n",
    "# Intraconal fat\n",
    "ax1[0][3].set_title(f'Intraconal fat')\n",
    "plot4 = sns.scatterplot(x=bmi_male.flatten(), y=volume_int_fat_male.flatten(), ax=ax1[0][3])\n",
    "ax1[0][3].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][3].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][3].set_ylim(y_axis)\n",
    "\n",
    "# Extraconal fat\n",
    "ax1[0][4].set_title(f'Extraconal fat')\n",
    "plot5 = sns.scatterplot(x=bmi_male.flatten(), y=volume_ext_fat_male.flatten(), ax=ax1[0][4])\n",
    "ax1[0][4].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][4].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][4].set_ylim(y_axis)\n",
    "\n",
    "# Lateral rectus muscle\n",
    "ax1[1][0].set_title(f'Lateral rectus muscle')\n",
    "plot6 = sns.scatterplot(x=bmi_male.flatten(), y=volume_lat_mus_male.flatten(), ax=ax1[1][0])\n",
    "ax1[1][0].set_xlabel('BMI (kg/m²)')\n",
    "ax1[1][0].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][0].set_ylim(y_axis)\n",
    "\n",
    "# Medial rectus muscle\n",
    "ax1[1][1].set_title(f'Medial rectus muscle')\n",
    "plot7 = sns.scatterplot(x=bmi_male.flatten(), y=volume_med_mus_male.flatten(), ax=ax1[1][1])\n",
    "ax1[1][1].set_xlabel('BMI (kg/m²)')\n",
    "ax1[1][1].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][1].set_ylim(y_axis)\n",
    "\n",
    "# Inferior rectus muscle\n",
    "ax1[1][2].set_title(f'Inferior rectus muscle')\n",
    "plot8 = sns.scatterplot(x=bmi_male.flatten(), y=volume_inf_mus_male.flatten(), ax=ax1[1][2])\n",
    "ax1[1][2].set_xlabel('BMI (kg/m²)')\n",
    "ax1[1][2].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][2].set_ylim(y_axis)\n",
    "\n",
    "# Superior rectus muscle\n",
    "ax1[1][3].set_title(f'Superior rectus muscle')\n",
    "plot8 = sns.scatterplot(x=bmi_male.flatten(), y=volume_sup_mus_male.flatten(), ax=ax1[1][3])\n",
    "ax1[1][3].set_xlabel('BMI (kg/m²)')\n",
    "ax1[1][3].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][3].set_ylim(y_axis)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/bmi_vs_volume_males_norm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female group\n",
    "female_group = sex_group.get_group(\"F\").dropna() \n",
    "\n",
    "# Volumes\n",
    "volume_lens_female = np.array([female_group[\"vol_lens\"]])\n",
    "volume_globe_female = np.array([female_group[\"vol_globe\"]])\n",
    "volume_nerve_female = np.array([female_group[\"vol_nerve\"]])\n",
    "volume_int_fat_female = np.array([female_group[\"vol_int_fat\"]])\n",
    "volume_ext_fat_female = np.array([female_group[\"vol_ext_fat\"]])\n",
    "volume_lat_mus_female = np.array([female_group[\"vol_lat_mus\"]])\n",
    "volume_med_mus_female = np.array([female_group[\"vol_med_mus\"]])\n",
    "volume_inf_mus_female = np.array([female_group[\"vol_inf_mus\"]])\n",
    "volume_sup_mus_female = np.array([female_group[\"vol_sup_mus\"]])\n",
    "\n",
    "# BMI\n",
    "bmi_female = np.array([female_group[\"BMI\"]])\n",
    "\n",
    "# Plot: boxplot (2x5), x_axis=BMI, y_axis=volume per label\n",
    "\n",
    "# Figure\n",
    "k = 1.5 # Figure size to preserve ratio 16:9\n",
    "fig2, ax2 = plt.subplots(2, 5, figsize=(16*k, 9*k))\n",
    "fig2.suptitle(f'BMI vs Volumes ({female_group.shape[0]} females)')\n",
    "fig2.patch.set_facecolor('white')\n",
    "fix_axis = False\n",
    "x_axis = [-2, 2]\n",
    "y_axis = [19,31]\n",
    "\n",
    "# Lens\n",
    "ax2[0][0].set_title(f'Lens')\n",
    "plot1 = sns.scatterplot(x=bmi_female.flatten(), y=volume_lens_female.flatten(), ax=ax2[0][0])\n",
    "ax2[0][0].set_xlabel('BMI (kg/m²)')\n",
    "ax2[0][0].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax2[0][0].set_ylim(y_axis)\n",
    "\n",
    "# Globe\n",
    "ax2[0][1].set_title(f'Globe')\n",
    "plot2 = sns.scatterplot(x=bmi_female.flatten(), y=volume_globe_female.flatten(), ax=ax2[0][1])\n",
    "ax2[0][1].set_xlabel('BMI (kg/m²)')\n",
    "ax2[0][1].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax2[0][1].set_ylim(y_axis)\n",
    "\n",
    "# Optic nerve\n",
    "ax2[0][2].set_title(f'Optic nerve')\n",
    "plot3 = sns.scatterplot(x=bmi_female.flatten(), y=volume_nerve_female.flatten(), ax=ax2[0][2])\n",
    "ax2[0][2].set_xlabel('BMI (kg/m²)')\n",
    "ax2[0][2].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax2[0][2].set_ylim(y_axis)\n",
    "\n",
    "# Intraconal fat\n",
    "ax2[0][3].set_title(f'Intraconal fat')\n",
    "plot4 = sns.scatterplot(x=bmi_female.flatten(), y=volume_int_fat_female.flatten(), ax=ax2[0][3])\n",
    "ax2[0][3].set_xlabel('BMI (kg/m²)')\n",
    "ax2[0][3].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax2[0][3].set_ylim(y_axis)\n",
    "\n",
    "# Extraconal fat\n",
    "ax2[0][4].set_title(f'Extraconal fat')\n",
    "plot5 = sns.scatterplot(x=bmi_female.flatten(), y=volume_ext_fat_female.flatten(), ax=ax2[0][4])\n",
    "ax2[0][4].set_xlabel('BMI (kg/m²)')\n",
    "ax2[0][4].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax2[0][4].set_ylim(y_axis)\n",
    "\n",
    "# Lateral rectus muscle\n",
    "ax2[1][0].set_title(f'Lateral rectus muscle')\n",
    "plot6 = sns.scatterplot(x=bmi_female.flatten(), y=volume_lat_mus_female.flatten(), ax=ax2[1][0])\n",
    "ax2[1][0].set_xlabel('BMI (kg/m²)')\n",
    "ax2[1][0].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax2[1][0].set_ylim(y_axis)\n",
    "\n",
    "# Medial rectus muscle\n",
    "ax2[1][1].set_title(f'Medial rectus muscle')\n",
    "plot7 = sns.scatterplot(x=bmi_female.flatten(), y=volume_med_mus_female.flatten(), ax=ax2[1][1])\n",
    "ax2[1][1].set_xlabel('BMI (kg/m²)')\n",
    "ax2[1][1].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax2[1][1].set_ylim(y_axis)\n",
    "\n",
    "# Inferior rectus muscle\n",
    "ax2[1][2].set_title(f'Inferior rectus muscle')\n",
    "plot8 = sns.scatterplot(x=bmi_female.flatten(), y=volume_inf_mus_female.flatten(), ax=ax2[1][2])\n",
    "ax2[1][2].set_xlabel('BMI (kg/m²)')\n",
    "ax2[1][2].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax2[1][2].set_ylim(y_axis)\n",
    "\n",
    "# Superior rectus muscle\n",
    "ax2[1][3].set_title(f'Superior rectus muscle')\n",
    "plot8 = sns.scatterplot(x=bmi_female.flatten(), y=volume_sup_mus_female.flatten(), ax=ax2[1][3])\n",
    "ax2[1][3].set_xlabel('BMI (kg/m²)')\n",
    "ax2[1][3].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax2[1][3].set_ylim(y_axis)\n",
    "\n",
    "plt.show\n",
    "\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/bmi_vs_volume_females_norm.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check normal distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MALES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male group\n",
    "male_group = sex_group.get_group(\"M\").dropna()\n",
    "\n",
    "# Volumes\n",
    "volume_lens_male = np.array([male_group[\"vol_lens\"]])\n",
    "volume_globe_male = np.array([male_group[\"vol_globe\"]])\n",
    "volume_nerve_male = np.array([male_group[\"vol_nerve\"]])\n",
    "volume_int_fat_male = np.array([male_group[\"vol_int_fat\"]])\n",
    "volume_ext_fat_male = np.array([male_group[\"vol_ext_fat\"]])\n",
    "volume_lat_mus_male = np.array([male_group[\"vol_lat_mus\"]])\n",
    "volume_med_mus_male = np.array([male_group[\"vol_med_mus\"]])\n",
    "volume_inf_mus_male = np.array([male_group[\"vol_inf_mus\"]])\n",
    "volume_sup_mus_male = np.array([male_group[\"vol_sup_mus\"]])\n",
    "\n",
    "# BMI\n",
    "bmi_male = np.array([male_group[\"BMI\"]])\n",
    "\n",
    "# Plot: boxplot (2x5), x_axis=BMI, y_axis=volume per label\n",
    "\n",
    "# Figure\n",
    "k = 1.5 # Figure size to preserve ratio 16:9\n",
    "fig1, ax1 = plt.subplots(2, 5, figsize=(16*k, 9*k))\n",
    "fig1.suptitle(f'BMI vs Volumes ({male_group.shape[0]} males)')\n",
    "fig1.patch.set_facecolor('white')\n",
    "fix_axis = False\n",
    "x_axis = [-2, 2]\n",
    "y_axis = [19,31]\n",
    "\n",
    "# Lens\n",
    "ax1[0][0].set_title(f'Lens')\n",
    "plot1 = sns.distplot(volume_lens_male.flatten(), ax=ax1[0][0])\n",
    "ax1[0][0].set_xlabel('Volume (mm³)')\n",
    "ax1[0][0].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][0].set_ylim(y_axis)\n",
    "\n",
    "# Globe\n",
    "ax1[0][1].set_title(f'Globe')\n",
    "plot2 = sns.distplot(volume_globe_male.flatten(), ax=ax1[0][1])\n",
    "ax1[0][1].set_xlabel('Volume (mm³)')\n",
    "ax1[0][1].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][1].set_ylim(y_axis)\n",
    "\n",
    "# Optic nerve\n",
    "ax1[0][2].set_title(f'Optic nerve')\n",
    "plot3 = sns.distplot(volume_nerve_male.flatten(), ax=ax1[0][2])\n",
    "ax1[0][2].set_xlabel('Volume (mm³)')\n",
    "ax1[0][2].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][2].set_ylim(y_axis)\n",
    "\n",
    "# Intraconal fat\n",
    "ax1[0][3].set_title(f'Intraconal fat')\n",
    "plot4 = sns.distplot(volume_int_fat_male.flatten(), ax=ax1[0][3])\n",
    "ax1[0][3].set_xlabel('Volume (mm³)')\n",
    "ax1[0][3].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][3].set_ylim(y_axis)\n",
    "\n",
    "# Extraconal fat\n",
    "ax1[0][4].set_title(f'Extraconal fat')\n",
    "plot5 = sns.distplot(volume_ext_fat_male.flatten(), ax=ax1[0][4])\n",
    "ax1[0][4].set_xlabel('Volume (mm³)')\n",
    "ax1[0][4].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][4].set_ylim(y_axis)\n",
    "\n",
    "# Lateral rectus muscle\n",
    "ax1[1][0].set_title(f'Lateral rectus muscle')\n",
    "plot6 = sns.distplot(volume_lat_mus_male.flatten(), ax=ax1[1][0])\n",
    "ax1[1][0].set_xlabel('Volume (mm³)')\n",
    "ax1[1][0].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][0].set_ylim(y_axis)\n",
    "\n",
    "# Medial rectus muscle\n",
    "ax1[1][1].set_title(f'Medial rectus muscle')\n",
    "plot7 = sns.distplot(volume_med_mus_male.flatten(), ax=ax1[1][1])\n",
    "ax1[1][1].set_xlabel('Volume (mm³)')\n",
    "ax1[1][1].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][1].set_ylim(y_axis)\n",
    "\n",
    "# Inferior rectus muscle\n",
    "ax1[1][2].set_title(f'Inferior rectus muscle')\n",
    "plot8 = sns.distplot(volume_inf_mus_male.flatten(), ax=ax1[1][2])\n",
    "ax1[1][2].set_xlabel('Volume (mm³)')\n",
    "ax1[1][2].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][2].set_ylim(y_axis)\n",
    "\n",
    "# Superior rectus muscle\n",
    "ax1[1][3].set_title(f'Superior rectus muscle')\n",
    "plot9 = sns.distplot(volume_sup_mus_male.flatten(), ax=ax1[1][3])\n",
    "ax1[1][3].set_xlabel('Volume (mm³)')\n",
    "ax1[1][3].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][3].set_ylim(y_axis)\n",
    "\n",
    "# Superior rectus muscle\n",
    "ax1[1][4].set_title(f'BMI')\n",
    "plot10 = sns.distplot(bmi_male.flatten(), ax=ax1[1][4])\n",
    "ax1[1][4].set_xlabel('BMI')\n",
    "ax1[1][4].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][4].set_ylim(y_axis)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/bmi_vs_volume/dist_gaussian_vol_bmi_males.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapiro-Wilk test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# LENS\n",
    "statistic, p_value = stats.shapiro(volume_lens_male.flatten())\n",
    "print(f\"LENS \\nstats = {statistic:g} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# GLOBE\n",
    "statistic, p_value = stats.shapiro(volume_globe_male.flatten())\n",
    "print(f\"GLOBE \\nstats = {statistic:g} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# OPTIC NERVE\n",
    "statistic, p_value = stats.shapiro(volume_nerve_male.flatten())\n",
    "print(f\"OPTIC NERVE \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# INTRACONAL FAT\n",
    "statistic, p_value = stats.shapiro(volume_int_fat_male.flatten())\n",
    "print(f\"INTRACONAL FAT \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# EXTRACONAL FAT\n",
    "statistic, p_value = stats.shapiro(volume_ext_fat_male.flatten())\n",
    "print(f\"EXTRACONAL FAT \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# LATERAL RECTUS MUSCLE\n",
    "statistic, p_value = stats.shapiro(volume_lat_mus_male.flatten())\n",
    "print(f\"LATERAL RECTUS MUSCLE \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# MEDIAL RECTUS MUSCLE\n",
    "statistic, p_value = stats.shapiro(volume_med_mus_male.flatten())\n",
    "print(f\"MEDIAL RECTUS MUSCLE \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# SUPERIOR RECTUS MUSCLE\n",
    "statistic, p_value = stats.shapiro(volume_sup_mus_male.flatten())\n",
    "print(f\"SUPERIOR RECTUS MUSCLE \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# INFERIOR RECTUS MUSCLE\n",
    "statistic, p_value = stats.shapiro(volume_inf_mus_male.flatten())\n",
    "print(f\"INFERIOR RECTUS MUSCLE \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# BMI\n",
    "statistic, p_value = stats.shapiro(bmi_male.flatten())\n",
    "print(f\"BMI \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FEMALES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female group\n",
    "female_group = sex_group.get_group(\"F\").dropna()\n",
    "\n",
    "# Volumes\n",
    "volume_lens_female = np.array([female_group[\"vol_lens\"]])\n",
    "volume_globe_female = np.array([female_group[\"vol_globe\"]])\n",
    "volume_nerve_female = np.array([female_group[\"vol_nerve\"]])\n",
    "volume_int_fat_female = np.array([female_group[\"vol_int_fat\"]])\n",
    "volume_ext_fat_female = np.array([female_group[\"vol_ext_fat\"]])\n",
    "volume_lat_mus_female = np.array([female_group[\"vol_lat_mus\"]])\n",
    "volume_med_mus_female = np.array([female_group[\"vol_med_mus\"]])\n",
    "volume_inf_mus_female = np.array([female_group[\"vol_inf_mus\"]])\n",
    "volume_sup_mus_female = np.array([female_group[\"vol_sup_mus\"]])\n",
    "\n",
    "# BMI\n",
    "bmi_female = np.array([female_group[\"BMI\"]])\n",
    "\n",
    "# Plot: boxplot (2x5), x_axis=BMI, y_axis=volume per label\n",
    "\n",
    "# Figure\n",
    "k = 1.5 # Figure size to preserve ratio 16:9\n",
    "fig1, ax1 = plt.subplots(2, 5, figsize=(16*k, 9*k))\n",
    "fig1.suptitle(f'BMI vs Volumes ({female_group.shape[0]} females)')\n",
    "fig1.patch.set_facecolor('white')\n",
    "fix_axis = False\n",
    "x_axis = [-2, 2]\n",
    "y_axis = [19,31]\n",
    "\n",
    "# Lens\n",
    "ax1[0][0].set_title(f'Lens')\n",
    "plot1 = sns.distplot(volume_lens_female.flatten(), ax=ax1[0][0])\n",
    "ax1[0][0].set_xlabel('Volume (mm³)')\n",
    "ax1[0][0].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][0].set_ylim(y_axis)\n",
    "\n",
    "# Globe\n",
    "ax1[0][1].set_title(f'Globe')\n",
    "plot2 = sns.distplot(volume_globe_female.flatten(), ax=ax1[0][1])\n",
    "ax1[0][1].set_xlabel('Volume (mm³)')\n",
    "ax1[0][1].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][1].set_ylim(y_axis)\n",
    "\n",
    "# Optic nerve\n",
    "ax1[0][2].set_title(f'Optic nerve')\n",
    "plot3 = sns.distplot(volume_nerve_female.flatten(), ax=ax1[0][2])\n",
    "ax1[0][2].set_xlabel('Volume (mm³)')\n",
    "ax1[0][2].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][2].set_ylim(y_axis)\n",
    "\n",
    "# Intraconal fat\n",
    "ax1[0][3].set_title(f'Intraconal fat')\n",
    "plot4 = sns.distplot(volume_int_fat_female.flatten(), ax=ax1[0][3])\n",
    "ax1[0][3].set_xlabel('Volume (mm³)')\n",
    "ax1[0][3].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][3].set_ylim(y_axis)\n",
    "\n",
    "# Extraconal fat\n",
    "ax1[0][4].set_title(f'Extraconal fat')\n",
    "plot5 = sns.distplot(volume_ext_fat_female.flatten(), ax=ax1[0][4])\n",
    "ax1[0][4].set_xlabel('Volume (mm³)')\n",
    "ax1[0][4].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][4].set_ylim(y_axis)\n",
    "\n",
    "# Lateral rectus muscle\n",
    "ax1[1][0].set_title(f'Lateral rectus muscle')\n",
    "plot6 = sns.distplot(volume_lat_mus_female.flatten(), ax=ax1[1][0])\n",
    "ax1[1][0].set_xlabel('Volume (mm³)')\n",
    "ax1[1][0].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][0].set_ylim(y_axis)\n",
    "\n",
    "# Medial rectus muscle\n",
    "ax1[1][1].set_title(f'Medial rectus muscle')\n",
    "plot7 = sns.distplot(volume_med_mus_female.flatten(), ax=ax1[1][1])\n",
    "ax1[1][1].set_xlabel('Volume (mm³)')\n",
    "ax1[1][1].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][1].set_ylim(y_axis)\n",
    "\n",
    "# Inferior rectus muscle\n",
    "ax1[1][2].set_title(f'Inferior rectus muscle')\n",
    "plot8 = sns.distplot(volume_inf_mus_female.flatten(), ax=ax1[1][2])\n",
    "ax1[1][2].set_xlabel('Volume (mm³)')\n",
    "ax1[1][2].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][2].set_ylim(y_axis)\n",
    "\n",
    "# Superior rectus muscle\n",
    "ax1[1][3].set_title(f'Superior rectus muscle')\n",
    "plot9 = sns.distplot(volume_sup_mus_female.flatten(), ax=ax1[1][3])\n",
    "ax1[1][3].set_xlabel('Volume (mm³)')\n",
    "ax1[1][3].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][3].set_ylim(y_axis)\n",
    "\n",
    "# Superior rectus muscle\n",
    "ax1[1][4].set_title(f'BMI')\n",
    "plot10 = sns.distplot(bmi_female.flatten(), ax=ax1[1][4])\n",
    "ax1[1][4].set_xlabel('BMI')\n",
    "ax1[1][4].set_ylabel('Frequency')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][4].set_ylim(y_axis)\n",
    "\n",
    "plt.show\n",
    "\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/bmi_vs_volume/dist_gaussian_vol_bmi_females.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapiro-Wilk test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# LENS\n",
    "statistic, p_value = stats.shapiro(volume_lens_female.flatten())\n",
    "print(f\"LENS \\nstats = {statistic:g} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# GLOBE\n",
    "statistic, p_value = stats.shapiro(volume_globe_female.flatten())\n",
    "print(f\"GLOBE \\nstats = {statistic:g} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# OPTIC NERVE\n",
    "statistic, p_value = stats.shapiro(volume_nerve_female.flatten())\n",
    "print(f\"OPTIC NERVE \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# INTRACONAL FAT\n",
    "statistic, p_value = stats.shapiro(volume_int_fat_female.flatten())\n",
    "print(f\"INTRACONAL FAT \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# EXTRACONAL FAT\n",
    "statistic, p_value = stats.shapiro(volume_ext_fat_female.flatten())\n",
    "print(f\"EXTRACONAL FAT \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# LATERAL RECTUS MUSCLE\n",
    "statistic, p_value = stats.shapiro(volume_lat_mus_female.flatten())\n",
    "print(f\"LATERAL RECTUS MUSCLE \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# MEDIAL RECTUS MUSCLE\n",
    "statistic, p_value = stats.shapiro(volume_med_mus_female.flatten())\n",
    "print(f\"MEDIAL RECTUS MUSCLE \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# SUPERIOR RECTUS MUSCLE\n",
    "statistic, p_value = stats.shapiro(volume_sup_mus_female.flatten())\n",
    "print(f\"SUPERIOR RECTUS MUSCLE \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# INFERIOR RECTUS MUSCLE\n",
    "statistic, p_value = stats.shapiro(volume_inf_mus_female.flatten())\n",
    "print(f\"INFERIOR RECTUS MUSCLE \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")\n",
    "\n",
    "# BMI\n",
    "statistic, p_value = stats.shapiro(bmi_female.flatten())\n",
    "print(f\"BMI \\nstats = {statistic} p_value = {p_value:g}\")\n",
    "if p_value < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected --> The set may NOT follow a normal distribution\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected --> The set may follow a normal distribution\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = 0\n",
    "remove_outliers = 0\n",
    "remove_zeros = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Males"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male group\n",
    "male_group = sex_group.get_group(\"M\").dropna() \n",
    "\n",
    "# # Splitting into train and test sets\n",
    "\n",
    "# Get all the columns from the dataframe.\n",
    "columns = male_group.columns.tolist()\n",
    "\n",
    "# Filter the columns to remove ones we don't want.\n",
    "columns = [c for c in columns if c not in [\"index\", \"Subject\", \"Sex\", \"Weight\", \"Height\", \"BMI\", \"Age\"]]\n",
    "# columns = ['vol_lens']\n",
    "# print([columns[0]])\n",
    "\n",
    "# Store the variable we'll be predicting on.\n",
    "target = \"BMI\"\n",
    "\n",
    "# Generate the training set.  Set random_state to be able to replicate results.\n",
    "if train_test:\n",
    "    train = male_group.sample(frac=0.8, random_state=1)\n",
    "else: train = male_group\n",
    "\n",
    "# Select anything not in the training set and put it in the testing set.\n",
    "test = male_group.loc[~male_group.index.isin(train.index)]\n",
    "\n",
    "# Print the shapes of both sets.\n",
    "print(train[columns].shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "ALPHA = 0.05\n",
    "f_statistics, p_values = f_regression(train[columns], train[target]) # volumes with BMI\n",
    "\n",
    "# print(f'p_value = {p_values}')\n",
    "print(f'p_values \\n Lens: {p_values[0]} \\n Globe: {p_values[1]} \\n Optic nerve: {p_values[2]} \\n Intraconal fat: {p_values[3]} \\\n",
    "    \\n Extraconal fat: {p_values[4]} \\n Lateral rectus muscle: {p_values[5]} \\n Medial rectus muscle: {p_values[6]} \\\n",
    "    \\n Inferior rectus muscle: {p_values[7]} \\n Superior rectus muscle: {p_values[8]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41vbNNjBMnqP"
   },
   "outputs": [],
   "source": [
    "# Fitting a linear regression\n",
    "\n",
    "# Import the linear models.\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sma\n",
    "\n",
    "# Initialize the model class.\n",
    "model = linear_model.LinearRegression()\n",
    "# model = linear_model.Ridge(alpha = 0.5)\n",
    "\n",
    "# Fit the model to the training data.\n",
    "trained_model = model.fit(train[columns], train[target])\n",
    "\n",
    "# Model score, intercept and  slope\n",
    "intercept = trained_model.intercept_\n",
    "slope = trained_model.coef_\n",
    "print(f'R² score = {trained_model.score(train[columns], train[target])} \\nIntercept = {intercept} \\nSlope = {slope}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Error\n",
    "\n",
    "# Import the scikit-learn function to compute error. Explained variance score.\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "if train_test:\n",
    "    # Generate our predictions for the test set.\n",
    "    predictions = model.predict(test[columns])\n",
    "\n",
    "    # Compute error between our test predictions and the actual values.\n",
    "    RMSE = mean_squared_error(predictions, test[target], squared=False)\n",
    "    print('Root mean squared error: ', RMSE)\n",
    "\n",
    "    # R² score\n",
    "    print('Variance score (R²-score): %.2f' % r2_score(test[target], predictions))\n",
    "else:\n",
    "    # Generate our predictions for the test set.\n",
    "    predictions = model.predict(train[columns])\n",
    "\n",
    "    # Compute error between our test predictions and the actual values.\n",
    "    RMSE = mean_squared_error(predictions, train[target], squared=False)\n",
    "    print('Root mean squared error: ', RMSE)\n",
    "\n",
    "    # R² score\n",
    "    print('Variance score (R²-score): %.2f' % r2_score(train[target], predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male group\n",
    "male_group = sex_group.get_group(\"M\").dropna() \n",
    "\n",
    "# Volumes\n",
    "volume_lens_male = np.array([male_group[\"vol_lens\"]])\n",
    "volume_globe_male = np.array([male_group[\"vol_globe\"]])\n",
    "volume_nerve_male = np.array([male_group[\"vol_nerve\"]])\n",
    "volume_int_fat_male = np.array([male_group[\"vol_int_fat\"]])\n",
    "volume_ext_fat_male = np.array([male_group[\"vol_ext_fat\"]])\n",
    "volume_lat_mus_male = np.array([male_group[\"vol_lat_mus\"]])\n",
    "volume_med_mus_male = np.array([male_group[\"vol_med_mus\"]])\n",
    "volume_inf_mus_male = np.array([male_group[\"vol_inf_mus\"]])\n",
    "volume_sup_mus_male = np.array([male_group[\"vol_sup_mus\"]])\n",
    "\n",
    "# BMI\n",
    "bmi_male = np.array([male_group[\"BMI\"]])\n",
    "\n",
    "# Plot: boxplot (2x5), x_axis=BMI, y_axis=volume per label\n",
    "\n",
    "# Figure\n",
    "k = 1.5 # Figure size to preserve ratio 16:9\n",
    "fig1, ax1 = plt.subplots(2, 5, figsize=(16*k, 9*k))\n",
    "fig1.suptitle(f'BMI vs Volumes ({male_group.shape[0]} males)')\n",
    "fig1.patch.set_facecolor('white')\n",
    "fix_axis = False\n",
    "x_axis = [-2, 2]\n",
    "y_axis = [19,31]\n",
    "\n",
    "# Line per label (using intercept and slope)\n",
    "def get_line_lens(x):\n",
    "    return slope[0] * x + intercept\n",
    "def get_line_globe(x):\n",
    "    return slope[1] * x + intercept\n",
    "def get_line_nerve(x):\n",
    "    return slope[2] * x + intercept\n",
    "def get_line_int_fat(x):\n",
    "    return slope[3] * x + intercept\n",
    "def get_line_ext_fat(x):\n",
    "    return slope[4] * x + intercept\n",
    "def get_line_lat_mus(x):\n",
    "    return slope[5] * x + intercept\n",
    "def get_line_med_mus(x):\n",
    "    return slope[6] * x + intercept\n",
    "def get_line_inf_mus(x):\n",
    "    return slope[7] * x + intercept\n",
    "def get_line_sup_mus(x):\n",
    "    return slope[8] * x + intercept\n",
    "\n",
    "# Lens\n",
    "ax1[0][0].set_title(f'Lens')\n",
    "plot1 = sns.scatterplot(x=bmi_male.flatten(), y=volume_lens_male.flatten(), ax=ax1[0][0])\n",
    "line_points = list(map(get_line_lens, volume_lens_male.flatten()))\n",
    "line = Line2D(line_points, volume_lens_male.flatten(), color='red')\n",
    "ax1[0][0].add_line(line)\n",
    "ax1[0][0].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][0].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][0].set_ylim(y_axis)\n",
    "\n",
    "# Globe\n",
    "ax1[0][1].set_title(f'Globe')\n",
    "plot2 = sns.scatterplot(x=bmi_male.flatten(), y=volume_globe_male.flatten(), ax=ax1[0][1])\n",
    "line_points = list(map(get_line_globe, volume_globe_male.flatten()))\n",
    "line = Line2D(line_points, volume_globe_male.flatten(), color='red')\n",
    "ax1[0][1].add_line(line)\n",
    "ax1[0][1].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][1].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][1].set_ylim(y_axis)\n",
    "\n",
    "# Optic nerve\n",
    "ax1[0][2].set_title(f'Optic nerve')\n",
    "plot3 = sns.scatterplot(x=bmi_male.flatten(), y=volume_nerve_male.flatten(), ax=ax1[0][2])\n",
    "line_points = list(map(get_line_nerve, volume_nerve_male.flatten()))\n",
    "line = Line2D(line_points, volume_nerve_male.flatten(), color='red')\n",
    "ax1[0][2].add_line(line)\n",
    "ax1[0][2].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][2].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][2].set_ylim(y_axis)\n",
    "\n",
    "# Intraconal fat\n",
    "ax1[0][3].set_title(f'Intraconal fat')\n",
    "plot4 = sns.scatterplot(x=bmi_male.flatten(), y=volume_int_fat_male.flatten(), ax=ax1[0][3])\n",
    "line_points = list(map(get_line_int_fat, volume_int_fat_male.flatten()))\n",
    "line = Line2D(line_points, volume_int_fat_male.flatten(), color='red')\n",
    "ax1[0][3].add_line(line)\n",
    "ax1[0][3].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][3].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][3].set_ylim(y_axis)\n",
    "\n",
    "# Extraconal fat\n",
    "ax1[0][4].set_title(f'Extraconal fat')\n",
    "plot5 = sns.scatterplot(x=bmi_male.flatten(), y=volume_ext_fat_male.flatten(), ax=ax1[0][4])\n",
    "line_points = list(map(get_line_ext_fat, volume_ext_fat_male.flatten()))\n",
    "line = Line2D(line_points, volume_ext_fat_male.flatten(), color='red')\n",
    "ax1[0][4].add_line(line)\n",
    "ax1[0][4].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][4].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][4].set_ylim(y_axis)\n",
    "\n",
    "# Lateral rectus muscle\n",
    "ax1[1][0].set_title(f'Lateral rectus muscle')\n",
    "plot6 = sns.scatterplot(x=bmi_male.flatten(), y=volume_lat_mus_male.flatten(), ax=ax1[1][0])\n",
    "line_points = list(map(get_line_lat_mus, volume_lat_mus_male.flatten()))\n",
    "line = Line2D(line_points, volume_lat_mus_male.flatten(), color='red')\n",
    "ax1[1][0].add_line(line)\n",
    "ax1[1][0].set_xlabel('BMI (kg/m²)')\n",
    "ax1[1][0].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][0].set_ylim(y_axis)\n",
    "\n",
    "# Medial rectus muscle\n",
    "ax1[1][1].set_title(f'Medial rectus muscle')\n",
    "plot7 = sns.scatterplot(x=bmi_male.flatten(), y=volume_med_mus_male.flatten(), ax=ax1[1][1])\n",
    "line_points = list(map(get_line_med_mus, volume_med_mus_male.flatten()))\n",
    "line = Line2D(line_points, volume_med_mus_male.flatten(), color='red')\n",
    "ax1[1][1].add_line(line)\n",
    "ax1[1][1].set_xlabel('BMI (kg/m²)')\n",
    "ax1[1][1].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][1].set_ylim(y_axis)\n",
    "\n",
    "# Inferior rectus muscle\n",
    "ax1[1][2].set_title(f'Inferior rectus muscle')\n",
    "plot8 = sns.scatterplot(x=bmi_male.flatten(), y=volume_inf_mus_male.flatten(), ax=ax1[1][2])\n",
    "line_points = list(map(get_line_inf_mus, volume_inf_mus_male.flatten()))\n",
    "line = Line2D(line_points, volume_inf_mus_male.flatten(), color='red')\n",
    "ax1[1][2].add_line(line)\n",
    "ax1[1][2].set_xlabel('BMI (kg/m²)')\n",
    "ax1[1][2].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][2].set_ylim(y_axis)\n",
    "\n",
    "# Superior rectus muscle\n",
    "ax1[1][3].set_title(f'Superior rectus muscle')\n",
    "plot8 = sns.scatterplot(x=bmi_male.flatten(), y=volume_sup_mus_male.flatten(), ax=ax1[1][3])\n",
    "line_points = list(map(get_line_sup_mus, volume_sup_mus_male.flatten()))\n",
    "line = Line2D(line_points, volume_sup_mus_male.flatten(), color='red')\n",
    "ax1[1][3].add_line(line)\n",
    "ax1[1][3].set_xlabel('BMI (kg/m²)')\n",
    "ax1[1][3].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][3].set_ylim(y_axis)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/bmi_vs_volume_males_norm.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "if train_test:\n",
    "    plt.scatter(test[target], predictions,  color='red')\n",
    "else:\n",
    "    plt.scatter(train[target], predictions, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "# Import the linear models.\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
    "import statsmodels.api as sma\n",
    "# Import the scikit-learn function to compute error. Explained variance score.\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# Correlations\n",
    "from scipy import stats\n",
    "\n",
    "# Male group\n",
    "male_group = sex_group.get_group(\"M\").dropna()\n",
    "print('MALES \\n')\n",
    "\n",
    "# Get all the columns from the dataframe.\n",
    "columns = male_group.columns.tolist()\n",
    "\n",
    "# Filter the columns to remove ones we don't want.\n",
    "columns = [c for c in columns if c not in [\"index\", \"Subject\", \"Sex\", \"Weight\", \"Height\", \"BMI\", \"Age\"]]\n",
    "# print([columns[0]])\n",
    "\n",
    "# Store the variable we'll be predicting on.\n",
    "target = \"BMI\"\n",
    "\n",
    "# Generate the training set.  Set random_state to be able to replicate results.\n",
    "if train_test:\n",
    "    train = male_group.sample(frac=0.8, random_state=1)\n",
    "else: train = male_group\n",
    "\n",
    "# Select anything not in the training set and put it in the testing set.\n",
    "test = male_group.loc[~male_group.index.isin(train.index)]\n",
    "\n",
    "# Print the shapes of both sets.\n",
    "print(f'Train shape: {train[columns].shape}')\n",
    "print(f'Test shape: {test.shape} \\n')\n",
    "\n",
    "ALPHA = 0.05 # for the p values\n",
    "# model = linear_model.LinearRegression() # linear model for the regression\n",
    "\n",
    "# List labels\n",
    "list_labels = ['Lens', 'Globe', 'Optic nerve', 'Intraconal fat', 'Extraconal fat', 'Lateral rectus muscle', 'Medial rectus muscle',\n",
    "    'Inferior rectus muscle', 'Superior rectus muscle']\n",
    "\n",
    "# Volumes\n",
    "volume_lens_male = np.array([male_group[\"vol_lens\"]])\n",
    "volume_globe_male = np.array([male_group[\"vol_globe\"]])\n",
    "volume_nerve_male = np.array([male_group[\"vol_nerve\"]])\n",
    "volume_int_fat_male = np.array([male_group[\"vol_int_fat\"]])\n",
    "volume_ext_fat_male = np.array([male_group[\"vol_ext_fat\"]])\n",
    "volume_lat_mus_male = np.array([male_group[\"vol_lat_mus\"]])\n",
    "volume_med_mus_male = np.array([male_group[\"vol_med_mus\"]])\n",
    "volume_inf_mus_male = np.array([male_group[\"vol_inf_mus\"]])\n",
    "volume_sup_mus_male = np.array([male_group[\"vol_sup_mus\"]])\n",
    "volumes_male_list = np.array([volume_lens_male, volume_globe_male, volume_nerve_male, volume_int_fat_male, volume_ext_fat_male,\n",
    "    volume_lat_mus_male, volume_med_mus_male, volume_inf_mus_male, volume_sup_mus_male])\n",
    "\n",
    "# BMI\n",
    "bmi_male = np.array([male_group[\"BMI\"]])\n",
    "\n",
    "# Plot: boxplot (2x5), x_axis=BMI, y_axis=volume per label\n",
    "# Figure\n",
    "k = 1.5 # Figure size to preserve ratio 16:9\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.tight_layout()\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "plt.suptitle(f'BMI vs Volumes ({male_group.shape[0]} males) - {METHOD}')\n",
    "fix_axis = False\n",
    "# x_axis = [-2, 2]\n",
    "y_axis = [0, 9000]\n",
    "# Legend\n",
    "# legend_elements = [Line2D([], [], color='red', lw=2, label=f'Huber regressor')] #Line2D([], [], color='green', label='Linear regressor')\n",
    "# fig.legend(handles=legend_elements, loc='upper right')\n",
    "color_arr = ['tab:red','lime','tab:blue','yellow','cyan','magenta','lightgray','tab:purple','chocolate']\n",
    "\n",
    "for n, c in enumerate(columns):\n",
    "\n",
    "    print(list_labels[n])\n",
    "\n",
    "    # print(train[c].shape)\n",
    "    # print(train[target].shape)\n",
    "\n",
    "    # 2D array having predictor and target\n",
    "    arr = np.array([train[c], train[target]]).T # predictor, target\n",
    "    print(f'Shape before removing outliers = {arr.shape}')\n",
    "\n",
    "    # Remove zeros\n",
    "    if remove_zeros == True:\n",
    "        # Vol\n",
    "        arr = arr[arr[:,0] != 0]\n",
    "        print(f'Shape after removing zeros = {arr.shape}')\n",
    "\n",
    "    # Huber regressor\n",
    "    huber = HuberRegressor().fit(arr[:,0].reshape(-1, 1), arr[:,1])\n",
    "    huber_score = huber.score(arr[:,0].reshape(-1, 1), arr[:,1])\n",
    "    predictions = huber.predict(arr[:,0].reshape(-1, 1))\n",
    "    slope_huber = huber.coef_\n",
    "    intercept_huber = huber.intercept_\n",
    "    print(f'Slope Huber = {slope_huber} \\nIntercept Huber = {intercept_huber} \\nHuber score (R² score) = {huber_score}')\n",
    "\n",
    "    # Linear regression\n",
    "    result = stats.linregress(arr)\n",
    "    slope_linear = result.slope\n",
    "    intercept_linear = result.intercept\n",
    "    r_value = result.rvalue\n",
    "    p_value = result.pvalue\n",
    "    stderr = result.stderr\n",
    "    print(f'Slope linear= {slope_linear} \\nIntercept linear = {intercept_linear} \\nR value (Pearson) = {r_value} \\nP value = {p_value} \\nStderr = {stderr} \\n')\n",
    "\n",
    "    # Line per label (using intercept and slope)\n",
    "    def get_line_huber(x):\n",
    "        return slope_huber * x + intercept_huber\n",
    "    def get_line_linear(x):\n",
    "        return slope_linear * x + intercept_linear\n",
    "\n",
    "    # Plot\n",
    "    ax = plt.subplot(3, 3, n+1) # add a new subplot iteratively\n",
    "    sns.scatterplot(y=arr[:,1], x=arr[:,0], ax=ax, color=color_arr[n])\n",
    "    line_points_huber = list(map(get_line_huber, arr[:,0]))\n",
    "    line_huber = Line2D(arr[:,0], line_points_huber, color='grey')\n",
    "    line_points_linear = list(map(get_line_linear, arr[:,0]))\n",
    "    line_linear= Line2D(arr[:,0], line_points_linear, color='green')\n",
    "    # if huber_score > 0.3:\n",
    "    ax.add_line(line_huber)\n",
    "        # ax.add_line(line_linear)\n",
    "    # Title and axis labels\n",
    "    ax.set_title(list_labels[n])\n",
    "    ax.set_ylabel('BMI (kg/m²)')\n",
    "    ax.set_xlabel('Volume (mm³)')\n",
    "    # Legend\n",
    "    values_legend = [f'y = {slope_huber[0]:f}*x + {intercept_huber:.2f}\\n r = {huber_score:f}']\n",
    "    ax.legend(values_legend, loc='upper right')\n",
    "    # Axis\n",
    "    if fix_axis:\n",
    "        # ax.set_xlim(x_axis)\n",
    "        ax.set_ylim(y_axis)\n",
    "\n",
    "filename = 'bmi_vs_volume_males_linear_regression_outliers_mean' if remove_outliers else f'{METHOD}_bmi_vs_volume_males_huber_regression_qc1_qc2_qc3'\n",
    "# plt.savefig(f'/mnt/sda1/Repos/a-eye/Output/volumetry_vs_bmi/{filename}_inv.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[:,0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Females"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female group\n",
    "female_group = sex_group.get_group(\"F\").dropna() \n",
    "\n",
    "# # Splitting into train and test sets\n",
    "\n",
    "# Get all the columns from the dataframe.\n",
    "columns = female_group.columns.tolist()\n",
    "\n",
    "# Filter the columns to remove ones we don't want.\n",
    "columns = [c for c in columns if c not in [\"index\", \"Subject\", \"Sex\", \"Weight\", \"Height\", \"BMI\"]]\n",
    "\n",
    "# Store the variable we'll be predicting on.\n",
    "target = \"BMI\"\n",
    "\n",
    "# Generate the training set.  Set random_state to be able to replicate results.\n",
    "if train_test:\n",
    "    train = female_group.sample(frac=0.8, random_state=1)\n",
    "else: train = female_group    \n",
    "\n",
    "# Select anything not in the training set and put it in the testing set.\n",
    "test = female_group.loc[~female_group.index.isin(train.index)]\n",
    "\n",
    "# Print the shapes of both sets.\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "ALPHA = 0.05\n",
    "f_statistics, p_values = f_regression(train[columns], train[target]) # volumes with BMI\n",
    "\n",
    "print(f'p_values \\n Lens: {p_values[0]} \\n Globe: {p_values[1]} \\n Optic nerve: {p_values[2]} \\n Intraconal fat: {p_values[3]} \\\n",
    "    \\n Extraconal fat: {p_values[4]} \\n Lateral rectus muscle: {p_values[5]} \\n Medial rectus muscle: {p_values[6]} \\\n",
    "    \\n Inferior rectus muscle: {p_values[7]} \\n Superior rectus muscle: {p_values[8]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41vbNNjBMnqP"
   },
   "outputs": [],
   "source": [
    "# Fitting a linear regression\n",
    "\n",
    "# Import the linear models.\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sma\n",
    "\n",
    "# Initialize the model class.\n",
    "model = linear_model.LinearRegression()\n",
    "# model = linear_model.Ridge(alpha = 0.5)\n",
    "\n",
    "# Fit the model to the training data.\n",
    "trained_model = model.fit(train[columns], train[target])\n",
    "\n",
    "# Model score, intercept and  slope\n",
    "intercept = trained_model.intercept_\n",
    "slope = trained_model.coef_\n",
    "print(f'R² score = {trained_model.score(train[columns], train[target])} \\nIntercept = {intercept} \\nSlope = {slope}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Error\n",
    "\n",
    "# Import the scikit-learn function to compute error. Explained variance score.\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "if train_test:\n",
    "    # Generate our predictions for the test set.\n",
    "    predictions = model.predict(test[columns])\n",
    "\n",
    "    # Compute error between our test predictions and the actual values.\n",
    "    RMSE = mean_squared_error(predictions, test[target], squared=False)\n",
    "    print('Root mean squared error: ', RMSE)\n",
    "\n",
    "    # R² score\n",
    "    print('Variance score (R²-score): %.2f' % r2_score(test[target], predictions))\n",
    "else:\n",
    "    # Generate our predictions for the test set.\n",
    "    predictions = model.predict(train[columns])\n",
    "\n",
    "    # Compute error between our test predictions and the actual values.\n",
    "    RMSE = mean_squared_error(predictions, train[target], squared=False)\n",
    "    print('Root mean squared error: ', RMSE)\n",
    "\n",
    "    # R² score\n",
    "    print('Variance score (R²-score): %.2f' % r2_score(train[target], predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female group\n",
    "female_group = sex_group.get_group(\"F\").dropna() \n",
    "\n",
    "# Volumes\n",
    "volume_lens_female = np.array([female_group[\"vol_lens\"]])\n",
    "volume_globe_female = np.array([female_group[\"vol_globe\"]])\n",
    "volume_nerve_female = np.array([female_group[\"vol_nerve\"]])\n",
    "volume_int_fat_female = np.array([female_group[\"vol_int_fat\"]])\n",
    "volume_ext_fat_female = np.array([female_group[\"vol_ext_fat\"]])\n",
    "volume_lat_mus_female = np.array([female_group[\"vol_lat_mus\"]])\n",
    "volume_med_mus_female = np.array([female_group[\"vol_med_mus\"]])\n",
    "volume_inf_mus_female = np.array([female_group[\"vol_inf_mus\"]])\n",
    "volume_sup_mus_female = np.array([female_group[\"vol_sup_mus\"]])\n",
    "\n",
    "# BMI\n",
    "bmi_female = np.array([female_group[\"BMI\"]])\n",
    "\n",
    "# Plot: boxplot (2x5), x_axis=BMI, y_axis=volume per label\n",
    "\n",
    "# Figure\n",
    "k = 1.5 # Figure size to preserve ratio 16:9\n",
    "fig1, ax1 = plt.subplots(2, 5, figsize=(16*k, 9*k))\n",
    "fig1.suptitle(f'BMI vs Volumes ({female_group.shape[0]} females)')\n",
    "fig1.patch.set_facecolor('white')\n",
    "fix_axis = False\n",
    "x_axis = [-2, 2]\n",
    "y_axis = [19,31]\n",
    "\n",
    "# Line per label (using intercept and slope)\n",
    "def get_line_lens(x):\n",
    "    return slope[0] * x + intercept\n",
    "def get_line_globe(x):\n",
    "    return slope[1] * x + intercept\n",
    "def get_line_nerve(x):\n",
    "    return slope[2] * x + intercept\n",
    "def get_line_int_fat(x):\n",
    "    return slope[3] * x + intercept\n",
    "def get_line_ext_fat(x):\n",
    "    return slope[4] * x + intercept\n",
    "def get_line_lat_mus(x):\n",
    "    return slope[5] * x + intercept\n",
    "def get_line_med_mus(x):\n",
    "    return slope[6] * x + intercept\n",
    "def get_line_inf_mus(x):\n",
    "    return slope[7] * x + intercept\n",
    "def get_line_sup_mus(x):\n",
    "    return slope[8] * x + intercept\n",
    "\n",
    "# Lens\n",
    "ax1[0][0].set_title(f'Lens')\n",
    "plot1 = sns.scatterplot(x=bmi_female.flatten(), y=volume_lens_female.flatten(), ax=ax1[0][0])\n",
    "line_points = list(map(get_line_lens, volume_lens_female.flatten()))\n",
    "line = Line2D(line_points, volume_lens_female.flatten(), color='red')\n",
    "ax1[0][0].add_line(line)\n",
    "ax1[0][0].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][0].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][0].set_ylim(y_axis)\n",
    "\n",
    "# Globe\n",
    "ax1[0][1].set_title(f'Globe')\n",
    "plot2 = sns.scatterplot(x=bmi_female.flatten(), y=volume_globe_female.flatten(), ax=ax1[0][1])\n",
    "line_points = list(map(get_line_globe, volume_globe_female.flatten()))\n",
    "line = Line2D(line_points, volume_globe_female.flatten(), color='red')\n",
    "ax1[0][1].add_line(line)\n",
    "ax1[0][1].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][1].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][1].set_ylim(y_axis)\n",
    "\n",
    "# Optic nerve\n",
    "ax1[0][2].set_title(f'Optic nerve')\n",
    "plot3 = sns.scatterplot(x=bmi_female.flatten(), y=volume_nerve_female.flatten(), ax=ax1[0][2])\n",
    "line_points = list(map(get_line_nerve, volume_nerve_female.flatten()))\n",
    "line = Line2D(line_points, volume_nerve_female.flatten(), color='red')\n",
    "ax1[0][2].add_line(line)\n",
    "ax1[0][2].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][2].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][2].set_ylim(y_axis)\n",
    "\n",
    "# Intraconal fat\n",
    "ax1[0][3].set_title(f'Intraconal fat')\n",
    "plot4 = sns.scatterplot(x=bmi_female.flatten(), y=volume_int_fat_female.flatten(), ax=ax1[0][3])\n",
    "line_points = list(map(get_line_int_fat, volume_int_fat_female.flatten()))\n",
    "line = Line2D(line_points, volume_int_fat_female.flatten(), color='red')\n",
    "ax1[0][3].add_line(line)\n",
    "ax1[0][3].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][3].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][3].set_ylim(y_axis)\n",
    "\n",
    "# Extraconal fat\n",
    "ax1[0][4].set_title(f'Extraconal fat')\n",
    "plot5 = sns.scatterplot(x=bmi_female.flatten(), y=volume_ext_fat_female.flatten(), ax=ax1[0][4])\n",
    "line_points = list(map(get_line_ext_fat, volume_ext_fat_female.flatten()))\n",
    "line = Line2D(line_points, volume_ext_fat_female.flatten(), color='red')\n",
    "ax1[0][4].add_line(line)\n",
    "ax1[0][4].set_xlabel('BMI (kg/m²)')\n",
    "ax1[0][4].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[0][4].set_ylim(y_axis)\n",
    "\n",
    "# Lateral rectus muscle\n",
    "ax1[1][0].set_title(f'Lateral rectus muscle')\n",
    "plot6 = sns.scatterplot(x=bmi_female.flatten(), y=volume_lat_mus_female.flatten(), ax=ax1[1][0])\n",
    "line_points = list(map(get_line_lat_mus, volume_lat_mus_female.flatten()))\n",
    "line = Line2D(line_points, volume_lat_mus_female.flatten(), color='red')\n",
    "ax1[1][0].add_line(line)\n",
    "ax1[1][0].set_xlabel('BMI (kg/m²)')\n",
    "ax1[1][0].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][0].set_ylim(y_axis)\n",
    "\n",
    "# Medial rectus muscle\n",
    "ax1[1][1].set_title(f'Medial rectus muscle')\n",
    "plot7 = sns.scatterplot(x=bmi_female.flatten(), y=volume_med_mus_female.flatten(), ax=ax1[1][1])\n",
    "line_points = list(map(get_line_med_mus, volume_med_mus_female.flatten()))\n",
    "line = Line2D(line_points, volume_med_mus_female.flatten(), color='red')\n",
    "ax1[1][1].add_line(line)\n",
    "ax1[1][1].set_xlabel('BMI (kg/m²)')\n",
    "ax1[1][1].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][1].set_ylim(y_axis)\n",
    "\n",
    "# Inferior rectus muscle\n",
    "ax1[1][2].set_title(f'Inferior rectus muscle')\n",
    "plot8 = sns.scatterplot(x=bmi_female.flatten(), y=volume_inf_mus_female.flatten(), ax=ax1[1][2])\n",
    "line_points = list(map(get_line_inf_mus, volume_inf_mus_female.flatten()))\n",
    "line = Line2D(line_points, volume_inf_mus_female.flatten(), color='red')\n",
    "ax1[1][2].add_line(line)\n",
    "ax1[1][2].set_xlabel('BMI (kg/m²)')\n",
    "ax1[1][2].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][2].set_ylim(y_axis)\n",
    "\n",
    "# Superior rectus muscle\n",
    "ax1[1][3].set_title(f'Superior rectus muscle')\n",
    "plot8 = sns.scatterplot(x=bmi_female.flatten(), y=volume_sup_mus_female.flatten(), ax=ax1[1][3])\n",
    "line_points = list(map(get_line_sup_mus, volume_sup_mus_female.flatten()))\n",
    "line = Line2D(line_points, volume_sup_mus_female.flatten(), color='red')\n",
    "ax1[1][3].add_line(line)\n",
    "ax1[1][3].set_xlabel('BMI (kg/m²)')\n",
    "ax1[1][3].set_ylabel('Volume (mm³)')\n",
    "if fix_axis:\n",
    "    # ax[1].set_xlim(x_axis)\n",
    "    ax1[1][3].set_ylim(y_axis)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('/mnt/sda1/Repos/a-eye/Output/bmi_vs_volume_males_norm.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "if train_test:\n",
    "    plt.scatter(test[target], predictions,  color='red')\n",
    "else:\n",
    "    plt.scatter(train[target], predictions, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "# Import the linear models.\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sma\n",
    "# Import the scikit-learn function to compute error. Explained variance score.\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import stats\n",
    "\n",
    "# Female group\n",
    "female_group = sex_group.get_group(\"F\").dropna() \n",
    "print('FEMALES \\n')\n",
    "\n",
    "# Get all the columns from the dataframe.\n",
    "columns = female_group.columns.tolist()\n",
    "\n",
    "# Filter the columns to remove ones we don't want.\n",
    "columns = [c for c in columns if c not in [\"index\", \"Subject\", \"Sex\", \"Weight\", \"Height\", \"BMI\", \"Age\"]]\n",
    "# print([columns[0]])\n",
    "\n",
    "# Store the variable we'll be predicting on.\n",
    "target = \"BMI\"\n",
    "\n",
    "# Generate the training set.  Set random_state to be able to replicate results.\n",
    "if train_test:\n",
    "    train = female_group.sample(frac=0.8, random_state=1)\n",
    "else: train = female_group\n",
    "\n",
    "# Select anything not in the training set and put it in the testing set.\n",
    "test = female_group.loc[~female_group.index.isin(train.index)]\n",
    "\n",
    "# Print the shapes of both sets.\n",
    "print(f'Train shape: {train[columns].shape}')\n",
    "print(f'Test shape: {test.shape} \\n')\n",
    "\n",
    "ALPHA = 0.05 # for the p values\n",
    "model = linear_model.LinearRegression() # linear model for the regression\n",
    "\n",
    "# List labels\n",
    "list_labels = ['Lens', 'Globe', 'Optic nerve', 'Intraconal fat', 'Extraconal fat', 'Lateral rectus muscle', 'Medial rectus muscle',\n",
    "    'Inferior rectus muscle', 'Superior rectus muscle']\n",
    "\n",
    "# Volumes\n",
    "volume_lens_female = np.array([female_group[\"vol_lens\"]])\n",
    "volume_globe_female = np.array([female_group[\"vol_globe\"]])\n",
    "volume_nerve_female = np.array([female_group[\"vol_nerve\"]])\n",
    "volume_int_fat_female = np.array([female_group[\"vol_int_fat\"]])\n",
    "volume_ext_fat_female = np.array([female_group[\"vol_ext_fat\"]])\n",
    "volume_lat_mus_female = np.array([female_group[\"vol_lat_mus\"]])\n",
    "volume_med_mus_female = np.array([female_group[\"vol_med_mus\"]])\n",
    "volume_inf_mus_female = np.array([female_group[\"vol_inf_mus\"]])\n",
    "volume_sup_mus_female = np.array([female_group[\"vol_sup_mus\"]])\n",
    "volumes_female_list = np.array([volume_lens_female, volume_globe_female, volume_nerve_female, volume_int_fat_female, volume_ext_fat_female,\n",
    "    volume_lat_mus_female, volume_med_mus_female, volume_inf_mus_female, volume_sup_mus_female])\n",
    "\n",
    "# BMI\n",
    "bmi_female = np.array([female_group[\"BMI\"]])\n",
    "\n",
    "# Plot: boxplot (2x5), x_axis=BMI, y_axis=volume per label\n",
    "# Figure\n",
    "k = 1.5 # Figure size to preserve ratio 16:9\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.tight_layout()\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "plt.suptitle(f'BMI vs Volumes ({female_group.shape[0]} females) - {METHOD}')\n",
    "fix_axis = False\n",
    "# x_axis = [-2, 2]\n",
    "y_axis = [0, 9000]\n",
    "# Legend\n",
    "# legend_elements = [Line2D([], [], color='red', lw=2, label=f'Huber regressor')] #Line2D([], [], color='green', label='Linear regressor')\n",
    "# fig.legend(handles=legend_elements, loc='upper right')\n",
    "color_arr = ['tab:red','lime','tab:blue','yellow','cyan','magenta','lightgray','tab:purple','chocolate','lightseagreen']\n",
    "\n",
    "for n, c in enumerate(columns):\n",
    "\n",
    "    print(list_labels[n])\n",
    "\n",
    "    # print(train[c].shape)\n",
    "    # print(train[target].shape)\n",
    "\n",
    "    # 2D array having predictor and target\n",
    "    arr = np.array([train[c], train[target]]).T\n",
    "    print(f'Shape before removing outliers = {arr.shape}')\n",
    "\n",
    "    # Remove zeros\n",
    "    if remove_zeros == True:\n",
    "        # Vol\n",
    "        arr = arr[arr[:,0] != 0]\n",
    "        print(f'Shape after removing zeros = {arr.shape}')\n",
    "\n",
    "    # Huber regressor\n",
    "    huber = HuberRegressor().fit(arr[:,0].reshape(-1, 1), arr[:,1])\n",
    "    huber_score = huber.score(arr[:,0].reshape(-1, 1), arr[:,1])\n",
    "    predictions = huber.predict(arr[:,0].reshape(-1, 1))\n",
    "    slope_huber = huber.coef_\n",
    "    intercept_huber = huber.intercept_\n",
    "    print(f'Slope Huber = {slope_huber} \\nIntercept Huber = {intercept_huber} \\nHuber score (R² score) = {huber_score}')\n",
    "\n",
    "    # Linear regression\n",
    "    result = stats.linregress(arr)\n",
    "    slope_linear = result.slope\n",
    "    intercept_linear = result.intercept\n",
    "    r_value = result.rvalue\n",
    "    p_value = result.pvalue\n",
    "    stderr = result.stderr\n",
    "    print(f'Slope linear= {slope_linear} \\nIntercept linear = {intercept_linear} \\nR value (Pearson) = {r_value} \\nP value = {p_value} \\nStderr = {stderr} \\n')\n",
    "\n",
    "    # Line per label (using intercept and slope)\n",
    "    def get_line_huber(x):\n",
    "        return slope_huber * x + intercept_huber\n",
    "    def get_line_linear(x):\n",
    "        return slope_linear * x + intercept_linear\n",
    "\n",
    "    # Plot\n",
    "    ax = plt.subplot(3, 3, n+1) # add a new subplot iteratively\n",
    "    sns.scatterplot(y=arr[:,1], x=arr[:,0], ax=ax, color=color_arr[n])\n",
    "    line_points_huber = list(map(get_line_huber, arr[:,0]))\n",
    "    line_huber = Line2D(arr[:,0], line_points_huber, color='grey')\n",
    "    line_points_linear = list(map(get_line_linear, arr[:,0]))\n",
    "    line_linear= Line2D(arr[:,0], line_points_linear, color='green')\n",
    "    # if huber_score > 0.3:\n",
    "    ax.add_line(line_huber)\n",
    "        # ax.add_line(line_linear)\n",
    "    # Title and axis labels\n",
    "    ax.set_title(list_labels[n])\n",
    "    ax.set_ylabel('BMI (kg/m²)')\n",
    "    ax.set_xlabel('Volume (mm³)')\n",
    "    # Legend\n",
    "    values_legend = [f'y = {slope_huber[0]:f}*x + {intercept_huber:.2f}\\n r = {huber_score:f}']\n",
    "    ax.legend(values_legend, loc='upper right')\n",
    "    # Axis\n",
    "    if fix_axis:\n",
    "        # ax.set_xlim(x_axis)\n",
    "        ax.set_ylim(y_axis)\n",
    "\n",
    "filename = 'bmi_vs_volume_females_linear_regression_outliers_mean' if remove_outliers else f'{METHOD}_bmi_vs_volume_females_huber_regression_qc1_qc2_qc3'\n",
    "plt.savefig(f'/mnt/sda1/Repos/a-eye/Output/volumetry_vs_bmi/{filename}_inv.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a-eye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
